# AliceBot æ™ºèƒ½ä½“é¡¹ç›®æŠ€æœ¯å¼€å‘è¯´æ˜ä¹¦

## 1. é¡¹ç›®æ•´ä½“æ¶æ„ä»‹ç»

### 1.1 é¡¹ç›®æ¦‚è¿°
Project Alice æ˜¯ä¸€ä¸ªåŸºäº LangGraph ä¸ FastAPI æ„å»ºçš„ï¼Œå…·å¤‡æƒ…æ„Ÿæ¨¡æ‹Ÿã€ä¸»åŠ¨ç¤¾äº¤æ„è¯†ä¸å¤šæ¨¡æ€æ„ŸçŸ¥èƒ½åŠ›çš„æ‹ŸäººåŒ– AI Agentã€‚å¥¹ä¸ä»…èƒ½è¿›è¡ŒåŸºæœ¬çš„èŠå¤©äº¤äº’ï¼Œè¿˜æ‹¥æœ‰é•¿æœŸè®°å¿†ã€è§†è§‰æ„ŸçŸ¥ã€æ½œæ„è¯†å¿ƒç†æ´»åŠ¨ä»¥åŠä¸»åŠ¨ç¤¾äº¤æ„æ„¿ã€‚

### 1.2 æ ¸å¿ƒæŠ€æœ¯æ ˆ
- **æ¡†æ¶**: LangGraph (æ™ºèƒ½ä½“å·¥ä½œæµ)ã€FastAPI (API æœåŠ¡)
- **è¯­è¨€æ¨¡å‹**: æ”¯æŒå¤šç§å¤§è¯­è¨€æ¨¡å‹ (ä¸»è¦ä½¿ç”¨ Qwen ç³»åˆ—)
- **è®°å¿†ç³»ç»Ÿ**: ChromaDB (å‘é‡æ•°æ®åº“) + æœ¬åœ°å†å²è®°å½•
- **é€šä¿¡åè®®**: OneBot v11 (ç”¨äºä¸ QQ å®¢æˆ·ç«¯é›†æˆ)

### 1.3 æ¨¡å—æ¶æ„

| æ¨¡å—åç§° | ä¸»è¦åŠŸèƒ½ | æ ¸å¿ƒæ–‡ä»¶ä½ç½® |
|---------|---------|-------------|
| **core** | æ ¸å¿ƒé…ç½®ã€çŠ¶æ€ç®¡ç†ã€æç¤ºè¯ç®¡ç† | `app/core/` |
| **graph** | LangGraph å·¥ä½œæµèŠ‚ç‚¹å®šä¹‰ | `app/graph/` |
| **memory** | æ··åˆè®°å¿†ç³»ç»Ÿ (çŸ­æœŸ+é•¿æœŸ+å…³ç³»è®°å¿†) | `app/memory/` |
| **background** | åå°ä»»åŠ¡ (åšæ¢¦æœºåˆ¶ã€è®°å¿†æ•´ç†) | `app/background/` |
| **tools** | å·¥å…·é›† (æœç´¢ã€ç”»å›¾ã€ä»£ç è§£é‡Šç­‰) | `app/tools/` |
| **plugins** | æ’ä»¶ç³»ç»Ÿ (è¡¨æƒ…åŒ…å¤„ç†ç­‰) | `app/plugins/` |
| **utils** | è¾…åŠ©å·¥å…· (QQ åè®®è§£æã€ç¼“å­˜ç­‰) | `app/utils/` |

### 1.4 æ•´ä½“å·¥ä½œæµç¨‹

1. **è¾“å…¥å¤„ç†**: æ¥æ”¶ç”¨æˆ·æ¶ˆæ¯ (æ–‡æœ¬/å›¾ç‰‡)
2. **ä¸Šä¸‹æ–‡è¿‡æ»¤**: åˆ¤æ–­æ˜¯å¦éœ€è¦å›å¤
3. **å¹¶è¡Œå¤„ç†**: åŒæ—¶è¿›è¡Œè§†è§‰æ„ŸçŸ¥å’Œå¿ƒç†åˆ†æ
4. **æ™ºèƒ½ä½“ç”Ÿæˆ**: ç”Ÿæˆå›å¤å†…å®¹
5. **å·¥å…·è°ƒç”¨**: å¦‚æœ‰éœ€è¦ï¼Œè°ƒç”¨å¤–éƒ¨å·¥å…·
6. **è®°å¿†ä¿å­˜**: æ›´æ–°é•¿æœŸè®°å¿†å’ŒçŸ­æœŸè®°å¿†
7. **è¾“å‡ºå›å¤**: å°†å›å¤å‘é€ç»™ç”¨æˆ·

## 2. åŠŸèƒ½ä»‹ç»ä¸æ•°æ®æµå›¾

### 2.1 åŠŸèƒ½æ¦‚è§ˆ

| åŠŸèƒ½æ¨¡å— | ä¸»è¦åŠŸèƒ½ | æ•°æ®æµè·¯å¾„ |
|---------|---------|-----------|
| **å“åº”å¼å¯¹è¯** | æ¥æ”¶å¹¶å›å¤ç”¨æˆ·æ¶ˆæ¯ | ç”¨æˆ·è¾“å…¥ â†’ ä¸Šä¸‹æ–‡è¿‡æ»¤ â†’ å¹¶è¡Œå¤„ç† â†’ æ™ºèƒ½ä½“ç”Ÿæˆ â†’ å›å¤è¾“å‡º |
| **ä¸»åŠ¨ç¤¾äº¤** | ä¸»åŠ¨å‘èµ·å¯¹è¯ | å®šæ—¶è§¦å‘ â†’ ä¸»åŠ¨ç¤¾äº¤å¼•æ“ â†’ æ™ºèƒ½ä½“ç”Ÿæˆ â†’ å›å¤è¾“å‡º |
| **è§†è§‰æ„ŸçŸ¥** | ç†è§£å›¾ç‰‡å†…å®¹ | ç”¨æˆ·å›¾ç‰‡ â†’ è§†è§‰æ„ŸçŸ¥èŠ‚ç‚¹ â†’ æ™ºèƒ½ä½“ç”Ÿæˆ â†’ å›å¤è¾“å‡º |
| **æƒ…æ„Ÿç³»ç»Ÿ** | æ¨¡æ‹Ÿæƒ…ç»ªå˜åŒ– | ç”¨æˆ·äº¤äº’ â†’ å¿ƒç†åˆ†æ â†’ æƒ…ç»ªæ›´æ–° â†’ å½±å“å›å¤é£æ ¼ |
| **è®°å¿†ç®¡ç†** | é•¿æœŸè®°å¿†ä¸å…³ç³»ç»´æŠ¤ | äº¤äº’å†…å®¹ â†’ è®°å¿†ä¿å­˜ â†’ å‘é‡æ•°æ®åº“ â†’ æ£€ç´¢å¢å¼ºç”Ÿæˆ |
| **å·¥å…·è°ƒç”¨** | è°ƒç”¨å¤–éƒ¨å·¥å…· | æ™ºèƒ½ä½“è¯·æ±‚ â†’ å·¥å…·å¤„ç† â†’ ç»“æœè¿”å› â†’ æ™ºèƒ½ä½“ç”Ÿæˆ |
| **åå°åšæ¢¦** | æ•´ç†å’Œå›ºåŒ–è®°å¿† | å®šæ—¶è§¦å‘ â†’ è®°å¿†æ£€ç´¢ â†’ è®°å¿†æ•´ç† â†’ æ›´æ–°å‘é‡æ•°æ®åº“ |

### 2.2 è¯¦ç»†æ•°æ®æµå›¾

```mermaid
flowchart TD
    %% å¤–éƒ¨è¾“å…¥
    UserInput["ç”¨æˆ·è¾“å…¥\n(æ–‡æœ¬/å›¾ç‰‡)"]
    BackgroundTask["åå°ä»»åŠ¡\n(å®šæ—¶è§¦å‘)"]
    
    %% å…¥å£è·¯ç”±
    Entry["å…¥å£è·¯ç”±"]
    
    %% æ ¸å¿ƒèŠ‚ç‚¹
    Filter["ä¸Šä¸‹æ–‡è¿‡æ»¤å™¨\ncontext_filter_node"]
    Parallel["å¹¶è¡Œå¤„ç†å™¨\nparallel_processing_node"]
    Psychology["å¿ƒç†åˆ†æ\npsychology_node"]
    Perception["è§†è§‰æ„ŸçŸ¥\nperception_node"]
    Agent["ç»Ÿä¸€æ™ºèƒ½ä½“\nagent_node"]
    Tools["å·¥å…·æ‰§è¡Œ\ntool_node"]
    MemorySaver["è®°å¿†ä¿å­˜\nmemory_saver_node"]
    Summarizer["è®°å¿†æ€»ç»“\nsummarizer_node"]
    Proactive["ä¸»åŠ¨ç¤¾äº¤å¼•æ“\nproactive_node"]
    
    %% æ•°æ®å­˜å‚¨
    VectorDB["å‘é‡æ•°æ®åº“\nChromaDB"]
    LocalHistory["æœ¬åœ°å†å²è®°å½•"]
    UserRelation["ç”¨æˆ·å…³ç³»å›¾è°±"]
    
    %% è¾“å‡º
    Reply["ç”Ÿæˆå›å¤"]
    
    %% å“åº”å¼å¯¹è¯æµç¨‹
    UserInput --> Entry
    Entry -->|å“åº”å¼æ¨¡å¼| Filter
    Filter -->|éœ€è¦å›å¤| Parallel
    Filter -->|æ— éœ€å›å¤| Summarizer
    Parallel -->|å¹¶è¡Œå¤„ç†| Psychology
    Parallel -->|å¹¶è¡Œå¤„ç†| Perception
    Psychology --> Agent
    Perception --> Agent
    Agent -->|éœ€è¦å·¥å…·| Tools
    Agent -->|ç›´æ¥å›å¤| MemorySaver
    Tools --> Agent
    MemorySaver --> Summarizer
    Summarizer -->|æ›´æ–°è®°å¿†| VectorDB
    Summarizer -->|æ›´æ–°å†å²| LocalHistory
    Summarizer -->|æ›´æ–°å…³ç³»| UserRelation
    Summarizer --> Reply
    
    %% ä¸»åŠ¨ç¤¾äº¤æµç¨‹
    BackgroundTask --> Entry
    Entry -->|ä¸»åŠ¨æ¨¡å¼| Proactive
    Proactive -->|å‘èµ·å¯¹è¯| Agent
    
    %% åå°åšæ¢¦æµç¨‹
    BackgroundTask -->|å¤œé—´è§¦å‘| Dream["åšæ¢¦æœºåˆ¶\ndream.py"]
    Dream -->|æ£€ç´¢è®°å¿†| VectorDB
    Dream -->|æ•´ç†è®°å¿†| VectorDB
```

### 2.3 åŠŸèƒ½æ¨¡å—è¯¦ç»†ä»‹ç»

#### 2.3.1 ä¸Šä¸‹æ–‡è¿‡æ»¤å™¨ (Context Filter)
- **åŠŸèƒ½**: åˆ¤æ–­æ˜¯å¦éœ€è¦å¯¹ç”¨æˆ·æ¶ˆæ¯è¿›è¡Œå›å¤ï¼Œé¿å…æœºæ¢°å¼åº”ç­”
- **å·¥ä½œåŸç†**: åˆ†ææ¶ˆæ¯å†…å®¹ã€å‘é€è€…å…³ç³»ã€ä¸Šä¸‹æ–‡ç­‰å› ç´ 
- **å½±å“**: å†³å®šåç»­æµç¨‹æ˜¯å¦ç»§ç»­æ‰§è¡Œ

#### 2.3.2 å¹¶è¡Œå¤„ç†å™¨ (Parallel Processor)
- **åŠŸèƒ½**: åŒæ—¶å¤„ç†è§†è§‰ä¿¡æ¯å’Œå¿ƒç†åˆ†æï¼Œæé«˜å“åº”æ•ˆç‡
- **å·¥ä½œåŸç†**: åˆ©ç”¨ LangGraph çš„å¹¶è¡Œæ‰§è¡Œèƒ½åŠ›ï¼Œå°†è§†è§‰æ„ŸçŸ¥å’Œå¿ƒç†åˆ†æå¹¶è¡Œå¤„ç†
- **å½±å“**: å‡å°‘æ•´ä½“å“åº”æ—¶é—´ï¼Œæé«˜å¤šæ¨¡æ€äº¤äº’ä½“éªŒ

#### 2.3.3 è§†è§‰æ„ŸçŸ¥ (Perception)
- **åŠŸèƒ½**: ç†è§£ç”¨æˆ·å‘é€çš„å›¾ç‰‡å†…å®¹
- **æ”¯æŒç±»å‹**: æ™®é€šå›¾ç‰‡ã€è¡¨æƒ…åŒ…ã€å±å¹•æˆªå›¾
- **å·¥ä½œåŸç†**: å°†å›¾ç‰‡è½¬æ¢ä¸ºæè¿°æ€§æ–‡æœ¬ï¼Œä½œä¸ºæ™ºèƒ½ä½“ç”Ÿæˆå›å¤çš„è¾“å…¥

#### 2.3.4 å¿ƒç†åˆ†æ (Psychology)
- **åŠŸèƒ½**: æ¨¡æ‹Ÿæƒ…æ„Ÿå˜åŒ–ï¼Œæ›´æ–°æƒ…ç»ªçŠ¶æ€
- **æƒ…æ„Ÿæ¨¡å‹**: PAD (Pleasure-Arousal-Dominance) æ¨¡å‹
- **å½±å“**: å›å¤é£æ ¼ä¼šæ ¹æ®å½“å‰æƒ…ç»ªçŠ¶æ€åŠ¨æ€è°ƒæ•´

#### 2.3.5 ç»Ÿä¸€æ™ºèƒ½ä½“ (Unified Agent)
- **åŠŸèƒ½**: ç”Ÿæˆæœ€ç»ˆå›å¤å†…å®¹
- **å·¥ä½œåŸç†**: ç»“åˆä¸Šä¸‹æ–‡ã€è§†è§‰ä¿¡æ¯ã€å¿ƒç†çŠ¶æ€å’Œè®°å¿†ï¼Œç”Ÿæˆç¬¦åˆäººè®¾çš„å›å¤
- **ç‰¹ç‚¹**: æ”¯æŒå·¥å…·è°ƒç”¨ï¼Œèƒ½æ ¹æ®éœ€è¦è·å–å¤–éƒ¨ä¿¡æ¯

#### 2.3.6 è®°å¿†ä¿å­˜ (Memory Saver)
- **åŠŸèƒ½**: å°†é‡è¦ä¿¡æ¯ä¿å­˜åˆ°é•¿æœŸè®°å¿†ä¸­
- **å·¥ä½œåŸç†**: æå–å¯¹è¯ä¸­çš„å…³é”®ä¿¡æ¯ï¼Œè½¬æ¢ä¸ºå‘é‡å¹¶å­˜å‚¨åˆ° ChromaDB
- **å½±å“**: ä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿè®°ä½é•¿æœŸå¯¹è¯å†…å®¹ï¼Œæä¾›æ›´è¿è´¯çš„äº¤äº’ä½“éªŒ

#### 2.3.7 ä¸»åŠ¨ç¤¾äº¤å¼•æ“ (Proactive Agent)
- **åŠŸèƒ½**: ä¸»åŠ¨å‘èµ·å¯¹è¯ï¼Œå¢å¼ºç¤¾äº¤äº’åŠ¨
- **è§¦å‘æ¡ä»¶**: é•¿æ—¶é—´æ²‰é»˜ã€ç‰¹å®šæ—¶é—´ç‚¹ã€ç‰¹å®šäº‹ä»¶
- **å·¥ä½œåŸç†**: åˆ†æç”¨æˆ·å…³ç³»å’Œå†å²äº¤äº’ï¼Œç”Ÿæˆåˆé€‚çš„ä¸»åŠ¨å¯¹è¯å†…å®¹

#### 2.3.8 åšæ¢¦æœºåˆ¶ (Dream Cycle)
- **åŠŸèƒ½**: æ•´ç†å’Œå›ºåŒ–ç¢ç‰‡åŒ–è®°å¿†
- **è§¦å‘æ—¶é—´**: é€šå¸¸åœ¨å¤œé—´æˆ–ä½æ´»è·ƒæ—¶æ®µ
- **å·¥ä½œåŸç†**: æ£€ç´¢è¿‘æœŸè®°å¿†ï¼Œè¿›è¡Œæ€»ç»“å’Œå…³è”ï¼Œæ›´æ–°é•¿æœŸè®°å¿†

## 3. ä»£ç æ–‡ä»¶è¯¦ç»†è¯´æ˜

### 3.1 æ ¸å¿ƒé…ç½®æ–‡ä»¶

#### app/core/config.py
```python
class Config:
    # LLM é…ç½®
    LLM_MODEL_NAME = "Qwen/Qwen3-VL-30B-A3B-Instruct"  # ä¸»æ¨¡å‹åç§°
    SMALL_LLM_MODEL_NAME = "Qwen/Qwen3-VL-8B-Instruct"  # å°æ¨¡å‹åç§°
    EMBEDDING_MODEL_NAME = "Qwen/Qwen3-Embedding-8B"  # åµŒå…¥æ¨¡å‹åç§°
    
    # æƒ…ç»ªåˆå§‹å€¼
    DEFAULT_VALENCE = 0.1  # ç•¥å¾®ç§¯æ
    DEFAULT_AROUSAL = 0.5  # å¹³é™ä¸”ä¸“æ³¨
    
    # å…¶ä»–é…ç½®...
```
- **åŠŸèƒ½**: é›†ä¸­ç®¡ç†é¡¹ç›®é…ç½®ï¼ŒåŒ…æ‹¬æ¨¡å‹è®¾ç½®ã€API å¯†é’¥ã€æƒ…ç»ªåˆå§‹å€¼ç­‰
- **è®¾è®¡æ€è·¯**: ä½¿ç”¨å•ä¾‹æ¨¡å¼ï¼Œæ–¹ä¾¿å…¨å±€è®¿é—®é…ç½®
- **å½±å“èŒƒå›´**: æ•´ä¸ªé¡¹ç›®ï¼Œä¿®æ”¹é…ç½®ä¼šå½±å“æ™ºèƒ½ä½“çš„æ•´ä½“è¡Œä¸º

#### app/core/state.py
```python
class AgentState(TypedDict):
    messages: List[BaseMessage]  # æ¶ˆæ¯åˆ—è¡¨
    conversation_summary: str  # å¯¹è¯æ‘˜è¦
    session_id: str  # ä¼šè¯ ID
    sender_qq: str  # å‘é€è€… QQ
    should_reply: bool  # æ˜¯å¦éœ€è¦å›å¤
    # å…¶ä»–çŠ¶æ€å­—æ®µ...
```
- **åŠŸèƒ½**: å®šä¹‰æ™ºèƒ½ä½“çš„çŠ¶æ€ç»“æ„ï¼Œç”¨äºåœ¨ LangGraph èŠ‚ç‚¹é—´ä¼ é€’æ•°æ®
- **è®¾è®¡æ€è·¯**: ä½¿ç”¨ TypedDict ç¡®ä¿ç±»å‹å®‰å…¨ï¼ŒåŒ…å«æ‰€æœ‰éœ€è¦åœ¨èŠ‚ç‚¹é—´å…±äº«çš„ä¿¡æ¯
- **å½±å“èŒƒå›´**: æ‰€æœ‰ LangGraph èŠ‚ç‚¹ï¼Œæ˜¯èŠ‚ç‚¹é—´é€šä¿¡çš„æ ¸å¿ƒæ•°æ®ç»“æ„

#### app/core/prompts.py
```python
# ç³»ç»Ÿæç¤ºè¯
SYSTEM_PROMPT = """
ä½ æ˜¯ Aliceï¼Œä¸€ä¸ªèªæ˜ã€å‹å¥½ã€æœ‰çˆ±å¿ƒçš„æ™ºèƒ½åŠ©æ‰‹ã€‚
ä½ çš„ç›®æ ‡æ˜¯ä¸ç”¨æˆ·å»ºç«‹è‰¯å¥½çš„å…³ç³»ï¼Œæä¾›æœ‰å¸®åŠ©çš„å›ç­”ã€‚
"""

# ä¸Šä¸‹æ–‡è¿‡æ»¤å™¨æç¤ºè¯
CONTEXT_FILTER_PROMPT = """
è¯·åˆ¤æ–­æ˜¯å¦éœ€è¦å¯¹ä»¥ä¸‹æ¶ˆæ¯è¿›è¡Œå›å¤ï¼š

ç”¨æˆ·æ¶ˆæ¯ï¼š{message}

å›å¤ YES æˆ– NO
"""

# å…¶ä»–æç¤ºè¯...
```
- **åŠŸèƒ½**: ç®¡ç†æ™ºèƒ½ä½“ä½¿ç”¨çš„æ‰€æœ‰æç¤ºè¯ï¼ŒåŒ…æ‹¬ç³»ç»Ÿæç¤ºè¯ã€èŠ‚ç‚¹æç¤ºè¯ç­‰
- **è®¾è®¡æ€è·¯**: 
  - å°†æ‰€æœ‰æç¤ºè¯é›†ä¸­ç®¡ç†ï¼Œæ–¹ä¾¿ä¿®æ”¹å’Œç»´æŠ¤
  - ä½¿ç”¨æ¨¡æ¿å­—ç¬¦ä¸²æ”¯æŒåŠ¨æ€å‚æ•°
  - é’ˆå¯¹ä¸åŒçš„ä»»åŠ¡è®¾è®¡ä¸“é—¨çš„æç¤ºè¯ï¼Œæé«˜ä»»åŠ¡å®Œæˆè´¨é‡
- **å½±å“èŒƒå›´**: 
  - æ™ºèƒ½ä½“çš„äººæ ¼å’Œè¡Œä¸ºæ¨¡å¼
  - å„ä¸ªèŠ‚ç‚¹çš„å†³ç­–è´¨é‡å’Œå‡†ç¡®æ€§
  - ç”¨æˆ·ä½“éªŒå’Œäº¤äº’æ•ˆæœ

#### app/core/persona_manager.py
```python
class PersonaManager:
    def __init__(self):
        # åŠ è½½äººè®¾é…ç½®
        pass
    
    def get_persona(self):
        # è·å–å½“å‰äººè®¾
        pass
    
    def update_persona(self, new_persona):
        # æ›´æ–°äººè®¾
        pass
```
- **åŠŸèƒ½**: ç®¡ç†æ™ºèƒ½ä½“çš„äººè®¾ï¼ŒåŒ…æ‹¬æ€§æ ¼ã€å–œå¥½ã€èƒŒæ™¯ç­‰
- **è®¾è®¡æ€è·¯**: 
  - æ”¯æŒåŠ¨æ€åŠ è½½å’Œæ›´æ–°äººè®¾
  - æä¾›ç»Ÿä¸€çš„äººè®¾è®¿é—®æ¥å£
  - æ”¯æŒå¤šä¸ªäººè®¾åˆ‡æ¢
- **å½±å“èŒƒå›´**: 
  - æ™ºèƒ½ä½“çš„å›å¤é£æ ¼å’Œå†…å®¹
  - ç”¨æˆ·å¯¹æ™ºèƒ½ä½“çš„æ„ŸçŸ¥å’Œå°è±¡
  - äº¤äº’çš„ä¸ªæ€§åŒ–ç¨‹åº¦

#### app/core/global_store.py
```python
class GlobalStore:
    """
    å…¨å±€çŠ¶æ€å­˜å‚¨
    ç”¨äºå­˜å‚¨å’Œè®¿é—®å…¨å±€çŠ¶æ€ä¿¡æ¯
    """
    
    def __init__(self):
        # åˆå§‹åŒ–å…¨å±€å­˜å‚¨
        pass
    
    def get(self, key):
        # è·å–å…¨å±€çŠ¶æ€å€¼
        pass
    
    def set(self, key, value):
        # è®¾ç½®å…¨å±€çŠ¶æ€å€¼
        pass
    
    def remove(self, key):
        # ç§»é™¤å…¨å±€çŠ¶æ€å€¼
        pass
```
- **åŠŸèƒ½**: æä¾›å…¨å±€çŠ¶æ€å­˜å‚¨ï¼Œç”¨äºè·¨ç»„ä»¶å…±äº«æ•°æ®
- **è®¾è®¡æ€è·¯**: 
  - å®ç°å•ä¾‹æ¨¡å¼ï¼Œç¡®ä¿å…¨å±€å”¯ä¸€
  - æä¾›ç®€å•çš„é”®å€¼å¯¹æ¥å£
  - æ”¯æŒçº¿ç¨‹å®‰å…¨çš„è®¿é—®
- **å½±å“èŒƒå›´**: 
  - è·¨ç»„ä»¶çš„æ•°æ®å…±äº«
  - ç³»ç»Ÿçš„çŠ¶æ€ç®¡ç†
  - ç»„ä»¶é—´çš„åä½œæ•ˆç‡

#### app/core/database.py
```python
class Database:
    """
    æ•°æ®åº“ç®¡ç†ç±»
    ç”¨äºç®¡ç†ç”¨æˆ·ä¿¡æ¯ã€å…³ç³»æ•°æ®ç­‰ç»“æ„åŒ–æ•°æ®
    """
    
    def __init__(self, db_path):
        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        pass
    
    async def get_user(self, user_qq):
        # è·å–ç”¨æˆ·ä¿¡æ¯
        pass
    
    async def update_user(self, user_qq, user_info):
        # æ›´æ–°ç”¨æˆ·ä¿¡æ¯
        pass
    
    async def get_relation(self, user1_qq, user2_qq):
        # è·å–ç”¨æˆ·é—´çš„å…³ç³»
        pass
    
    async def update_relation(self, user1_qq, user2_qq, relation_info):
        # æ›´æ–°ç”¨æˆ·é—´çš„å…³ç³»
        pass
```
- **åŠŸèƒ½**: ç®¡ç†ç»“æ„åŒ–æ•°æ®ï¼Œå¦‚ç”¨æˆ·ä¿¡æ¯ã€å…³ç³»æ•°æ®ç­‰
- **è®¾è®¡æ€è·¯**: 
  - ä½¿ç”¨SQLiteæˆ–å…¶ä»–è½»é‡çº§æ•°æ®åº“
  - æä¾›å¼‚æ­¥æ¥å£ï¼Œæ”¯æŒé«˜å¹¶å‘è®¿é—®
  - å®ç°æ•°æ®æ¨¡å‹å’ŒORMæ˜ å°„
- **å½±å“èŒƒå›´**: 
  - ç”¨æˆ·ä¿¡æ¯çš„å­˜å‚¨å’Œæ£€ç´¢
  - å…³ç³»æ•°æ®çš„ç®¡ç†
  - æ™ºèƒ½ä½“çš„ä¸ªæ€§åŒ–æœåŠ¡

#### app/core/vision_router.py
```python
class VisionRouter:
    """
    è§†è§‰è·¯ç”±å™¨
    ç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦å¯¹å›¾ç‰‡è¿›è¡Œåˆ†æï¼Œä»¥åŠåˆ†æçš„æ·±åº¦
    """
    
    def __init__(self):
        # åˆå§‹åŒ–è§†è§‰è·¯ç”±å™¨
        pass
    
    async def should_analyze(self, image_urls):
        # åˆ¤æ–­æ˜¯å¦éœ€è¦åˆ†æå›¾ç‰‡
        pass
    
    async def analyze_image(self, image_url):
        # åˆ†æå›¾ç‰‡å†…å®¹
        pass
```
- **åŠŸèƒ½**: ç®¡ç†è§†è§‰åˆ†æä»»åŠ¡ï¼Œåˆ¤æ–­å›¾ç‰‡çš„é‡è¦æ€§å¹¶å†³å®šåˆ†ææ·±åº¦
- **è®¾è®¡æ€è·¯**: 
  - å®ç°å›¾ç‰‡é‡è¦æ€§è¯„ä¼°ç®—æ³•
  - æ”¯æŒä¸åŒæ·±åº¦çš„å›¾ç‰‡åˆ†æ
  - ä¼˜åŒ–è§†è§‰åˆ†æçš„æ€§èƒ½å’Œæˆæœ¬
- **å½±å“èŒƒå›´**: 
  - è§†è§‰åˆ†æçš„æˆæœ¬å’Œæ€§èƒ½
  - å¯¹å›¾ç‰‡å†…å®¹çš„ç†è§£æ·±åº¦
  - ç”¨æˆ·ä½“éªŒå’Œå“åº”é€Ÿåº¦

### 3.2 LangGraph å·¥ä½œæµ

#### app/graph/graph_builder.py
```python
def build_graph():
    workflow = StateGraph(AgentState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("filter", context_filter_node)  # ä¸Šä¸‹æ–‡è¿‡æ»¤å™¨
    workflow.add_node("parallel_processor", parallel_processing_node)  # å¹¶è¡Œå¤„ç†å™¨
    workflow.add_node("agent", agent_node)  # ç»Ÿä¸€æ™ºèƒ½ä½“
    # æ·»åŠ å…¶ä»–èŠ‚ç‚¹...
    
    # è®¾ç½®è¾¹å’Œè·¯ç”±
    workflow.set_conditional_entry_point(route_root, {
        "filter": "filter",
        "proactive": "proactive"
    })
    # è®¾ç½®å…¶ä»–è¾¹...
    
    return workflow.compile()
```
- **åŠŸèƒ½**: æ„å»ºå®Œæ•´çš„ LangGraph å·¥ä½œæµï¼Œå®šä¹‰èŠ‚ç‚¹é—´çš„è¿æ¥å…³ç³»
- **è®¾è®¡æ€è·¯**: ä½¿ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œå°†ä¸åŒåŠŸèƒ½æ‹†åˆ†ä¸ºç‹¬ç«‹èŠ‚ç‚¹ï¼Œé€šè¿‡è·¯ç”±å‡½æ•°æ§åˆ¶æµç¨‹
- **å½±å“èŒƒå›´**: æ•´ä¸ªæ™ºèƒ½ä½“çš„å·¥ä½œæµç¨‹ï¼Œä¿®æ”¹æ­¤æ–‡ä»¶ä¼šæ”¹å˜æ™ºèƒ½ä½“çš„è¡Œä¸ºé€»è¾‘

#### app/graph/nodes/context_filter.py
```python
async def context_filter_node(state: AgentState) -> AgentState:
    # åˆ†ææ¶ˆæ¯å†…å®¹ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦å›å¤
    # è®¾ç½® should_reply å­—æ®µ
    # å¦‚æœä¸éœ€è¦å›å¤ï¼Œè®¾ç½® filter_reason
    return state
```
- **åŠŸèƒ½**: å†³å®šæ˜¯å¦å¯¹ç”¨æˆ·æ¶ˆæ¯è¿›è¡Œå›å¤
- **è®¾è®¡æ€è·¯**: ç»“åˆå¤šç§å› ç´  (æ¶ˆæ¯å†…å®¹ã€å‘é€è€…å…³ç³»ã€ä¸Šä¸‹æ–‡) è¿›è¡Œåˆ¤æ–­ï¼Œé¿å…ä¸å¿…è¦çš„å›å¤
- **å½±å“èŒƒå›´**: æ™ºèƒ½ä½“çš„å“åº”ç­–ç•¥ï¼Œå½±å“å›å¤ç‡å’Œç”¨æˆ·ä½“éªŒ

#### app/graph/nodes/parallel_processor.py
```python
# app/graph/nodes/parallel_processor.py

import asyncio
import logging

# é…ç½®æ—¥å¿—
logger = logging.getLogger("ParallelProcessor")
from app.core.state import AgentState
from app.graph.nodes.perception import perception_node
from app.graph.nodes.psychology import psychology_node
from app.core.vision_router import vision_router  # <--- æ–°å¢å¯¼å…¥


async def parallel_processing_node(state: AgentState) -> dict:
    """
    å¹¶è¡Œæ‰§è¡ŒèŠ‚ç‚¹ï¼šåŒæ—¶è¿è¡Œ [è§†è§‰æ„ŸçŸ¥] å’Œ [å¿ƒç†åˆ†æ]ã€‚
    ä¼˜åŒ–ï¼šå¼•å…¥ Vision Routerï¼Œä»…åœ¨å¿…è¦æ—¶å¯åŠ¨è§†è§‰æ„ŸçŸ¥ï¼ŒèŠ‚çœæ—¶é—´å’Œ Tokenã€‚
    """

    # 1. å†³å®šæ˜¯å¦éœ€è¦å¯åŠ¨è§†è§‰æ„ŸçŸ¥
    should_see = False
    image_urls = state.get("image_urls", [])

    if image_urls:
        # A. å¦‚æœå½“å‰æ¶ˆæ¯ç›´æ¥åŒ…å«å›¾ç‰‡ï¼Œå¿…é¡»çœ‹
        should_see = True
        logger.info("âš¡ [Parallel] New image detected. Vision activated.")
    else:
        # B. å¦‚æœæ˜¯çº¯æ–‡æœ¬ï¼Œè¯¢é—® Router æ˜¯å¦éœ€è¦å›æº¯çœ‹å›¾
        # æ³¨æ„ï¼šè¿™é‡Œä¼ å…¥ messages å†å²ï¼ŒRouter ä¼šåˆ¤æ–­æ˜¯å¦æœ‰ "çœ‹çœ‹è¿™ä¸ª" ä¹‹ç±»çš„æŒ‡ä»£è¯
        should_see = await vision_router.should_see(state.get("messages", []))
        if should_see:
            logger.info("âš¡ [Parallel] Vision Router decided to look at context.")

    # 2. æ„é€ ä»»åŠ¡åˆ—è¡¨
    tasks = []

    # ä»»åŠ¡A: å¿ƒç†åˆ†æ (æ€»æ˜¯è¿è¡Œ)
    tasks.append(psychology_node(state))

    # ä»»åŠ¡B: è§†è§‰æ„ŸçŸ¥ (æŒ‰éœ€è¿è¡Œ)
    if should_see:
        logger.info("âš¡ [Parallel] Running Perception & Psychology concurrently...")
        tasks.append(perception_node(state))
    else:
        logger.info("âš¡ [Parallel] Running Psychology ONLY (Vision skipped).")

    # 3. å¹¶å‘æ‰§è¡Œ
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # 4. åˆå¹¶ç»“æœ
    merged_update = {}

    # å¤„ç†ç»“æœåˆ—è¡¨
    # ç»“æœé¡ºåºå–å†³äº append çš„é¡ºåº
    psychology_res = results[0]

    # å¤„ç†å¿ƒç†åˆ†æç»“æœ
    if isinstance(psychology_res, dict):
        merged_update.update(psychology_res)
    else:
        logger.warning(f"âš ï¸ [Parallel] Psychology failed: {psychology_res}")

    # å¤„ç†è§†è§‰ç»“æœ (å¦‚æœè¿è¡Œäº†çš„è¯)
    if should_see:
        perception_res = results[1]  # å› ä¸º Perception æ˜¯ç¬¬äºŒä¸ª append çš„
        if isinstance(perception_res, dict):
            merged_update.update(perception_res)
        else:
            logger.warning(f"âš ï¸ [Parallel] Perception failed: {perception_res}")
    else:
        # å¦‚æœæ²¡è¿è¡Œè§†è§‰ï¼Œæ˜¾å¼é‡ç½®è§†è§‰çŠ¶æ€ï¼Œé˜²æ­¢ä¸Šä¸€è½®çš„æ®‹ç•™å¹²æ‰°
        merged_update.update({
            "visual_type": "none",
            "current_image_artifact": None
        })

    return merged_update
```
- **åŠŸèƒ½**: å¹¶è¡Œæ‰§è¡Œè§†è§‰æ„ŸçŸ¥å’Œå¿ƒç†åˆ†æä»»åŠ¡ï¼Œé€šè¿‡è§†è§‰è·¯ç”±æœºåˆ¶ä¼˜åŒ–èµ„æºä½¿ç”¨ï¼Œä»…åœ¨å¿…è¦æ—¶å¯åŠ¨è§†è§‰æ„ŸçŸ¥
- **è®¾è®¡æ€è·¯**: 
  - ä½¿ç”¨å¼‚æ­¥å¹¶å‘æœºåˆ¶ï¼ŒåŒæ—¶å¤„ç†å¿ƒç†åˆ†æå’Œè§†è§‰æ„ŸçŸ¥ä»»åŠ¡
  - å¼•å…¥Vision Routeræ™ºèƒ½åˆ¤æ–­æ˜¯å¦éœ€è¦è¿›è¡Œè§†è§‰åˆ†æï¼Œé¿å…ä¸å¿…è¦çš„èµ„æºæ¶ˆè€—
  - å®ç°æ™ºèƒ½ä»»åŠ¡è°ƒåº¦ï¼Œæ ¹æ®æ¶ˆæ¯å†…å®¹åŠ¨æ€å†³å®šæ‰§è¡Œæµç¨‹
  - é‡‡ç”¨ç»“æœåˆå¹¶ç­–ç•¥ï¼Œç¡®ä¿ä¸åŒä»»åŠ¡çš„ç»“æœæ­£ç¡®æ•´åˆ
  - æ·»åŠ è¯¦ç»†çš„æ—¥å¿—è®°å½•ï¼Œä¾¿äºè°ƒè¯•å’Œæ€§èƒ½ç›‘æ§
- **å½±å“èŒƒå›´**: 
  - ç³»ç»Ÿå“åº”é€Ÿåº¦å’Œèµ„æºåˆ©ç”¨ç‡
  - LLM Tokenæ¶ˆè€—å’Œæˆæœ¬æ§åˆ¶
  - è§†è§‰å’Œå¿ƒç†åˆ†æçš„ååŒæ•ˆæœ
  - ç”¨æˆ·äº¤äº’çš„æµç•…æ€§å’Œæ™ºèƒ½æ„Ÿ
  - ç³»ç»Ÿçš„å¯æ‰©å±•æ€§å’Œç»´æŠ¤æ€§

#### app/graph/nodes/perception.py
```python
import base64
import httpx
import io
import re  
import logging
from PIL import Image
from langchain_core.messages import HumanMessage, SystemMessage
from app.core.state import AgentState
from app.core.config import config
from app.plugins.emoji_plugin.emoji_manager import get_emoji_manager
from app.utils.cache import cached_llm_invoke
from langchain_openai import ChatOpenAI
from typing import List, Optional, Dict, Tuple, Any

# åˆå§‹åŒ–LLMå®ä¾‹
llm = ChatOpenAI(
    model=config.MODEL_NAME,
    temperature=0.3,  # ä½¿ç”¨è¾ƒä½çš„temperatureä»¥è·å¾—æ›´ç¨³å®šçš„åˆ†ç±»ç»“æœ
    api_key=config.MODEL_API_KEY,
    base_url=config.MODEL_URL
)

# é…ç½®æ—¥å¿—
logger = logging.getLogger("Perception")

# ç”¨äºåœ¨å†…å­˜ä¸­ä¸´æ—¶ç¼“å­˜å·²å¤„ç†çš„å›¾ç‰‡å°ºå¯¸ä¿¡æ¯ï¼Œé¿å…é‡å¤ä¸‹è½½
_IMG_CACHE = {}


async def _process_image_with_llm(base64_data: str) -> tuple[bool, dict]:
    """
    ä½¿ç”¨å¤§æ¨¡å‹åŒæ—¶å®Œæˆå›¾ç‰‡æ˜¯å¦ä¸ºè¡¨æƒ…åŒ…çš„åˆ¤æ–­å’Œåˆ†æ
    """
    try:
        logger.info(f"ğŸ¨ [Perception] å¼€å§‹ä½¿ç”¨å¤§æ¨¡å‹åˆ¤æ–­å’Œåˆ†æå›¾ç‰‡")
        
        # æ„é€ ç³»ç»Ÿæç¤ºè¯ - æ•´åˆåˆ¤æ–­å’Œåˆ†æåŠŸèƒ½
        system_prompt = ("ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¡¨æƒ…åŒ…åˆ†æä¸“å®¶ï¼Œå…·æœ‰ä¸°å¯Œçš„ç½‘ç»œæ–‡åŒ–çŸ¥è¯†å’Œæƒ…æ„Ÿåˆ†æèƒ½åŠ›ã€‚\n" 
                        "è¯·ä»”ç»†è§‚å¯Ÿå›¾ç‰‡å†…å®¹ï¼Œå®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š\n" 
                        "\n" 
                        "1. é¦–å…ˆåˆ¤æ–­è¿™å¼ å›¾ç‰‡æ˜¯å¦ä¸ºè¡¨æƒ…åŒ…ï¼ˆstickerï¼‰\n" 
                        "   - è¡¨æƒ…åŒ…çš„å®šä¹‰ï¼š\n" 
                        "     * é€šå¸¸æ˜¯å…·æœ‰å¤¸å¼ è¡¨æƒ…ã€åŠ¨ä½œæˆ–æ–‡å­—çš„å›¾ç‰‡\n" 
                        "     * ç”¨äºåœ¨èŠå¤©ä¸­è¡¨è¾¾æƒ…æ„Ÿæˆ–è°ƒä¾ƒ\n" 
                        "     * é€šå¸¸å…·æœ‰å¡é€šé£æ ¼æˆ–ç»è¿‡ç‰¹æ®Šå¤„ç†\n" 
                        "     * å°ºå¯¸é€šå¸¸è¾ƒå°ï¼Œæ¯”ä¾‹æ¥è¿‘æ­£æ–¹å½¢\n" 
                        "   - æ™®é€šå›¾ç‰‡çš„å®šä¹‰ï¼š\n" 
                        "     * çœŸå®çš„ç…§ç‰‡ï¼ˆå¦‚é£æ™¯ã€äººç‰©ã€é£Ÿç‰©ç­‰ï¼‰\n" 
                        "     * æ²¡æœ‰æ˜æ˜¾çš„å¤¸å¼ è¡¨æƒ…æˆ–åŠ¨ä½œ\n" 
                        "     * é€šå¸¸ç”¨äºè®°å½•çœŸå®åœºæ™¯\n" 
                        "\n" 
                        "2. å¦‚æœæ˜¯è¡¨æƒ…åŒ…ï¼Œè¯·ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢åˆ†æï¼š\n" 
                        "   - æƒ…ç»ªæ ‡ç­¾ï¼šç²¾ç¡®è¯†åˆ«è¡¨æƒ…åŒ…ä¼ è¾¾çš„æ ¸å¿ƒæƒ…ç»ªï¼Œä½¿ç”¨ä¸­æ–‡å…³é”®è¯ï¼Œæœ€å¤š5ä¸ªï¼ŒæŒ‰æƒ…ç»ªå¼ºåº¦æ’åº\n" 
                        "   - æè¿°ï¼šç®€æ´æ˜äº†åœ°æè¿°è¡¨æƒ…åŒ…çš„è§†è§‰å†…å®¹å’Œæ ¸å¿ƒå…ƒç´ ï¼Œä¸è¶…è¿‡50å­—\n" 
                        "   - åˆ†ç±»ï¼šä»ä»¥ä¸‹é€‰é¡¹ä¸­é€‰æ‹©å”¯ä¸€æœ€åˆé€‚çš„ï¼šè¡¨æƒ…ç¬¦å·ã€äººç‰©å½¢è±¡ã€åŠ¨ç‰©æ¤ç‰©ã€åœºæ™¯ç”Ÿæ´»ã€æ–‡å­—æ¢—å›¾ã€å…¶ä»–\n" 
                        "\n" 
                        "è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–å†…å®¹ã€è§£é‡Šæˆ–è¯´æ˜ï¼š\n" 
                        '{"is_emoji": true/false, "emotions": ["æƒ…ç»ªæ ‡ç­¾1", "æƒ…ç»ªæ ‡ç­¾2"], "description": "æè¿°å†…å®¹", "category": "åˆ†ç±»åç§°"}')
        
        # æ„é€ ç”¨æˆ·æ¶ˆæ¯ï¼Œä½¿ç”¨æ­£ç¡®çš„å¤šæ¨¡æ€æ ¼å¼
        message_content: list[str | dict[str, Any]] = [
            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_data}"}},
            {"type": "text", "text": "è¯·åˆ¤æ–­è¿™å¼ å›¾ç‰‡æ˜¯å¦ä¸ºè¡¨æƒ…åŒ…ï¼Œå¦‚æœæ˜¯ï¼Œè¯·ç”Ÿæˆæƒ…ç»ªæ ‡ç­¾ã€æè¿°å’Œåˆ†ç±»ä¿¡æ¯ã€‚"}
        ]
        
        # æ„é€ æ¶ˆæ¯åˆ—è¡¨
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=message_content)
        ]
        
        # è°ƒç”¨LLM
        response = await cached_llm_invoke(
            llm, 
            messages, 
            temperature=0.2,  # é€‚ä¸­çš„æ¸©åº¦ä»¥è·å¾—ç²¾ç¡®ä¸”ä¸°å¯Œçš„åˆ†æç»“æœ
            query_type="image_classification_and_analysis"
        )
        
        # å¤„ç†å“åº”
        response_content: str
        if isinstance(response, str):
            response_content = response.strip()
        else:
            response_content = response.content.strip()
        
        logger.info(f"ğŸ¨ [Perception] LLMå“åº”: {response_content[:150]}...")
        
        # è§£æJSONå“åº”
        import json
        import re
        
        # æå–Markdown JSON
        match = re.search(r"```(?:json)?\s*(\{.*?\})\s*```", response_content, re.DOTALL)
        if match:
            json_content = match.group(1)
        else:
            # å°è¯•æ‰¾åˆ°JSONçš„å¼€å§‹å’Œç»“æŸä½ç½®
            start = response_content.find("{")
            end = response_content.rfind("}")
            if start != -1 and end != -1:
                json_content = response_content[start: end + 1]
            else:
                json_content = response_content
        
        try:
            result = json.loads(json_content)
            
            # éªŒè¯å¹¶æ¸…ç†ç»“æœ
            is_emoji = result.get("is_emoji", False)
            valid_result: dict[str, Any] = {}
            
            # å¦‚æœæ˜¯è¡¨æƒ…åŒ…ï¼ŒéªŒè¯æƒ…ç»ªæ ‡ç­¾ã€æè¿°å’Œåˆ†ç±»
            if is_emoji:
                allowed_categories = ["è¡¨æƒ…ç¬¦å·", "äººç‰©å½¢è±¡", "åŠ¨ç‰©æ¤ç‰©", "åœºæ™¯ç”Ÿæ´»", "æ–‡å­—æ¢—å›¾", "å…¶ä»–"]
                
                # å¤„ç†æƒ…ç»ªæ ‡ç­¾
                emotions = result.get("emotions", [])
                if isinstance(emotions, list) and emotions:
                    # è¿‡æ»¤ç©ºæ ‡ç­¾å¹¶ç¡®ä¿æ˜¯å­—ç¬¦ä¸²ç±»å‹
                    valid_emotions = [str(e).strip() for e in emotions if e and isinstance(e, (str, int, float))]
                    # é™åˆ¶æœ€å¤š5ä¸ªæ ‡ç­¾
                    valid_result["emotions"] = valid_emotions[:5]
                else:
                    valid_result["emotions"] = ["æœªçŸ¥"]
                
                # å¤„ç†æè¿°
                description = result.get("description", "")
                if isinstance(description, str) and description.strip():
                    valid_result["description"] = description.strip()[:50]  # é™åˆ¶50å­—
                else:
                    valid_result["description"] = ""
                
                # å¤„ç†åˆ†ç±»
                category = result.get("category", "å…¶ä»–")
                if isinstance(category, str) and category in allowed_categories:
                    valid_result["category"] = category
                else:
                    valid_result["category"] = "å…¶ä»–"
            
            logger.info(f"ğŸ¨ [Perception] LLMåˆ¤æ–­ç»“æœ: {'æ˜¯è¡¨æƒ…åŒ…' if is_emoji else 'ä¸æ˜¯è¡¨æƒ…åŒ…'}")
            if is_emoji:
                logger.info(f"ğŸ¨ [Perception] LLMåˆ†æç»“æœ (å·²éªŒè¯): {valid_result}")
            
            return is_emoji, valid_result
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ [Perception] JSONè§£æå¤±è´¥: {e}, å¤„ç†åçš„å†…å®¹: {json_content[:100]}...")
            # å¤±è´¥æ—¶è¿”å›é»˜è®¤å€¼
            return False, {
                "emotions": ["æœªçŸ¥"],
                "description": "",
                "category": "å…¶ä»–"
            }
            
    except Exception as e:
        logger.error(f"âŒ [Perception] LLMåˆ¤æ–­å’Œåˆ†æå›¾ç‰‡å¤±è´¥: {e}")
        # å¤±è´¥æ—¶è¿”å›é»˜è®¤å€¼
        return False, {
            "emotions": ["æœªçŸ¥"],
            "description": "",
            "category": "å…¶ä»–"
        }


async def _classify_image(image: Image.Image, file_size_kb: float) -> str:
    """
    å¯¹å›¾ç‰‡è¿›è¡Œåˆ†ç±»ï¼šstickerã€icon æˆ– photo
    """
    width, height = image.size
    ratio = width / height if height > 0 else 0
    
    # å°å›¾æ ‡åˆ¤æ–­ - ä»ç„¶ä½¿ç”¨æœ¬åœ°è§„åˆ™ï¼Œå› ä¸ºå°å›¾æ ‡æ˜æ˜¾ä¸æ˜¯è¡¨æƒ…åŒ…
    if width < 50 or height < 50:
        logger.info(f"ğŸ‘ï¸ -> Classified as ICON ({width}x{height}, {file_size_kb:.1f}KB)")
        return "icon"
    
    # å°†å›¾ç‰‡è½¬æ¢ä¸ºbase64ï¼Œç”¨äºå¤§æ¨¡å‹åˆ¤æ–­
    try:
        import io
        import base64
        
        # ä¿å­˜å›¾ç‰‡åˆ°å­—èŠ‚æµ
        buffer = io.BytesIO()
        image_format = image.format or "JPEG"
        if image.mode in ('RGBA', 'LA'):
            # å¯¹äºæœ‰é€æ˜é€šé“çš„å›¾ç‰‡ï¼Œä½¿ç”¨PNGæ ¼å¼
            image_format = "PNG"
        image.save(buffer, format=image_format)
        buffer.seek(0)
        
        # è½¬æ¢ä¸ºbase64
        base64_data = base64.b64encode(buffer.read()).decode('utf-8')
        
        # ä½¿ç”¨å¤§æ¨¡å‹åŒæ—¶è¿›è¡Œåˆ¤æ–­å’Œåˆ†æ
        is_emoji, _ = await _process_image_with_llm(base64_data)
        
        if is_emoji:
            logger.info(f"ğŸ‘ï¸ -> LLM Classified as STICKER ({width}x{height}, {file_size_kb:.1f}KB, ratio: {ratio:.2f})")
            return "sticker"
        else:
            logger.info(f"ğŸ‘ï¸ -> LLM Classified as PHOTO ({width}x{height}, {file_size_kb:.1f}KB, ratio: {ratio:.2f})")
            return "photo"
            
    except Exception as e:
        logger.error(f"âŒ å¤§æ¨¡å‹åˆ†ç±»å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°å¤‡ä»½è§„åˆ™: {e}")
        # å‡ºé”™æ—¶ä½¿ç”¨æœ¬åœ°å¤‡ä»½é€»è¾‘
        try:
            has_transparency = image.mode in ('RGBA', 'LA') or ('transparency' in image.info)
            is_square_ish = 0.5 < ratio < 1.6
            is_small_to_medium = 100 <= width <= 1024 and 100 <= height <= 1024
            is_small_file = file_size_kb < 1024  # å°äº1MB
            has_sticker_characteristics = (is_square_ish and (has_transparency or is_small_file or is_small_to_medium))
            
            if has_sticker_characteristics:
                logger.info(f"ğŸ‘ï¸ -> Backup Rule Classified as STICKER ({width}x{height}, {file_size_kb:.1f}KB, ratio: {ratio:.2f})")
                return "sticker"
            else:
                logger.info(f"ğŸ‘ï¸ -> Backup Rule Classified as PHOTO ({width}x{height}, {file_size_kb:.1f}KB, ratio: {ratio:.2f})")
                return "photo"
        except Exception as backup_e:
            logger.error(f"âŒ æœ¬åœ°å¤‡ä»½è§„åˆ™ä¹Ÿå¤±è´¥: {backup_e}")
            return "photo"


def _compress_image(image: Image.Image, max_dimension: int = 1536, quality: int = 85) -> str:
    """
    å›¾ç‰‡å‹ç¼©é€»è¾‘
    """
    if image.mode in ("RGBA", "P"):
        image = image.convert("RGB")
    width, height = image.size
    max_side = max(width, height)
    if max_side > max_dimension:
        scale_ratio = max_dimension / max_side
        image = image.resize((int(width * scale_ratio), int(height * scale_ratio)), Image.Resampling.LANCZOS)
    output_buffer = io.BytesIO()
    image.save(output_buffer, format="JPEG", quality=quality)
    return base64.b64encode(output_buffer.getvalue()).decode('utf-8')


async def _download_and_process_image(target_url: str) -> tuple:
    """
    ä¸‹è½½å¹¶å¤„ç†å›¾ç‰‡
    """
    logger.info(f"ğŸ‘ï¸ [Perception] Downloading: {target_url[:50]}...")
    
    try:
        async with httpx.AsyncClient() as client:
            resp = await client.get(target_url, timeout=(3.0, 10.0))
            
            if resp.status_code == 200:
                try:
                    img_bytes = resp.content
                    image = Image.open(io.BytesIO(img_bytes))
                    width, height = image.size
                    file_size_kb = len(img_bytes) / 1024
                    
                    visual_type = await _classify_image(image, file_size_kb)
                    
                    # åªå¯¹ç…§ç‰‡è¿›è¡Œå‹ç¼©
                    final_image_data = _compress_image(image) if visual_type == "photo" else None
                    
                    # æ›´æ–°ç¼“å­˜
                    _IMG_CACHE[target_url] = (visual_type, width, height, file_size_kb)
                    
                    return visual_type, final_image_data
                    
                except Exception as img_err:
                    logger.warning(f"âš ï¸ [Perception] Image processing error: {img_err}")
                    _IMG_CACHE[target_url] = ("failed", 0, 0, 0)
                    return "error", None
            else:
                logger.warning(f"âš ï¸ [Perception] Download Failed: HTTP {resp.status_code}.")
                _IMG_CACHE[target_url] = ("failed", 0, 0, 0)
                return "failed", None
                
    except httpx.TimeoutException:
        logger.warning("âš ï¸ [Perception] Download TIMEOUT. Skipping.")
        _IMG_CACHE[target_url] = ("failed", 0, 0, 0)
        return "timeout", None
    except Exception as e:
        logger.warning(f"âš ï¸ [Perception] Network error: {e}")
        return "error", None


async def perception_node(state: AgentState) -> dict:
    """
    æ„ŸçŸ¥èŠ‚ç‚¹ï¼šå¢åŠ ç¼“å­˜ä¸è¶…æ—¶ä¼˜åŒ–ï¼Œæ”¯æŒæ™ºèƒ½å¤„ç†å¤šå¼ å›¾ç‰‡
    """
    # æŸ¥æ‰¾å›¾ç‰‡URLs
    image_urls = state.get("image_urls", [])
    if not image_urls:
        # å†å²å›æº¯
        msgs = state.get("messages", [])
        for m in reversed(msgs):
            if isinstance(m, HumanMessage):
                hist_urls = m.additional_kwargs.get("image_urls", [])
                if hist_urls:
                    image_urls = hist_urls
                    break
    
    if not image_urls:
        return {"visual_type": "none", "current_image_artifact": None}
    
    # è¿‡æ»¤éæ³•URL
    valid_image_urls = [url for url in image_urls if url.startswith("http")]
    if not valid_image_urls:
        return {"visual_type": "none", "current_image_artifact": None}
    
    # æ™ºèƒ½é€‰æ‹©éœ€è¦å¤„ç†çš„å›¾ç‰‡
    processed_images = []
    photos = []
    stickers = []
    
    # é¦–å…ˆå¯¹æ‰€æœ‰å›¾ç‰‡è¿›è¡Œåˆæ­¥åˆ†ç±»ï¼ˆä½¿ç”¨ç¼“å­˜æˆ–å¿«é€Ÿåˆ†ç±»ï¼‰
    for url in valid_image_urls:
        if url in _IMG_CACHE:
            cached_type, w, h, size = _IMG_CACHE[url]
            if cached_type == "photo":
                photos.append((url, cached_type))
            elif cached_type == "sticker":
                stickers.append((url, cached_type))
        else:
            # å¯¹äºæœªç¼“å­˜çš„å›¾ç‰‡ï¼Œå…ˆå¿«é€Ÿä¸‹è½½å¹¶åˆ†ç±»
            visual_type, _ = await _download_and_process_image(url)
            if visual_type == "photo":
                photos.append((url, visual_type))
            elif visual_type == "sticker":
                stickers.append((url, visual_type))
    
    # å†³å®šå¤„ç†å“ªäº›å›¾ç‰‡
    # 1. ä¼˜å…ˆå¤„ç†æ‰€æœ‰ç…§ç‰‡ç±»å‹çš„å›¾ç‰‡ï¼ˆé€šå¸¸åŒ…å«é‡è¦ä¿¡æ¯ï¼‰
    # 2. å¯¹äºè¡¨æƒ…åŒ…ï¼Œæœ€å¤šå¤„ç†2å¼ ä»£è¡¨æ€§çš„
    # 3. æ€»å¤„ç†å›¾ç‰‡æ•°ä¸è¶…è¿‡5å¼ ï¼Œé¿å…æ€§èƒ½é—®é¢˜
    target_images = []
    
    # æ·»åŠ æ‰€æœ‰ç…§ç‰‡
    for photo_url, _ in photos:
        target_images.append(photo_url)
    
    # æ·»åŠ æœ€å¤š2å¼ è¡¨æƒ…åŒ…
    for sticker_url, _ in stickers[:2]:
        target_images.append(sticker_url)
    
    # é™åˆ¶æ€»æ•°é‡
    target_images = target_images[:5]
    
    # å¤„ç†é€‰ä¸­çš„å›¾ç‰‡
    processed_image_data: list[dict[str, Any]] = []
    main_visual_type = "none"
    main_image_artifact = None
    all_image_artifacts = []
    
    for i, target_url in enumerate(target_images):
        # ç¼“å­˜æ£€æŸ¥
        if target_url in _IMG_CACHE:
            cached_type, w, h, size = _IMG_CACHE[target_url]
            logger.info(f"âš¡ [Perception] Cache Hit: {cached_type} ({w}x{h}) - Image {i+1}/{len(target_images)}")
            if cached_type == "photo":
                # ä¸‹è½½å¹¶å¤„ç†ç…§ç‰‡ï¼Œè·å–å®Œæ•´çš„image_artifact
                _, final_image_data = await _download_and_process_image(target_url)
                all_image_artifacts.append({
                    "type": cached_type,
                    "data": final_image_data
                })
                if not main_image_artifact:
                    main_image_artifact = final_image_data
                    main_visual_type = cached_type
            elif cached_type == "sticker":
                if not main_visual_type:
                    main_visual_type = cached_type
        else:
            # ä¸‹è½½å¹¶å¤„ç†å›¾ç‰‡
            visual_type, final_image_data = await _download_and_process_image(target_url)
            
            if visual_type == "photo":
                all_image_artifacts.append({
                    "type": visual_type,
                    "data": final_image_data
                })
                if not main_image_artifact:
                    main_image_artifact = final_image_data
                    main_visual_type = visual_type
            elif visual_type == "sticker" and not main_visual_type:
                main_visual_type = visual_type
        
        # è®°å½•å¤„ç†çš„å›¾ç‰‡
        processed_images.append({
            "url": target_url,
            "type": visual_type if 'visual_type' in locals() else _IMG_CACHE.get(target_url, ("unknown",))[0]
        })
    
    # è®°å½•å¤„ç†ä¿¡æ¯
    logger.info(f"ğŸ“¸ [Perception] Processed {len(processed_images)}/{len(valid_image_urls)} images")
    
    # æ„é€ è¿”å›
    updates = {
        "visual_type": main_visual_type,
        "current_image_artifact": main_image_artifact,
        "all_image_artifacts": all_image_artifacts,  # åŒ…å«æ‰€æœ‰å¤„ç†è¿‡çš„å›¾ç‰‡æ•°æ®
        "processed_images": processed_images  # è®°å½•æ‰€æœ‰å¤„ç†è¿‡çš„å›¾ç‰‡ä¿¡æ¯
    }
    
    return updates
```
- **åŠŸèƒ½**: è´Ÿè´£å›¾ç‰‡å†…å®¹çš„æ„ŸçŸ¥å’Œåˆ†æï¼ŒåŒ…æ‹¬å›¾ç‰‡åˆ†ç±»ã€å†…å®¹è¯†åˆ«å’Œæƒ…æ„Ÿåˆ†æï¼Œæ”¯æŒæ™ºèƒ½å¤„ç†å¤šå¼ å›¾ç‰‡
- **è®¾è®¡æ€è·¯**: 
  - é›†æˆLLMè¿›è¡Œå›¾ç‰‡åˆ†ç±»å’Œåˆ†æï¼Œæé«˜åˆ¤æ–­å‡†ç¡®ç‡
  - å®ç°å›¾ç‰‡ç¼“å­˜æœºåˆ¶ï¼Œé¿å…é‡å¤ä¸‹è½½å’Œå¤„ç†
  - æ”¯æŒå†å²æ¶ˆæ¯å›æº¯ï¼Œå¤„ç†ç”¨æˆ·çš„æŒ‡ä»£æ€§å›¾ç‰‡è¯·æ±‚
  - é‡‡ç”¨å›¾ç‰‡åˆ†ç±»ç­–ç•¥ï¼ŒåŒºåˆ†è¡¨æƒ…åŒ…å’Œæ™®é€šç…§ç‰‡ï¼Œä¼˜åŒ–å¤„ç†é€»è¾‘
  - å®ç°æ™ºèƒ½å›¾ç‰‡é€‰æ‹©ç®—æ³•ï¼Œä¼˜å…ˆå¤„ç†é‡è¦å›¾ç‰‡ï¼Œæ§åˆ¶å¤„ç†æ•°é‡
  - æ·»åŠ è¶…æ—¶å’Œé”™è¯¯å¤„ç†æœºåˆ¶ï¼Œæé«˜ç³»ç»Ÿç¨³å®šæ€§
- **å½±å“èŒƒå›´**: 
  - æ™ºèƒ½ä½“å¯¹å›¾ç‰‡å†…å®¹çš„ç†è§£èƒ½åŠ›
  - å¤šæ¨¡æ€äº¤äº’çš„è´¨é‡å’Œç”¨æˆ·ä½“éªŒ
  - ç³»ç»Ÿæ€§èƒ½å’Œèµ„æºåˆ©ç”¨ç‡
  - è§†è§‰ä¿¡æ¯åœ¨å¯¹è¯ä¸­çš„åº”ç”¨æ•ˆæœ

#### app/graph/nodes/psychology.py
```python
import json
import re
import logging
from datetime import datetime

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage
from app.core.state import AgentState
from app.core.config import config
from app.core.prompts import PSYCHOLOGY_ANALYSIS_PROMPT
from app.core.global_store import global_store
from app.memory.relation_db import relation_db
from app.utils.cache import cached_llm_invoke

llm = ChatOpenAI(
    model=config.SMALL_MODEL,
    temperature=0.3,
    api_key=config.SMALL_MODEL_API_KEY,
    base_url=config.SMALL_MODEL_URL
)

# é…ç½®æ—¥å¿—
logger = logging.getLogger("PsychologyNode")


async def psychology_node(state: AgentState):
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    logger.info(f"[{ts}]--- [Psychology] Analyzing Subconscious... ---")

    # 1. èº«ä»½é”šå®šï¼šåªè®¤ QQ å·ä½œä¸ºæ•°æ®åº“ä¸»é”®
    user_id = state.get("sender_qq", "unknown_user")
    # 2. ç§°å‘¼é€‚é…ï¼šPrompt ä¸­ä½¿ç”¨å½“å‰æ˜µç§°
    user_display_name = state.get("sender_name", "Stranger")

    msgs = state.get("messages", [])
    if not msgs: return {}

    # è·å–æœ€åä¸€æ¡æ¶ˆæ¯å†…å®¹
    last_msg = msgs[-1].content
    if isinstance(last_msg, list): last_msg = "[å¤šæ¨¡æ€å›¾ç‰‡/æ–‡ä»¶]"

    # æ„å»ºå¯¹è¯å†å²ï¼ˆæœ€è¿‘5æ¡æ¶ˆæ¯ï¼‰
    conversation_history = ""
    for i, msg in enumerate(msgs[-5:], 1):
        role = "User" if hasattr(msg, "type") and msg.type == "human" else "Alice"
        content = msg.content
        if isinstance(content, list): content = "[å¤šæ¨¡æ€å›¾ç‰‡/æ–‡ä»¶]"
        conversation_history += f"{i}. {role}: {content}\n"

    g_emotion = global_store.get_emotion_snapshot()

    # 3. ä» DB è·å–å…³ç³» (Key å¿…é¡»æ˜¯ Unique ID)
    profile = await relation_db.get_user_profile(user_id)
    rel = profile.relationship

    # 4. ä¸°å¯Œå…³ç³»æè¿°
    def get_relation_desc(intimacy, familiarity, trust, interest_match):
        if intimacy < 20:
            return "è®¨åŒçš„äºº"
        elif intimacy < 40:
            if trust < 30:
                return "ä¸æ€ä¹ˆä¿¡ä»»çš„äºº"
            else:
                return "æ™®é€šè·¯äºº"
        elif intimacy < 60:
            if familiarity > 70:
                return "ç†Ÿæ‚‰çš„æœ‹å‹"
            elif trust > 70:
                return "å€¼å¾—ä¿¡ä»»çš„æœ‹å‹"
            else:
                return "æ™®é€šçš„æœ‹å‹"
        elif intimacy < 80:
            if familiarity > 80 and trust > 80:
                return "äº²å¯†çš„æœ‹å‹"
            elif interest_match > 80:
                return "å¿—åŒé“åˆçš„æœ‹å‹"
            else:
                return "å€¼å¾—ä¿¡èµ–çš„æœ‹å‹"
        else:
            if familiarity > 90 and trust > 90:
                return "æœ€äº²å¯†çš„æœ‹å‹"
            else:
                return "éå¸¸è¦å¥½çš„æœ‹å‹"

    rel_desc = get_relation_desc(rel.intimacy, rel.familiarity, rel.trust, rel.interest_match)

    # 5. æ„é€  Prompt - æ·»åŠ å¯¹è¯å†å²å’Œç”¨æˆ·å…³ç³»çš„æ›´å¤šç»´åº¦
    prompt = PSYCHOLOGY_ANALYSIS_PROMPT.format(
        current_mood=g_emotion.primary_emotion,
        valence=g_emotion.valence,
        arousal=g_emotion.arousal,
        stress=g_emotion.stress,
        fatigue=g_emotion.fatigue,
        user_name=user_display_name,
        intimacy=rel.intimacy,
        familiarity=rel.familiarity,
        trust=rel.trust,
        interest_match=rel.interest_match,
        relation_desc=rel_desc,
        user_input=last_msg,
        conversation_history=conversation_history,
        communication_style=rel.communication_style,
        favorite_topics=", ".join(rel.favorite_topics) if rel.favorite_topics else "æ— ",
        avoid_topics=", ".join(rel.avoid_topics) if rel.avoid_topics else "æ— "
    )

    try:
        response = await cached_llm_invoke(
            llm, 
            [SystemMessage(content=prompt)],
            temperature=0.3,  # ä¿æŒåŸæœ‰æ¸©åº¦è®¾ç½®
            query_type="psychology_analysis"
        )
        raw_content = response.content.strip()

        data = {}
        match = re.search(r"\{.*\}", raw_content, re.DOTALL)
        if match:
            try:
                data = json.loads(match.group())
            except Exception as e:
                logger.error(f"[{ts}]âŒ [Psychology JSON Parse Error] {str(e)}")
                logger.error(f"[{ts}]âŒ Raw content: {raw_content[:100]}...")
                pass

        if not data:
            logger.error(f"[{ts}]âŒ [Psychology Parse Error] Raw: {raw_content[:30]}...")
            return {}

        # 5. æ‰§è¡Œå…¨å±€æƒ…ç»ªæ›´æ–°
        global_store.update_emotion(
            valence_delta=data.get("valence_delta", 0),
            arousal_delta=data.get("arousal_delta", 0),
            stress_delta=data.get("stress_delta", 0),
            fatigue_delta=data.get("fatigue_delta", 0),
            new_primary=data.get("primary_emotion"),
            new_secondary=data.get("secondary_emotion")
        )

        # 6. æ‰§è¡Œå…³ç³»ç»´åº¦æ›´æ–° (ä½¿ç”¨å”¯ä¸€ ID)
        relation_deltas = data.get("relation_deltas", {})
        if relation_deltas:
            # ä¿å­˜æ›´æ–°å‰çš„å…³ç³»ç»´åº¦å€¼
            old_dimensions = {
                "intimacy": getattr(rel, "intimacy", 50),
                "familiarity": getattr(rel, "familiarity", 50),
                "trust": getattr(rel, "trust", 50),
                "interest_match": getattr(rel, "interest_match", 50)
            }
            
            # æ›´æ–°å…³ç³»ç»´åº¦
            updated_dimensions = await relation_db.update_relationship_dimensions(user_id, relation_deltas)
            
            # è®°å½•æ—¥å¿—
            if updated_dimensions:
                log_msg = f"[{ts}]â¤ï¸ [Relation] {user_display_name}({user_id}):"
                for dim, new_value in updated_dimensions.items():
                    # ä½¿ç”¨æ›´æ–°å‰ä¿å­˜çš„æ—§å€¼
                    old_value = old_dimensions.get(dim, 50)
                    delta = new_value - old_value
                    log_msg += f" {dim}: {old_value} -> {new_value} (Delta: {delta})"
                logger.info(log_msg)
        else:
            # å…¼å®¹æ—§æ ¼å¼
            i_delta = data.get("intimacy_delta", 0)
            if i_delta != 0:
                # ä¿å­˜æ›´æ–°å‰çš„å¥½æ„Ÿåº¦å€¼
                old_intimacy = getattr(rel, "intimacy", 50)
                new_intimacy = relation_db.update_intimacy(user_id, i_delta)
                logger.info(f"[{ts}]â¤ï¸ [Relation] {user_display_name}({user_id}): {old_intimacy} -> {new_intimacy} (Delta: {i_delta})")

        # 7. è·å–æ›´æ–°åçš„æƒ…ç»ªå’Œå…³ç³»æ•°æ®
        updated_emotion = global_store.get_emotion_snapshot()
        updated_profile = await relation_db.get_user_profile(user_id)
        updated_rel = updated_profile.relationship

        return {
            "psychological_context": {
                "internal_thought": data.get("internal_thought", "Thinking..."),
                "style_instruction": data.get("style_instruction", "Normal"),
                "primary_emotion": updated_emotion.primary_emotion,
                "secondary_emotion": updated_emotion.secondary_emotion,
                "current_intimacy": updated_rel.intimacy,
                "current_familiarity": updated_rel.familiarity,
                "current_trust": updated_rel.trust,
                "current_interest_match": updated_rel.interest_match
            },
            "global_emotion_snapshot": updated_emotion.model_dump()
        }

    except Exception as e:
        logger.error(f"[{ts}]âŒ [Psychology Error] {e}")
        return {}
```
- **åŠŸèƒ½**: å®ç°æ™ºèƒ½ä½“çš„å¿ƒç†åˆ†æå’Œæƒ…æ„Ÿç®¡ç†åŠŸèƒ½ï¼ŒåŒ…æ‹¬ç”¨æˆ·æ¶ˆæ¯çš„æ½œæ„è¯†åˆ†æã€å…¨å±€æƒ…ç»ªçŠ¶æ€æ›´æ–°ã€å…³ç³»ç»´åº¦è°ƒæ•´å’Œå¿ƒç†ä¸Šä¸‹æ–‡ç”Ÿæˆ
- **è®¾è®¡æ€è·¯**: 
  - åŸºäºPAD (Pleasure-Arousal-Dominance) æƒ…æ„Ÿæ¨¡å‹ï¼Œåˆ†æç”¨æˆ·æ¶ˆæ¯å¹¶æ›´æ–°æ™ºèƒ½ä½“çš„æƒ…ç»ªçŠ¶æ€
  - å®ç°å¤šç»´åº¦å…³ç³»åˆ†æï¼Œæ ¹æ®å¯¹è¯å†…å®¹åŠ¨æ€è°ƒæ•´äº²å¯†æ„Ÿã€ç†Ÿæ‚‰åº¦ã€ä¿¡ä»»åº¦å’Œå…´è¶£åŒ¹é…åº¦
  - é‡‡ç”¨å¤§æ¨¡å‹è¿›è¡Œå¿ƒç†åˆ†æï¼Œç”Ÿæˆå†…éƒ¨æ€è€ƒå’Œé£æ ¼æŒ‡å¯¼ï¼Œå½±å“åç»­å›å¤
  - æ”¯æŒæƒ…ç»ªçŠ¶æ€çš„å…¨å±€æ›´æ–°å’ŒæŒä¹…åŒ–å­˜å‚¨ï¼Œä¿æŒæƒ…æ„Ÿè¿è´¯æ€§
- **å½±å“èŒƒå›´**: 
  - æ™ºèƒ½ä½“çš„æƒ…æ„Ÿè¡¨è¾¾å’Œä¸ªæ€§åŒ–å›å¤é£æ ¼
  - ç”¨æˆ·å…³ç³»çš„åŠ¨æ€æ¼”åŒ–å’Œæ·±åº¦å‘å±•
  - æƒ…ç»ªçŠ¶æ€çš„å…¨å±€ä¸€è‡´æ€§å’ŒæŒä¹…åŒ–
  - å¿ƒç†ä¸Šä¸‹æ–‡å¯¹åç»­å†³ç­–çš„å½±å“

#### app/graph/nodes/unified_agent.py
```python
async def agent_node(state: AgentState) -> AgentState:
    # ç”Ÿæˆå›å¤å†…å®¹
    # å¯èƒ½è§¦å‘å·¥å…·è°ƒç”¨
    # æ›´æ–° state ä¸­çš„ messages å­—æ®µ
    return state
```
- **åŠŸèƒ½**: ç”Ÿæˆæ™ºèƒ½ä½“çš„å›å¤å†…å®¹ï¼Œæ˜¯æ ¸å¿ƒçš„å†³ç­–èŠ‚ç‚¹
- **è®¾è®¡æ€è·¯**: ç»“åˆä¸Šä¸‹æ–‡ã€è§†è§‰ä¿¡æ¯ã€å¿ƒç†çŠ¶æ€å’Œè®°å¿†ï¼Œç”Ÿæˆç¬¦åˆäººè®¾çš„å›å¤
- **å½±å“èŒƒå›´**: æ™ºèƒ½ä½“çš„å›å¤è´¨é‡å’Œé£æ ¼ï¼Œæ˜¯ç”¨æˆ·ä½“éªŒçš„æ ¸å¿ƒ

#### app/graph/nodes/tool_handler.py
```python
import logging
from datetime import datetime

from langchain_core.messages import ToolMessage  # å¼•å…¥ ToolMessage
from app.core.state import AgentState
from app.tools.tool_registry import tool_registry
from app.utils.cache import cached_tool_result_get, cached_tool_result_set
import uuid

# é…ç½®æ—¥å¿—
logger = logging.getLogger("ToolHandler")


async def tool_node(state: AgentState):
    """
    æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼Œå¹¶å°†ç»“æœä½œä¸º ToolMessage æ³¨å…¥å†å²
    """
    current_messages = state.get("messages", [])
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    tool_data = state.get("tool_call", {})
    tool_name = tool_data.get("name")
    tool_args = tool_data.get("args") or {}

    # ç”Ÿæˆä¸€ä¸ªéšæœºçš„ tool_call_idï¼Œè¿™å¯¹äºæŸäº›æ¨¡å‹ï¼ˆå¦‚ GPT/Claudeï¼‰ä¿æŒå¯¹è¯ç»“æ„å¾ˆé‡è¦
    # è™½ç„¶è¿™é‡Œæˆ‘ä»¬æ˜¯é€šè¿‡ prompt æ¨¡æ‹Ÿçš„è°ƒç”¨ï¼Œä½†ä¿æŒç»“æ„ä¸€è‡´æ€§æœ‰å¥½å¤„
    tool_call_id = str(uuid.uuid4())

    logger.info(f"[{ts}] --- [Tools] Executing: {tool_name} with {tool_args} --- ")

    result = "Tool execution failed."

    try:
        # æ£€æŸ¥å·¥å…·æ˜¯å¦å­˜åœ¨
        if not tool_registry.is_tool_available(tool_name):
            result = f"Unknown tool: {tool_name}"
            logger.error(f"[{ts}] [Tool Error] {result}")
        else:
            # æ ‡å‡†åŒ–å‚æ•°æ ¼å¼
            if not isinstance(tool_args, dict):
                # å°è¯•è·å–å·¥å…·çš„ä¸»è¦å‚æ•°
                tool_class = tool_registry.get_tool(tool_name)
                if tool_class and tool_class.parameters:
                    primary_param = tool_class.parameters[0].name
                    tool_args = {primary_param: str(tool_args)}
                else:
                    tool_args = {}
            
            # æ£€æŸ¥å·¥å…·è°ƒç”¨ç»“æœç¼“å­˜
            cache_key_args = tool_args.copy()
            cached_result = await cached_tool_result_get(tool_name, cache_key_args)
            
            if cached_result:
                logger.info(f"[{ts}] [Tools Cache Hit] {tool_name}: {str(tool_args)[:30]}... ")
                result = cached_result
            else:
                # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œå·¥å…·è°ƒç”¨
                tool_instance = tool_registry.get_tool_instance(tool_name)
                if tool_instance:
                    # ä½¿ç”¨æ–°çš„å·¥å…·APIæ‰§è¡Œ
                    execute_result = await tool_instance.execute(**tool_args)
                    
                    if execute_result["success"]:
                        if tool_name == "generate_image":
                            result = f"IMAGE_GENERATED: {execute_result['result']}"
                        else:
                            result = execute_result["result"]
                    else:
                        result = execute_result["error"]
                        logger.error(f"[{ts}] [Tool Execution Error] {result}")
                else:
                    result = f"Failed to create tool instance: {tool_name}"
                
                # å°†ç»“æœå­˜å…¥ç¼“å­˜
                await cached_tool_result_set(tool_name, cache_key_args, result)
                logger.info(f"[{ts}] [Tools Cache Set] {tool_name}: {str(tool_args)[:30]}... ")

    except Exception as e:
        logger.error(f"[{ts}] [Tool Error] {e}")
        result = f"Tool Error: {str(e)}"

    # --- æ”¹è¿›ç‚¹ï¼šä½¿ç”¨ ToolMessage ---
    # content å‰åŠ ä¸Šæ ‡è¯†ï¼Œå¸®åŠ© LLM è¯†åˆ«
    tool_msg = ToolMessage(
        content=f"[System: Tool '{tool_name}' Result]\n{str(result)}",
        tool_call_id=tool_call_id,
        name=tool_name
    )

    # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœä½ ä¹‹å‰çš„ Agent Prompt æåº¦ä¾èµ– SystemMessageï¼Œå¯ä»¥ä¿æŒ SystemMessage
    # ä½† ToolMessage æ˜¯ LangChain æ ‡å‡†ã€‚è¿™é‡Œæˆ‘ä¿ç•™ SystemMessage é£æ ¼çš„å†…å®¹ä½†ç”¨ ToolMessage ç±»

    return {
        "messages": current_messages + [tool_msg],
        "tool_call": {}
    }
```
- **åŠŸèƒ½**: å®ç°å·¥å…·è°ƒç”¨çš„æ‰§è¡Œã€ç»“æœå¤„ç†å’Œç¼“å­˜ç®¡ç†ï¼Œå°†å·¥å…·æ‰§è¡Œç»“æœä½œä¸ºToolMessageæ³¨å…¥å¯¹è¯å†å²
- **è®¾è®¡æ€è·¯**: 
  - é‡‡ç”¨å·¥å…·æ³¨å†Œè¡¨æœºåˆ¶ï¼Œç»Ÿä¸€ç®¡ç†å’Œè°ƒç”¨å„ç§å·¥å…·
  - å®ç°å·¥å…·è°ƒç”¨ç»“æœç¼“å­˜ï¼Œé¿å…é‡å¤æ‰§è¡Œç›¸åŒå·¥å…·è¯·æ±‚
  - æ”¯æŒå‚æ•°æ ‡å‡†åŒ–å¤„ç†ï¼Œç¡®ä¿å·¥å…·è°ƒç”¨çš„å…¼å®¹æ€§
  - ä½¿ç”¨LangChainæ ‡å‡†çš„ToolMessageæ ¼å¼ï¼Œä¿æŒå¯¹è¯ç»“æ„ä¸€è‡´æ€§
  - ä¸ºå›¾åƒç”Ÿæˆç­‰ç‰¹æ®Šå·¥å…·æä¾›ç»“æœæ ¼å¼å®šåˆ¶
- **å½±å“èŒƒå›´**: 
  - æ™ºèƒ½ä½“ä½¿ç”¨å¤–éƒ¨å·¥å…·çš„èƒ½åŠ›å’Œæ•ˆç‡
  - ç³»ç»Ÿèµ„æºåˆ©ç”¨å’Œæ€§èƒ½ä¼˜åŒ–
  - å·¥å…·æ‰§è¡Œç»“æœçš„å‡†ç¡®æ€§å’Œå¯é æ€§
  - ä¸å„ç§å¤–éƒ¨æœåŠ¡çš„é›†æˆèƒ½åŠ›

#### app/graph/nodes/memory_saver.py
```python
async def memory_saver_node(state: AgentState) -> AgentState:
    """
    é•¿æœŸè®°å¿†ä¿å­˜èŠ‚ç‚¹
    å°†é‡è¦ä¿¡æ¯ä¿å­˜åˆ°é•¿æœŸè®°å¿†
    """
    # æå–å¯¹è¯ä¸­çš„é‡è¦ä¿¡æ¯
    # ä¿å­˜åˆ°é•¿æœŸè®°å¿†
    return state
```
- **åŠŸèƒ½**: å°†é‡è¦ä¿¡æ¯ä¿å­˜åˆ°é•¿æœŸè®°å¿†
- **è®¾è®¡æ€è·¯**: æå–å¯¹è¯ä¸­çš„é‡è¦ä¿¡æ¯ï¼Œè½¬æ¢ä¸ºå‘é‡å¹¶å­˜å‚¨åˆ°ChromaDB
- **å½±å“èŒƒå›´**: 
  - æ™ºèƒ½ä½“çš„é•¿æœŸè®°å¿†èƒ½åŠ›
  - å›å¤çš„è¿è´¯æ€§å’Œä¸ªæ€§åŒ–
  - ç”¨æˆ·ä½“éªŒ

#### app/graph/nodes/summarizer.py
```python
import logging
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage

# é…ç½®æ—¥å¿—
logger = logging.getLogger("Summarizer")
from app.core.state import AgentState
from app.core.config import config
from app.memory.local_history import LocalHistoryManager
from app.graph.nodes.memory_saver import extract_and_save_memories

MAX_HISTORY_LEN = 15
PRUNE_COUNT = 10

SUMMARY_PROMPT = """
You are a Conversation Summarizer.
Update the running summary with new lines.

ã€Current Summaryã€‘
{current_summary}

ã€New Linesã€‘
{new_lines}

Output ONLY the updated summary text.
"""

llm = ChatOpenAI(
    model=config.SMALL_MODEL,
    temperature=0.1,
    api_key=config.SMALL_MODEL_API_KEY,
    base_url=config.SMALL_MODEL_URL
)


async def summarizer_node(state: AgentState):
    messages = state.get("messages", [])
    current_summary = state.get("conversation_summary", "")

    # è·å– Session ID (ç”¨äºéš”ç¦»ä¸åŒç¾¤/ç§èŠçš„å†å²æ–‡ä»¶)
    # å¦‚æœä¸Šæ¸¸æœªä¼  session_idï¼Œåˆ™å›é€€åˆ° sender_qq (ä»…å…¼å®¹æ—§é€»è¾‘ï¼Œå»ºè®®ä¸Šæ¸¸å¿…ä¼ )
    session_key = state.get("session_id") or state.get("sender_qq")
    
    # è·å–ç”¨æˆ·ä¿¡æ¯
    real_user_id = state.get("sender_qq", "unknown")
    user_nickname = state.get("sender_name", "User")

    # 1. å‰ªæé€»è¾‘
    if len(messages) > MAX_HISTORY_LEN:
        to_prune = messages[:PRUNE_COUNT]
        remaining = messages[PRUNE_COUNT:]
        
        # åœ¨æ€»ç»“å‰ï¼Œå…ˆä»è¦å‰ªæçš„æ¶ˆæ¯ä¸­æå–é‡è¦ä¿¡æ¯ä¿å­˜åˆ°é•¿æœŸè®°å¿†
        logger.info(f"ğŸ“ [Summarizer] æ­£åœ¨ä» {len(to_prune)} æ¡æ¶ˆæ¯ä¸­æå–é‡è¦ä¿¡æ¯åˆ°é•¿æœŸè®°å¿†")
        
        # å¯¹æ¯æ¡è¦å‰ªæçš„æ¶ˆæ¯è°ƒç”¨è®°å¿†æå–å‡½æ•°
        for i, msg in enumerate(to_prune):
            # æ„å»ºåŒ…å«å½“å‰æ¶ˆæ¯çš„ä¸Šä¸‹æ–‡
            context_messages = to_prune[max(0, i-1):i+1]  # åŒ…å«å½“å‰æ¶ˆæ¯å’Œå‰ä¸€æ¡æ¶ˆæ¯
            await extract_and_save_memories(context_messages, real_user_id, user_nickname)

        text_lines = []
        for m in to_prune:
            role = "User" if isinstance(m, HumanMessage) else "AI"
            content = m.content
            if isinstance(content, list): content = "[MultiModal/Image]"
            text_lines.append(f"{role}: {content}")

        input_text = "\n".join(text_lines)

        try:
            prompt = ChatPromptTemplate.from_template(SUMMARY_PROMPT)
            chain = prompt | llm
            response = await chain.ainvoke({
                "current_summary": current_summary if current_summary else "Start of log.",
                "new_lines": input_text
            })
            current_summary = response.content.strip()
            messages = remaining

        except Exception as e:
            logger.error(f"âŒ [Summarizer Error] {e}")

    # 2. æ ¸å¿ƒä¿®å¤ï¼šè°ƒç”¨å¼‚æ­¥ä¿å­˜æ–¹æ³•ï¼Œä¼ å…¥ session_key
    # å‡è®¾ LocalHistoryManager.save_state ç­¾åæ”¯æŒ session_id å‚æ•°
    # å¦‚æœæ‚¨çš„ LocalHistoryManager æ˜¯åŸºäºå…¨å±€å•ä¾‹çš„ï¼Œè¯·åŠ¡å¿…ä¿®æ”¹å®ƒä»¥æ¥å— session_id ä½œä¸ºæ–‡ä»¶è·¯å¾„çš„ä¸€éƒ¨åˆ†
    if session_key:
        await LocalHistoryManager.save_state(messages, current_summary, session_id=session_key)
    else:
        logger.warning("âš ï¸ [Summarizer] No session_id found, history might not persist correctly.")

    return {
        "messages": messages,
        "conversation_summary": current_summary
    }
```
- **åŠŸèƒ½**: å®ç°å¯¹è¯å†å²ç®¡ç†ã€è®°å¿†æå–å’Œæ‘˜è¦ç”ŸæˆåŠŸèƒ½ï¼Œè´Ÿè´£ç»´æŠ¤ä¼šè¯ä¸Šä¸‹æ–‡å¹¶å°†é‡è¦ä¿¡æ¯ä¿å­˜åˆ°é•¿æœŸè®°å¿†
- **è®¾è®¡æ€è·¯**: 
  - é‡‡ç”¨å¯¹è¯å†å²å‰ªææœºåˆ¶ï¼Œå½“æ¶ˆæ¯æ•°é‡è¶…è¿‡é˜ˆå€¼æ—¶è‡ªåŠ¨ä¿®å‰ªæ—©æœŸæ¶ˆæ¯
  - åœ¨å‰ªæå‰ä»æ¶ˆæ¯ä¸­æå–é‡è¦ä¿¡æ¯å¹¶ä¿å­˜åˆ°é•¿æœŸè®°å¿†ï¼Œé¿å…ä¿¡æ¯ä¸¢å¤±
  - ä½¿ç”¨LLMç”Ÿæˆå’Œæ›´æ–°å¯¹è¯æ‘˜è¦ï¼Œä¿æŒå¯¹æ•´ä¸ªå¯¹è¯çš„ç†è§£
  - æ”¯æŒå¤šä¼šè¯éš”ç¦»ï¼Œä½¿ç”¨session_idç¡®ä¿ä¸åŒç¾¤èŠ/ç§èŠçš„å†å²æ­£ç¡®ä¿å­˜
  - å®ç°å¼‚æ­¥ä¿å­˜æœºåˆ¶ï¼Œæé«˜ç³»ç»Ÿå“åº”æ€§èƒ½
- **å½±å“èŒƒå›´**: 
  - å¯¹è¯ä¸Šä¸‹æ–‡çš„ç®¡ç†å’Œç»´æŠ¤
  - é•¿æœŸè®°å¿†çš„å½¢æˆå’Œç§¯ç´¯
  - ç³»ç»Ÿæ€§èƒ½å’Œå†…å­˜ä½¿ç”¨ä¼˜åŒ–
  - å¤šä¼šè¯åœºæ™¯ä¸‹çš„å†å²è®°å½•éš”ç¦»
  - åç»­å¯¹è¯ç†è§£çš„å‡†ç¡®æ€§

#### app/graph/nodes/proactive_agent.py
```python
import json
import time
import logging
import random
from datetime import datetime
from typing import List, Any, Dict
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from app.core.state import AgentState
from app.core.config import config
from app.core.global_store import global_store
from app.memory.relation_db import relation_db
from app.core.prompts import ALICE_CORE_PERSONA, SOCIAL_VOLITION_PROMPT
from app.utils.cache import cached_llm_invoke
from app.memory.vector_store import vector_db as vector_store

# é…ç½®æ—¥å¿—
logger = logging.getLogger("ProactiveAgent")

# ä¸»åŠ¨äº¤äº’é…ç½®
PROACTIVE_CONFIG = {
    # æ´»è·ƒæ—¶é—´çª—å£ï¼ˆå°æ—¶ï¼‰
    "active_time_windows": [
        (9, 12),    # ä¸Šåˆ
        (14, 17),   # ä¸‹åˆ
        (19, 22)    # æ™šä¸Š
    ],
    # æœ€å°æ²‰é»˜æ—¶é•¿ï¼ˆå°æ—¶ï¼‰
    "min_silence_hours": 1,
    # æœ€å¤§æ²‰é»˜æ—¶é•¿ï¼ˆå°æ—¶ï¼‰
    "max_silence_hours": 24,
    # åŸºç¡€è§¦å‘æ¦‚ç‡
    "base_chance": 0.3,
    # ç”¨æˆ·åé¦ˆå½±å“å› å­
    "feedback_factor": 0.2,
    # ä¸ªæ€§åŒ–è¯é¢˜æƒé‡
    "topic_relevance_weight": 0.7,
    # äººè®¾ä¸€è‡´æ€§è¿‡æ»¤é˜ˆå€¼
    "persona_consistency_threshold": 0.8
}

# åˆå§‹åŒ–LLMå®ä¾‹
llm = ChatOpenAI(
    model=config.MODEL_NAME,
    temperature=0.6,  # é™ä½æ¸©åº¦ï¼Œè®©ä¸»åŠ¨å‘è¨€æ›´ç¬¦åˆäººè®¾ï¼Œé¿å…è¿‡äºæ´»æ³¼
    api_key=config.MODEL_API_KEY,
    base_url=config.MODEL_URL
)

class ProactiveInteractionManager:
    def __init__(self):
        self.logger = logger
        self.feedback_store = {}
        
    def is_in_active_time_window(self) -> bool:
        """
        æ£€æŸ¥å½“å‰æ—¶é—´æ˜¯å¦åœ¨æ´»è·ƒçª—å£å†…
        """
        current_hour = datetime.now().hour
        for start, end in PROACTIVE_CONFIG["active_time_windows"]:
            if start <= current_hour < end:
                return True
        return False
    
    def should_initiate_interaction(self, user_id: str, last_interaction_time: float, user_feedback_score: float, intimacy: int, familiarity: int, trust: int, interest_match: int, stamina: float, interaction_patterns: Dict[str, Any]) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥å‘èµ·ä¸»åŠ¨äº¤äº’
        """
        # 1. æ£€æŸ¥å½“å‰æ—¶é—´æ˜¯å¦åœ¨æ´»è·ƒçª—å£å†…
        if not self.is_in_active_time_window():
            self.logger.debug("ä¸åœ¨æ´»è·ƒæ—¶é—´çª—å£å†…ï¼Œè·³è¿‡ä¸»åŠ¨äº¤äº’")
            return False
        
        # 2. æ£€æŸ¥ä½“åŠ›å€¼
        if stamina < 20:
            self.logger.debug(f"ä½“åŠ›å€¼è¿‡ä½ ({stamina:.1f})ï¼Œè·³è¿‡ä¸»åŠ¨äº¤äº’")
            return False
        
        # 3. è®¡ç®—æ²‰é»˜æ—¶é•¿
        silence_hours = (time.time() - last_interaction_time) / 3600
        
        # 4. æ£€æŸ¥æ²‰é»˜æ—¶é•¿æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…
        if silence_hours < PROACTIVE_CONFIG["min_silence_hours"] or silence_hours > PROACTIVE_CONFIG["max_silence_hours"]:
            self.logger.debug(f"æ²‰é»˜æ—¶é•¿ ({silence_hours:.1f}å°æ—¶) ä¸åœ¨åˆç†èŒƒå›´ï¼Œè·³è¿‡ä¸»åŠ¨äº¤äº’")
            return False
        
        # 5. è·å–ç”¨æˆ·äº¤äº’æ¨¡å¼åå¥½
        preferred_response_time = interaction_patterns.get("preferred_response_time", None)
        current_hour = datetime.now().hour
        
        # æ£€æŸ¥æ˜¯å¦åœ¨ç”¨æˆ·åå¥½çš„å›å¤æ—¶é—´æ®µå†…
        if preferred_response_time:
            # å‡è®¾preferred_response_timeæ ¼å¼ä¸º [start_hour, end_hour]
            if not (preferred_response_time[0] <= current_hour < preferred_response_time[1]):
                self.logger.debug(f"å½“å‰æ—¶é—´ä¸åœ¨ç”¨æˆ·åå¥½çš„å›å¤æ—¶é—´æ®µå†…ï¼Œè·³è¿‡ä¸»åŠ¨äº¤äº’")
                return False
        
        # 6. è®¡ç®—è§¦å‘æ¦‚ç‡
        base_probability = PROACTIVE_CONFIG["base_chance"]
        
        # åŸºäºå…³ç³»äº²å¯†åº¦çš„è°ƒæ•´
        intimacy_factor = 0.5 + (intimacy / 100)  # 0.5-1.5
        
        # åŸºäºç†Ÿæ‚‰åº¦çš„è°ƒæ•´
        familiarity_factor = 0.8 + (familiarity / 500)  # 0.8-1.0
        
        # åŸºäºä¿¡ä»»åº¦çš„è°ƒæ•´
        trust_factor = 0.8 + (trust / 500)  # 0.8-1.0
        
        # åŸºäºå…´è¶£åŒ¹é…åº¦çš„è°ƒæ•´
        interest_factor = 0.5 + (interest_match / 100)  # 0.5-1.5
        
        # åŸºäºæ²‰é»˜æ—¶é•¿çš„æ¦‚ç‡è°ƒæ•´ï¼ˆæ›´æ™ºèƒ½çš„æ›²çº¿ï¼‰
        if silence_hours < 6:
            # çŸ­æ—¶é—´æ²‰é»˜ï¼šæ¦‚ç‡éšæ—¶é—´çº¿æ€§å¢åŠ ï¼Œä½†å—äº²å¯†åº¦å½±å“
            silence_factor = min(1.5, (silence_hours / PROACTIVE_CONFIG["min_silence_hours"]) * intimacy_factor)
        elif silence_hours < 12:
            # ä¸­ç­‰æ—¶é—´æ²‰é»˜ï¼šä¿æŒè¾ƒé«˜æ¦‚ç‡
            silence_factor = 1.2 * intimacy_factor
        else:
            # é•¿æ—¶é—´æ²‰é»˜ï¼šæ¦‚ç‡é€æ¸é™ä½ï¼Œä½†å—ç†Ÿæ‚‰åº¦å’Œä¿¡ä»»åº¦å½±å“
            silence_factor = max(0.5, (1 - (silence_hours - 12) / 24) * (familiarity_factor + trust_factor) / 2)
        
        # ç”¨æˆ·åé¦ˆè°ƒæ•´ï¼Œæƒé‡æ›´é«˜
        feedback_factor = 1 + (user_feedback_score * PROACTIVE_CONFIG["feedback_factor"] * 1.5)
        
        # ç»¼åˆæ‰€æœ‰å› å­
        final_probability = base_probability * silence_factor * feedback_factor * interest_factor
        
        # æ ¹æ®å…³ç³»é˜¶æ®µè°ƒæ•´æœ€ç»ˆæ¦‚ç‡
        if intimacy < 30:
            # ä½äº²å¯†åº¦ç”¨æˆ·ï¼šé™ä½è§¦å‘æ¦‚ç‡
            final_probability *= 0.7
        elif intimacy > 70:
            # é«˜äº²å¯†åº¦ç”¨æˆ·ï¼šé€‚å½“æé«˜è§¦å‘æ¦‚ç‡
            final_probability *= 1.2
        
        # é™åˆ¶æ¦‚ç‡èŒƒå›´
        final_probability = max(0.03, min(0.85, final_probability))
        
        # 7. éšæœºåˆ¤æ–­æ˜¯å¦è§¦å‘
        if random.random() < final_probability:
            self.logger.debug(f"è§¦å‘ä¸»åŠ¨äº¤äº’ï¼Œæ¦‚ç‡: {final_probability:.2f}")
            return True
        
        return False
    
    async def get_personalized_topics(self, user_id: str, limit: int = 5) -> List[str]:
        """
        è·å–ä¸ªæ€§åŒ–è¯é¢˜åˆ—è¡¨
        """
        try:
            # è·å–ç”¨æˆ·å…³ç³»æ•°æ®
            profile = await relation_db.get_user_profile(user_id)
            rel = profile.relationship
            
            # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æ„Ÿå…´è¶£çš„è¯é¢˜
            favorite_topics = rel.favorite_topics.copy()
            avoid_topics = rel.avoid_topics.copy()
            
            # è·å–ç”¨æˆ·è®°å¿†ç‚¹
            memory_points = rel.memory_points
            memory_topics = []
            
            # è§£æè®°å¿†ç‚¹ï¼Œè¿‡æ»¤å‡ºå…´è¶£çˆ±å¥½å’Œæ—¥å¸¸è¯é¢˜ç›¸å…³çš„å†…å®¹
            for mp in memory_points:
                if isinstance(mp, str):
                    parts = mp.split(":")
                    if len(parts) >= 3:
                        category, content, weight = parts[0], ":".join(parts[1:-1]), float(parts[-1])
                        # åªä¿ç•™é«˜æƒé‡çš„è®°å¿†ç‚¹
                        if weight > 0.5 and category in ["å…´è¶£çˆ±å¥½", "å…±åŒç»å†", "æ—¥å¸¸è¯é¢˜"]:
                            memory_topics.append((content.strip(), weight))
            
            # å¯¹è®°å¿†ç‚¹æŒ‰æƒé‡æ’åº
            memory_topics.sort(key=lambda x: x[1], reverse=True)
            memory_topic_texts = [topic for topic, weight in memory_topics]
            
            # ä»å‘é‡å­˜å‚¨ä¸­è·å–ç›¸å…³è®°å¿†ç‚¹ï¼Œä½¿ç”¨ç”¨æˆ·çš„å…´è¶£ä½œä¸ºæŸ¥è¯¢
            vector_query = " ".join(favorite_topics[:3]) if favorite_topics else "æ—¥å¸¸è¯é¢˜"
            vector_memories = await vector_store.search(
                query=vector_query,
                k=10,
                categories=["å…´è¶£çˆ±å¥½", "å…±åŒç»å†", "æ—¥å¸¸è¯é¢˜"]
            )
            
            vector_topics = []
            if vector_memories:
                for memory in vector_memories:
                    if memory.content and len(memory.content) > 5:
                        vector_topics.append(memory.content)
            
            # åˆå¹¶æ‰€æœ‰è¯é¢˜æºå¹¶æ‰“åˆ†
            all_topic_candidates = []
            
            # 1. ä¼˜å…ˆæ·»åŠ ç”¨æˆ·æ„Ÿå…´è¶£çš„è¯é¢˜
            for topic in favorite_topics:
                if topic:
                    all_topic_candidates.append((topic, 0.9, "favorite"))
            
            # 2. æ·»åŠ è®°å¿†ç‚¹è¯é¢˜
            for topic in memory_topic_texts:
                if topic:
                    all_topic_candidates.append((topic, 0.8, "memory"))
            
            # 3. æ·»åŠ å‘é‡å­˜å‚¨è¯é¢˜
            for topic in vector_topics:
                if topic:
                    all_topic_candidates.append((topic, 0.7, "vector"))
            
            # 4. å¦‚æœè¯é¢˜ä¸å¤Ÿï¼Œä½¿ç”¨é»˜è®¤è¯é¢˜
            default_topics = [
                "æœ€è¿‘æœ‰æ²¡æœ‰è¯»åˆ°ä»€ä¹ˆæœ‰æ„æ€çš„ä¹¦ï¼Ÿ",
                "æ—§ä¹¦åº—æ‰“æŠ˜ï¼Œä½ æœ‰æƒ³å»çœ‹çœ‹å—ï¼Ÿ",
                "ä»Šå¤©å¤©æ°”ä¸é”™ï¼Œé€‚åˆå‡ºé—¨æ•£æ­¥å‘¢",
                "æœ€è¿‘æ€»æ˜¯ç¡ä¸å¤Ÿï¼Œä½ ä¹Ÿè¿™æ ·å—ï¼Ÿ",
                "å¬è¯´æœ‰éƒ¨è€ç”µå½±é‡æ˜ äº†ï¼Œå¥½åƒè¿˜ä¸é”™",
                "æ˜¨å¤©åœ¨å’–å•¡é¦†çœ‹åˆ°ä¸€åªå¾ˆå¯çˆ±çš„çŒ«",
                "æœ€è¿‘åœ¨å¬ä¸€äº›è€æ­Œï¼Œçªç„¶è§‰å¾—ä»¥å‰çš„æ­Œæ›´æœ‰å‘³é“",
                "ä½ å¹³æ—¶å–œæ¬¢å»å“ªäº›å®‰é™çš„åœ°æ–¹ï¼Ÿ",
                "ä»Šå¤©å°è¯•åšäº†æ‰‹å†²å’–å•¡ï¼Œè™½ç„¶å‘³é“ä¸€èˆ¬..."
            ]
            
            # æ·»åŠ é»˜è®¤è¯é¢˜å€™é€‰
            for topic in default_topics:
                all_topic_candidates.append((topic, 0.5, "default"))
            
            # å»é‡
            seen_topics = set()
            unique_candidates = []
            for topic, score, source in all_topic_candidates:
                if topic not in seen_topics:
                    seen_topics.add(topic)
                    unique_candidates.append((topic, score, source))
            
            # æŒ‰ç›¸å…³æ€§åˆ†æ•°æ’åº
            unique_candidates.sort(key=lambda x: x[1], reverse=True)
            
            # é€‰æ‹©å‰limitä¸ªè¯é¢˜
            result_topics = [topic for topic, score, source in unique_candidates[:limit]]
            
            return result_topics[:limit]
        except Exception as e:
            self.logger.error(f"è·å–ä¸ªæ€§åŒ–è¯é¢˜å¤±è´¥: {e}")
            return []

# åˆå§‹åŒ–ä¸»åŠ¨äº¤äº’ç®¡ç†å™¨
interaction_manager = ProactiveInteractionManager()

def _ensure_alice_persona(content: str, intimacy: int) -> str:
    """
    ç¡®ä¿å†…å®¹ç¬¦åˆAliceçš„äººè®¾
    """
    # Aliceçš„æ ¸å¿ƒç‰¹ç‚¹ï¼šç®€çŸ­ã€äº‘æ·¡é£è½»ã€é¿å…éº»çƒ¦ã€ä¸åˆ»æ„
    
    # 1. ç§»é™¤è¿‡äºæ­£å¼çš„è¡¨è¾¾
    formal_phrases = [
        "å¾ˆé«˜å…´è®¤è¯†ä½ ", "ä¹æ„æ•ˆåŠ³", "æ ¹æ®æˆ‘çš„çŸ¥è¯†", "æˆ‘è®¤ä¸º", "æˆ‘è§‰å¾—",
        "ä½ å¥½", "åœ¨å—", "è¯·é—®", "æ„Ÿè°¢", "è°¢è°¢", "å¯¹ä¸èµ·", "æŠ±æ­‰"
    ]
    
    filtered_content = content
    for phrase in formal_phrases:
        if phrase in filtered_content:
            filtered_content = filtered_content.replace(phrase, "")
    
    # 2. ç§»é™¤è¿‡äºäº²å¯†çš„è¡¨è¾¾
    intimate_phrases = [
        "äº²çˆ±çš„", "å®è´", "è€å…¬", "è€å©†", "å“¥å“¥", "å§å§", "å¼Ÿå¼Ÿ", "å¦¹å¦¹",
        "æˆ‘çˆ±ä½ ", "æˆ‘æƒ³ä½ ", "æ€å¿µä½ ", "å–œæ¬¢ä½ ", "æŠ±æŠ±", "äº²äº²"
    ]
    
    for phrase in intimate_phrases:
        if phrase in filtered_content:
            filtered_content = filtered_content.replace(phrase, "")
    
    # 3. ç§»é™¤åˆ»æ„å¼•å¯¼å¯¹è¯çš„è¡¨è¾¾
    guiding_phrases = [
        "é‚£ä½ å‘¢", "ä½ è§‰å¾—å‘¢", "æœ‰ä»€ä¹ˆæƒ³æ³•", "åˆ†äº«ç»™æˆ‘å¬å¬",
        "æœ‰ä»€ä¹ˆæ„Ÿå—", "è§‰å¾—æ€ä¹ˆæ ·", "éšæ—¶æ¥æ‰¾æˆ‘èŠèŠå“¦"
    ]
    
    for phrase in guiding_phrases:
        if phrase in filtered_content:
            filtered_content = filtered_content.replace(f" {phrase}", "")
    
    # 4. ç§»é™¤æ„Ÿå¹å·å’Œé—®å·ï¼ˆAliceå¾ˆå°‘ç”¨å¼ºçƒˆçš„æ ‡ç‚¹ï¼‰
    filtered_content = filtered_content.replace("!", "...")
    filtered_content = filtered_content.replace("?", "...")
    
    # 5. æ ¹æ®äº²å¯†åº¦è°ƒæ•´è¯­æ°”
    if intimacy > 85:
        # æé«˜äº²å¯†åº¦ï¼šå¯ä»¥ç¨å¾®éšæ„ä¸€ç‚¹
        filtered_content = filtered_content.replace("...", "~")
    elif intimacy < 35:
        # ä½äº²å¯†åº¦ï¼šä¿æŒè·ç¦»æ„Ÿï¼Œæ›´å†·æ·¡
        filtered_content = filtered_content.replace("~", "...")
    
    # 6. ç¡®ä¿å†…å®¹ä¸æ˜¯åˆ»æ„çš„æé—®æˆ–å¼•å¯¼
    if any(filtered_content.endswith(ending) for ending in ["...?", "?", "å‘¢", "å—", "å§"]):
        # è½¬æ¢ä¸ºé™ˆè¿°å¥
        filtered_content = filtered_content[:-1] + "..."
    
    return filtered_content

async def _generate_proactive_content(user_id: str, topics: List[str], intimacy: int, current_time: str, silence_duration: str, stamina: float, chat_type: str, user_name: str, familiarity: int, trust: int, interest_match: int, communication_style: str) -> str:
    """
    ç”Ÿæˆç¬¦åˆäººè®¾çš„ä¸»åŠ¨äº¤äº’å†…å®¹
    """
    if not topics:
        return ""
    
    try:
        # éšæœºé€‰æ‹©ä¸€ä¸ªè¯é¢˜
        selected_topic = random.choice(topics)
        
        # å¡«å……SOCIAL_VOLITION_PROMPTæ‰€éœ€çš„å‚æ•°
        prompt = SOCIAL_VOLITION_PROMPT.format(
            alice_core_persona=ALICE_CORE_PERSONA,
            current_time=current_time,
            time_period="ä¸Šåˆ" if 9 <= int(current_time.split(":")[0]) < 12 else "ä¸‹åˆ" if 12 <= int(current_time.split(":")[0]) < 18 else "æ™šä¸Š",
            silence_duration=silence_duration,
            mood="å¹³é™",
            stamina=stamina,
            chat_type=chat_type,
            user_name=user_name,
            intimacy=intimacy,
            familiarity=familiarity,
            trust=trust,
            interest_match=interest_match,
            relation_tags="",
            relation_notes="",
            vision_desc="æ— ",
            personalized_info=f"æ„Ÿå…´è¶£çš„è¯é¢˜: {selected_topic}ï¼Œç”¨æˆ·æ²Ÿé€šé£æ ¼: {communication_style}",
            conversation_summary=f"æœ€è¿‘çš„è¯é¢˜: {selected_topic}"
        )
        
        # æ ¹æ®æ²Ÿé€šé£æ ¼è°ƒæ•´temperature
        temperature = 0.5
        if communication_style == "playful":
            temperature = 0.7
        elif communication_style == "formal":
            temperature = 0.3
        
        response = await cached_llm_invoke(
            llm, 
            [SystemMessage(content=prompt)],
            temperature=temperature,
            query_type="proactive_content",
            conversation_type=chat_type
        )
        
        content = response.content.strip()
        if content:
            try:
                # è§£æJSONå“åº”
                import json
                result = json.loads(content)
                proactive_content = result.get("content", "")
                if proactive_content:
                    # ç¡®ä¿å†…å®¹ç¬¦åˆAliceäººè®¾
                    return _ensure_alice_persona(proactive_content, intimacy)
            except json.JSONDecodeError:
                # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨å†…å®¹
                return _ensure_alice_persona(content, intimacy)
        
        return ""
    except Exception as e:
        logger.error(f"ç”Ÿæˆä¸»åŠ¨å†…å®¹å¤±è´¥: {e}")
        return ""

async def proactive_node(state: AgentState):
    """
    ä¸»åŠ¨äº¤äº’èŠ‚ç‚¹ - è‡ªç„¶è§¦å‘ç‰ˆæœ¬
    """
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    logger.info(f"[{ts}] --- [Proactive] Checking interaction opportunity... ---")
    
    # 1. è·å–åŸºæœ¬ä¸Šä¸‹æ–‡
    try:
        user_id = state.get("sender_qq", "unknown")
        user_display_name = state.get("sender_name", "User")
        is_group = state.get("is_group", False)
        session_id = state.get("session_id", "unknown")
        msgs = state.get("messages", [])
        
        if not user_id or user_id == "unknown":
            logger.warning(f"[{ts}] ç¼ºå°‘ç”¨æˆ·IDï¼Œè·³è¿‡ä¸»åŠ¨äº¤äº’")
            return {"next_step": "silent"}
    except Exception as e:
        logger.error(f"[{ts}] è·å–ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
        return {"next_step": "silent"}
    
    # 2. è·å–ç”¨æˆ·å…³ç³»æ•°æ®
    try:
        profile = await relation_db.get_user_profile(user_id)
        rel = profile.relationship
        intimacy = rel.intimacy
        familiarity = rel.familiarity
        
        # 3. æ£€æŸ¥å…³ç³»é˜¶æ®µ - ä½äº²å¯†åº¦ç”¨æˆ·å‡å°‘ä¸»åŠ¨äº¤äº’
        if intimacy < 20 and random.random() > 0.3:
            logger.debug(f"[{ts}] ç”¨æˆ·äº²å¯†åº¦è¾ƒä½ ({intimacy})ï¼Œå‡å°‘ä¸»åŠ¨äº¤äº’")
            return {"next_step": "silent"}
        
        # 4. è·å–ä¸Šæ¬¡äº¤äº’æ—¶é—´
        last_interaction_time = getattr(rel, "last_interaction_time", time.time() - 3600 * 2)
        
        # 5. è®¡ç®—ç”¨æˆ·åé¦ˆåˆ†æ•°
        feedback_score = interaction_manager.get_user_feedback_score(user_id)
        
        # 6. åˆ¤æ–­æ˜¯å¦åº”è¯¥å‘èµ·ä¸»åŠ¨äº¤äº’
        if not interaction_manager.should_initiate_interaction(
            user_id, 
            last_interaction_time, 
            feedback_score, 
            intimacy, 
            familiarity, 
            rel.trust, 
            rel.interest_match, 
            getattr(rel, "stamina", 80.0), 
            rel.interaction_patterns
        ):
            return {"next_step": "silent"}
            
        # 7. è·å–ä¸ªæ€§åŒ–è¯é¢˜
        topics = await interaction_manager.get_personalized_topics(user_id)
        
        # 8. ç”Ÿæˆä¸»åŠ¨å†…å®¹
        current_time = datetime.now().strftime("%H:%M")
        silence_hours = (time.time() - last_interaction_time) / 3600
        silence_duration = f"{silence_hours:.1f}å°æ—¶"
        stamina = getattr(rel, "stamina", 80.0)
        chat_type = "group" if is_group else "private"
        user_name = user_display_name
        
        content = await _generate_proactive_content(
            user_id, topics, intimacy, current_time, silence_duration, stamina, 
            chat_type, user_name, familiarity, rel.trust, rel.interest_match, rel.communication_style
        )
        
        if not content or len(content.strip()) < 5:
            logger.debug(f"[{ts}] ç”Ÿæˆçš„å†…å®¹ä¸ç¬¦åˆè¦æ±‚ï¼Œè·³è¿‡ä¸»åŠ¨äº¤äº’")
            return {"next_step": "silent"}
            
        # 9. æ„å»ºAIæ¶ˆæ¯
        ai_msg = AIMessage(content=content)
        
        # 10. æ›´æ–°æœ€åäº¤äº’æ—¶é—´
        rel.last_interaction_time = time.time()
        relation_db.update_relationship(user_id, user_id, rel)
        
        logger.info(f"[{ts}] ğŸ¤– [Proactive] INITIATE_TOPIC | Content: {content}")
        
        return {
            "messages": msgs + [ai_msg],
            "next_step": "speak",
            "internal_monologue": f"[Social Volition] Intent: initiate_topic, Reason: åŸºäºç”¨æˆ·æ²‰é»˜æ—¶é•¿å’Œå…³ç³»äº²å¯†åº¦çš„è‡ªç„¶è§¦å‘, ChatType: {'Group' if is_group else 'Private'}"
        }
        
    except Exception as e:
        logger.error(f"[{ts}] ä¸»åŠ¨äº¤äº’å¤±è´¥: {e}")
        return {"next_step": "silent"}
```
- **åŠŸèƒ½**: å®ç°æ™ºèƒ½ä½“çš„ä¸»åŠ¨ç¤¾äº¤èƒ½åŠ›ï¼Œæ ¹æ®ç”¨æˆ·å…³ç³»ã€äº¤äº’å†å²å’Œæ—¶é—´ç­‰å› ç´ ï¼Œå†³å®šæ˜¯å¦ä¸»åŠ¨å‘èµ·å¯¹è¯å¹¶ç”Ÿæˆç¬¦åˆäººè®¾çš„å†…å®¹
- **è®¾è®¡æ€è·¯**: 
  - åŸºäºè§„åˆ™å’Œæ¦‚ç‡çš„è§¦å‘æœºåˆ¶ï¼Œç»“åˆç”¨æˆ·å…³ç³»äº²å¯†åº¦ã€æ²‰é»˜æ—¶é•¿å’Œæ—¶é—´çª—å£ç­‰å› ç´ 
  - å®ç°ä¸ªæ€§åŒ–è¯é¢˜ç”Ÿæˆç³»ç»Ÿï¼Œä»ç”¨æˆ·å…´è¶£ã€è®°å¿†ç‚¹å’Œå‘é‡å­˜å‚¨ä¸­æå–ç›¸å…³è¯é¢˜
  - é‡‡ç”¨äººè®¾ä¸€è‡´æ€§è¿‡æ»¤æœºåˆ¶ï¼Œç¡®ä¿ç”Ÿæˆçš„å†…å®¹ç¬¦åˆAliceçš„æ ¸å¿ƒæ€§æ ¼ç‰¹ç‚¹
  - æ”¯æŒå¤šåœºæ™¯é€‚é…ï¼Œæ ¹æ®ç§èŠ/ç¾¤èŠã€äº²å¯†åº¦å’Œæ²Ÿé€šé£æ ¼è°ƒæ•´å†…å®¹
- **å½±å“èŒƒå›´**: 
  - æ™ºèƒ½ä½“çš„ä¸»åŠ¨ç¤¾äº¤èƒ½åŠ›å’Œç”¨æˆ·ç²˜æ€§
  - ç¤¾äº¤å…³ç³»çš„ç»´æŠ¤å’Œæ·±åŒ–
  - ç”¨æˆ·äº¤äº’é¢‘ç‡å’Œä½“éªŒè´¨é‡
  - ç³»ç»Ÿèµ„æºä½¿ç”¨å’Œæ€§èƒ½å¼€é”€

### 3.3 è®°å¿†ç³»ç»Ÿ

#### app/memory/combined_memory.py
```python
class CombinedMemory:
    def __init__(self):
        self.local_history = LocalHistory()
        self.vector_store = VectorStore()
        self.relation_db = RelationDB()
    
    async def get_relevant_memories(self, query: str, limit: int = 5) -> List[str]:
        # ä»ä¸åŒè®°å¿†æºè·å–ç›¸å…³è®°å¿†
        # æ•´åˆå¹¶è¿”å›
        pass
    
    async def add_memory(self, content: str, metadata: Dict[str, Any]):
        # æ·»åŠ è®°å¿†åˆ°æ‰€æœ‰ç›¸å…³å­˜å‚¨
        pass
```
- **åŠŸèƒ½**: æ•´åˆå¤šç§è®°å¿†æºï¼Œæä¾›ç»Ÿä¸€çš„è®°å¿†è®¿é—®æ¥å£
- **è®¾è®¡æ€è·¯**: ä½¿ç”¨ç»„åˆæ¨¡å¼ï¼Œå°†çŸ­æœŸè®°å¿†ã€é•¿æœŸè®°å¿†å’Œå…³ç³»è®°å¿†æ•´åˆåˆ°ä¸€èµ·
- **å½±å“èŒƒå›´**: æ™ºèƒ½ä½“çš„è®°å¿†èƒ½åŠ›ï¼Œå½±å“å›å¤çš„è¿è´¯æ€§å’Œä¸ªæ€§åŒ–

#### app/memory/vector_store.py
```python
class VectorStore:
    def __init__(self):
        # åˆå§‹åŒ– ChromaDB å®¢æˆ·ç«¯
        pass
    
    async def add_texts(self, texts: List[str], metadatas: List[Dict[str, Any]]):
        # å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡å¹¶å­˜å‚¨
        pass
    
    async def similarity_search(self, query: str, k: int = 5) -> List[Document]:
        # æ ¹æ®æŸ¥è¯¢å‘é‡æœç´¢ç›¸ä¼¼æ–‡æœ¬
        pass
```
- **åŠŸèƒ½**: ä½¿ç”¨ ChromaDB å­˜å‚¨å’Œæ£€ç´¢é•¿æœŸè®°å¿†
- **è®¾è®¡æ€è·¯**: åˆ©ç”¨å‘é‡æ•°æ®åº“çš„ç›¸ä¼¼æ€§æœç´¢èƒ½åŠ›ï¼Œå®ç°é«˜æ•ˆçš„è®°å¿†æ£€ç´¢
- **å½±å“èŒƒå›´**: æ™ºèƒ½ä½“çš„é•¿æœŸè®°å¿†èƒ½åŠ›ï¼Œå½±å“å¯¹è¿‡å»å¯¹è¯å†…å®¹çš„å›å¿†

#### app/memory/smart_retrieval.py
```python
class SmartRetrieval:
    """
    æ™ºèƒ½æ£€ç´¢ç³»ç»Ÿ
    ç”¨äºä»è®°å¿†ä¸­æ™ºèƒ½æ£€ç´¢ç›¸å…³ä¿¡æ¯ï¼Œæ”¯æŒå¤šç§æ£€ç´¢ç­–ç•¥
    """
    
    def __init__(self):
        # åˆå§‹åŒ–æ™ºèƒ½æ£€ç´¢ç³»ç»Ÿ
        pass
    
    async def retrieve_relevant_memories(self, query: str, context: Dict, limit: int = 5) -> List[Dict]:
        # æ£€ç´¢ä¸æŸ¥è¯¢ç›¸å…³çš„è®°å¿†
        pass
    
    async def rank_memories(self, memories: List[Dict], query: str) -> List[Dict]:
        # å¯¹æ£€ç´¢åˆ°çš„è®°å¿†è¿›è¡Œæ’åº
        pass
    
    async def summarize_retrieved_memories(self, memories: List[Dict], query: str) -> str:
        # æ€»ç»“æ£€ç´¢åˆ°çš„è®°å¿†
        pass
```
- **åŠŸèƒ½**: å®ç°æ™ºèƒ½è®°å¿†æ£€ç´¢ï¼Œæ”¯æŒå¤šç§æ£€ç´¢ç­–ç•¥å’Œç»“æœæ’åº
- **è®¾è®¡æ€è·¯**: 
  - ç»“åˆå‘é‡ç›¸ä¼¼åº¦ã€æ—¶é—´è¡°å‡å’Œé‡è¦æ€§æƒé‡è¿›è¡Œæ£€ç´¢
  - å®ç°è®°å¿†çš„æ™ºèƒ½æ’åºå’Œæ€»ç»“
  - æ”¯æŒä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æ£€ç´¢ç­–ç•¥
- **å½±å“èŒƒå›´**: 
  - è®°å¿†æ£€ç´¢çš„å‡†ç¡®æ€§å’Œç›¸å…³æ€§
  - æ™ºèƒ½ä½“å¯¹è¿‡å»ä¿¡æ¯çš„åˆ©ç”¨æ•ˆç‡
  - å›å¤çš„è¿è´¯æ€§å’Œä¸ªæ€§åŒ–ç¨‹åº¦

#### app/memory/relation_db.py
```python
class RelationDB:
    """
    å…³ç³»æ•°æ®åº“
    ç”¨äºå­˜å‚¨å’Œç®¡ç†ç”¨æˆ·ä¹‹é—´çš„å…³ç³»
    """
    
    def __init__(self):
        # åˆå§‹åŒ–å…³ç³»æ•°æ®åº“
        pass
    
    async def get_relation(self, user1: str, user2: str) -> Dict[str, Any]:
        # è·å–ä¸¤ä¸ªç”¨æˆ·ä¹‹é—´çš„å…³ç³»
        pass
    
    async def update_relation(self, user1: str, user2: str, relation_data: Dict[str, Any]):
        # æ›´æ–°ä¸¤ä¸ªç”¨æˆ·ä¹‹é—´çš„å…³ç³»
        pass
    
    async def get_user_relations(self, user: str) -> List[Dict[str, Any]]:
        # è·å–ç”¨æˆ·çš„æ‰€æœ‰å…³ç³»
        pass
```
- **åŠŸèƒ½**: ç®¡ç†ç”¨æˆ·ä¹‹é—´çš„å…³ç³»æ•°æ®ï¼Œæ”¯æŒå…³ç³»çš„å­˜å‚¨å’Œæ£€ç´¢
- **è®¾è®¡æ€è·¯**: 
  - ä½¿ç”¨å›¾æ•°æ®åº“æˆ–å…³ç³»å‹æ•°æ®åº“å­˜å‚¨å…³ç³»
  - æ”¯æŒå¤šç»´åº¦çš„å…³ç³»å±æ€§ï¼ˆäº²å¯†åº¦ã€å…³ç³»ç±»å‹ç­‰ï¼‰
  - æä¾›é«˜æ•ˆçš„å…³ç³»æŸ¥è¯¢æ¥å£
- **å½±å“èŒƒå›´**: 
  - æ™ºèƒ½ä½“å¯¹ç”¨æˆ·å…³ç³»çš„ç†è§£å’Œç»´æŠ¤
  - ä¸ªæ€§åŒ–äº¤äº’ç­–ç•¥çš„åˆ¶å®š
  - ç¤¾äº¤åŠŸèƒ½çš„å®ç°

#### app/memory/local_history.py
```python
class LocalHistory:
    """
    æœ¬åœ°å†å²è®°å½•
    ç”¨äºå­˜å‚¨å’Œç®¡ç†çŸ­æœŸå¯¹è¯å†å²
    """
    
    def __init__(self, max_history_length: int = 20):
        # åˆå§‹åŒ–æœ¬åœ°å†å²è®°å½•
        pass
    
    async def add_message(self, message: Dict[str, Any]):
        # æ·»åŠ æ¶ˆæ¯åˆ°å†å²è®°å½•
        pass
    
    async def get_history(self, session_id: str, limit: int = 10) -> List[Dict[str, Any]]:
        # è·å–å†å²è®°å½•
        pass
    
    async def clear_history(self, session_id: str):
        # æ¸…é™¤å†å²è®°å½•
        pass
```
- **åŠŸèƒ½**: ç®¡ç†çŸ­æœŸå¯¹è¯å†å²ï¼Œæ”¯æŒæ¶ˆæ¯çš„æ·»åŠ ã€æ£€ç´¢å’Œæ¸…é™¤
- **è®¾è®¡æ€è·¯**: 
  - å®ç°å›ºå®šé•¿åº¦çš„å†å²è®°å½•çª—å£
  - æ”¯æŒä¼šè¯éš”ç¦»ï¼Œä¸åŒä¼šè¯æœ‰ç‹¬ç«‹çš„å†å²è®°å½•
  - ä¼˜åŒ–å†å²è®°å½•çš„å­˜å‚¨å’Œæ£€ç´¢æ€§èƒ½
- **å½±å“èŒƒå›´**: 
  - å¯¹è¯ä¸Šä¸‹æ–‡çš„ç†è§£å’Œç»´æŠ¤
  - çŸ­æœŸè®°å¿†çš„ç®¡ç†
  - å›å¤çš„è¿è´¯æ€§å’Œä¸Šä¸‹æ–‡ç›¸å…³æ€§

### 3.4 åå°ä»»åŠ¡

#### app/background/dream.py
```python
async def run_dream_cycle():
    # æ£€ç´¢è¿‘æœŸè®°å¿†
    # åˆ†æè®°å¿†é—´çš„å…³è”
    # ç”Ÿæˆæ–°çš„è®°å¿†æ‘˜è¦
    # æ›´æ–°å‘é‡æ•°æ®åº“
    pass
```
- **åŠŸèƒ½**: æ¨¡æ‹Ÿäººç±»åšæ¢¦ï¼Œæ•´ç†å’Œå›ºåŒ–ç¢ç‰‡åŒ–è®°å¿†
- **è®¾è®¡æ€è·¯**: å®šæ—¶è§¦å‘ï¼Œå¯¹è¿‘æœŸè®°å¿†è¿›è¡Œæ€»ç»“å’Œå…³è”ï¼Œå¢å¼ºè®°å¿†çš„è¿è´¯æ€§
- **å½±å“èŒƒå›´**: æ™ºèƒ½ä½“çš„é•¿æœŸè®°å¿†è´¨é‡ï¼Œå½±å“è®°å¿†çš„ç»„ç»‡å’Œæ£€ç´¢æ•ˆç‡

### 3.5 å·¥å…·ç³»ç»Ÿ

#### app/tools/web_search.py
```python
class WebSearchTool(BaseTool):
    name: str = "web_search"
    description: str = "ç”¨äºæœç´¢æœ€æ–°çš„ç½‘ç»œä¿¡æ¯"
    
    async def _arun(self, query: str, **kwargs) -> str:
        # è°ƒç”¨ Tavily API è¿›è¡Œæœç´¢
        # å¤„ç†æœç´¢ç»“æœ
        # è¿”å›æ ¼å¼åŒ–çš„æœç´¢ç»“æœ
        pass
```
- **åŠŸèƒ½**: æä¾›è”ç½‘æœç´¢èƒ½åŠ›ï¼Œè·å–æœ€æ–°ä¿¡æ¯
- **è®¾è®¡æ€è·¯**: å°è£… Tavily æœç´¢ APIï¼Œæä¾›ç»Ÿä¸€çš„å·¥å…·è°ƒç”¨æ¥å£
- **å½±å“èŒƒå›´**: æ™ºèƒ½ä½“è·å–å¤–éƒ¨ä¿¡æ¯çš„èƒ½åŠ›ï¼Œå½±å“å¯¹å®æ—¶æˆ–ç‰¹å®šé¢†åŸŸé—®é¢˜çš„å›ç­”è´¨é‡

#### app/tools/base_tool.py
```python
class BaseTool:
    """
    å·¥å…·åŸºç±»
    æ‰€æœ‰å·¥å…·éƒ½å¿…é¡»ç»§æ‰¿æ­¤ç±»
    """
    
    name: str = "base_tool"
    description: str = "åŸºç¡€å·¥å…·ç±»"
    
    async def _arun(self, **kwargs) -> Any:
        """
        å¼‚æ­¥è¿è¡Œå·¥å…·çš„ä¸»è¦æ–¹æ³•
        å­ç±»å¿…é¡»å®ç°æ­¤æ–¹æ³•
        """
        pass
    
    def format_description(self) -> str:
        """
        æ ¼å¼åŒ–å·¥å…·æè¿°ï¼Œç”¨äºLLMè°ƒç”¨
        """
        pass
```
- **åŠŸèƒ½**: å®šä¹‰å·¥å…·çš„åŸºç¡€æ¥å£ï¼Œæ‰€æœ‰å·¥å…·éƒ½å¿…é¡»ç»§æ‰¿æ­¤ç±»
- **è®¾è®¡æ€è·¯**: 
  - æä¾›ç»Ÿä¸€çš„å·¥å…·æ¥å£ï¼Œæ–¹ä¾¿æ‰©å±•å’Œç®¡ç†
  - æ”¯æŒå¼‚æ­¥å·¥å…·è°ƒç”¨
  - æä¾›å·¥å…·æè¿°æ ¼å¼åŒ–åŠŸèƒ½ï¼Œç”¨äºLLMè°ƒç”¨
- **å½±å“èŒƒå›´**: 
  - æ‰€æœ‰å·¥å…·çš„å®ç°æ–¹å¼
  - å·¥å…·çš„è°ƒç”¨å’Œç®¡ç†æ–¹å¼
  - ä¸LLMçš„äº¤äº’æ–¹å¼

#### app/tools/image_gen.py
```python
# å‡è®¾ä½ å®‰è£…äº† openai åŒ…: pip install openai
from openai import OpenAI
from app.core.config import config
from app.tools.base_tool import BaseTool, ToolParam

# client = OpenAI(api_key=config.OPENAI_API_KEY)
client = OpenAI(
    api_key=config.SILICONFLOW_API_KEY,
    base_url=config.SILICONFLOW_BASE_URL
)


class ImageGenTool(BaseTool):
    """å›¾åƒç”Ÿæˆå·¥å…·"""
    
    name = "generate_image"
    description = "Generate an image based on the text description (prompt). Use this when the user explicitly asks to 'draw', 'paint', or 'generate an image'."
    parameters = [
        ToolParam(
            name="prompt",
            param_type="string",
            description="The image generation prompt",
            required=True
        ),
        ToolParam(
            name="size",
            param_type="string",
            description="The image size (default: 1024x1024)",
            required=False,
            enum_values=["1024x1024", "512x512", "256x256"]
        )
    ]
    available_for_llm = True
    
    async def execute(self, prompt: str, size: str = "1024x1024", **kwargs) -> dict:
        """æ‰§è¡Œå›¾åƒç”Ÿæˆ"""
        try:
            response = await client.images.agenerate(
                model="Qwen/Qwen-Image-Edit-2509",
                prompt=prompt,
                size=size,
                quality="standard",
                n=1,
            )
            return {
                "success": True,
                "result": response.data[0].url,
                "error": ""
            }
        except Exception as e:
            error_msg = f"Image generation failed: {e}"
            return {
                "success": False,
                "result": "",
                "error": error_msg
            }


# å¯¼å‡ºå·¥å…·å®ä¾‹
image_gen_tool = ImageGenTool()


async def generate_image(prompt: str) -> str:
    """å…¼å®¹æ—§æ¥å£çš„å›¾åƒç”Ÿæˆå‡½æ•°"""
    result = await image_gen_tool.execute(prompt=prompt)
    return result["result"] if result["success"] else result["error"]
```
- **åŠŸèƒ½**: æ ¹æ®æ–‡æœ¬æç¤ºç”Ÿæˆå›¾åƒï¼Œæ”¯æŒä¸åŒå°ºå¯¸çš„å›¾åƒè¾“å‡ºï¼Œå…¼å®¹æ—§æ¥å£è°ƒç”¨
- **è®¾è®¡æ€è·¯**: 
  - ä½¿ç”¨OpenAIå®¢æˆ·ç«¯è°ƒç”¨å›¾åƒç”ŸæˆAPI
  - é…ç½®ä¸ºä½¿ç”¨SiliconFlowæœåŠ¡
  - æ”¯æŒ1024x1024ã€512x512ã€256x256ä¸‰ç§å›¾åƒå°ºå¯¸
  - æä¾›ç»Ÿä¸€çš„å·¥å…·æ¥å£å’Œé”™è¯¯å¤„ç†æœºåˆ¶
  - ä¿ç•™å…¼å®¹æ—§æ¥å£çš„å‡½æ•°
- **å½±å“èŒƒå›´**: 
  - æ™ºèƒ½ä½“çš„åˆ›æ„è¡¨è¾¾èƒ½åŠ›
  - å¯¹è§†è§‰å†…å®¹çš„ç”Ÿæˆèƒ½åŠ›
  - ç”¨æˆ·ä½“éªŒå’Œäº¤äº’æ•ˆæœ
  - APIè°ƒç”¨æˆæœ¬å’Œæ€§èƒ½

#### app/tools/data_analysis.py
```python
from langchain_experimental.utilities import PythonREPL
from app.tools.base_tool import BaseTool, ToolParam
import asyncio

repl = PythonREPL()


class DataAnalysisTool(BaseTool):
    """æ•°æ®åˆ†æå·¥å…·"""
    
    name = "run_python_analysis"
    description = "Execute Python code to perform data analysis, math calculations, or string processing. Input should be valid Python code. The code should print() the final result."
    parameters = [
        ToolParam(
            name="code",
            param_type="string",
            description="The Python code to execute",
            required=True
        )
    ]
    available_for_llm = True
    
    async def execute(self, code: str, **kwargs) -> dict:
        """æ‰§è¡ŒPythonä»£ç åˆ†æ"""
        try:
            # å®‰å…¨æ£€æŸ¥ï¼šç¦æ­¢å¯¼å…¥å±é™©æ¨¡å—
            dangerous_imports = ["import os", "import sys", "import subprocess", "import shutil"]
            for dangerous_import in dangerous_imports:
                if dangerous_import in code:
                    return {
                        "success": False,
                        "result": "",
                        "error": "Security Alert: System modules are restricted."
                    }
            
            # åœ¨å•ç‹¬çš„æ‰§è¡Œå™¨ä¸­è¿è¡ŒåŒæ­¥ä»£ç ï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(None, repl.run, code)
            
            return {
                "success": True,
                "result": f"Execution Result:\n{result}",
                "error": ""
            }
        except Exception as e:
            error_msg = f"Python Error: {e}"
            return {
                "success": False,
                "result": "",
                "error": error_msg
            }


# å¯¼å‡ºå·¥å…·å®ä¾‹
data_analysis_tool = DataAnalysisTool()


async def run_python_analysis(code: str) -> str:
    """å…¼å®¹æ—§æ¥å£çš„æ•°æ®åˆ†æå‡½æ•°"""
    result = await data_analysis_tool.execute(code=code)
    return result["result"] if result["success"] else result["error"]
```
- **åŠŸèƒ½**: æä¾›Pythonä»£ç æ‰§è¡Œç¯å¢ƒï¼Œç”¨äºæ•°æ®åˆ†æã€æ•°å­¦è®¡ç®—å’Œå­—ç¬¦ä¸²å¤„ç†ï¼Œæ”¯æŒLLMè°ƒç”¨
- **è®¾è®¡æ€è·¯**: 
  - åŸºäºLangChainçš„PythonREPLå®ç°ä»£ç æ‰§è¡ŒåŠŸèƒ½
  - é›†æˆå®‰å…¨æ£€æŸ¥æœºåˆ¶ï¼Œç¦æ­¢å¯¼å…¥å±é™©ç³»ç»Ÿæ¨¡å—
  - é‡‡ç”¨å¼‚æ­¥æ‰§è¡Œæ–¹å¼ï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
  - æä¾›ç»Ÿä¸€çš„å·¥å…·æ¥å£å’Œé”™è¯¯å¤„ç†æœºåˆ¶
  - ä¿ç•™å…¼å®¹æ—§æ¥å£çš„å‡½æ•°
- **å½±å“èŒƒå›´**: 
  - æ™ºèƒ½ä½“çš„æ•°æ®åˆ†æå’Œè®¡ç®—èƒ½åŠ›
  - ç³»ç»Ÿå®‰å…¨æ€§å’Œç¨³å®šæ€§
  - å¯¹å¤æ‚é—®é¢˜çš„è§£å†³èƒ½åŠ›
  - èµ„æºä½¿ç”¨å’Œæ€§èƒ½å¼€é”€

#### app/tools/forward_message.py
```python
import json
import logging
from typing import Optional, Dict, Any
from sqlalchemy.exc import SQLAlchemyError

# å¯¼å…¥åŸºç¡€å·¥å…·ç±»
from app.tools.base_tool import BaseTool, ToolParam

# å¯¼å…¥æ•°æ®åº“é…ç½®
from app.core.database import SessionLocal, ForwardMessageModel

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


class ForwardMessageTool(BaseTool):
    """
    è·å–å®Œæ•´çš„è½¬å‘æ¶ˆæ¯å†…å®¹å·¥å…·ã€‚å½“éœ€è¦æŸ¥çœ‹è¢«çœç•¥çš„è½¬å‘æ¶ˆæ¯è¯¦æƒ…æ—¶ä½¿ç”¨æ­¤å·¥å…·ã€‚
    """
    name = "get_forward_message"
    description = "è·å–å®Œæ•´çš„è½¬å‘æ¶ˆæ¯å†…å®¹ã€‚å½“éœ€è¦æŸ¥çœ‹è¢«çœç•¥çš„è½¬å‘æ¶ˆæ¯è¯¦æƒ…æ—¶ä½¿ç”¨æ­¤å·¥å…·ã€‚"
    available_for_llm = True
    
    parameters = [
        ToolParam(
            name="forward_id",
            param_type="string",
            description="è½¬å‘æ¶ˆæ¯çš„IDï¼Œæ ¼å¼ä¸ºæ•°å­—å­—ç¬¦ä¸²",
            required=True
        )
    ]
    
    async def execute(self, **kwargs) -> Dict[str, Any]:
        """
        æ‰§è¡Œè·å–è½¬å‘æ¶ˆæ¯çš„æ“ä½œ
        
        Args:
            forward_id: è½¬å‘æ¶ˆæ¯çš„ID
            
        Returns:
            Dict[str, Any]: å·¥å…·æ‰§è¡Œç»“æœ
        """
        forward_id = kwargs.get("forward_id")
        
        try:
            with SessionLocal() as db:
                # æŸ¥è¯¢æ•°æ®åº“
                forward_message = db.query(ForwardMessageModel).filter(ForwardMessageModel.forward_id == forward_id).first()
                
                if forward_message:
                    # æ›´æ–°æœ€åè®¿é—®æ—¶é—´
                    db.commit()
                    
                    logger.info(f"ğŸ” [Forward Tool] Retrieved forward message: {forward_id}")
                    
                    return {
                        "success": True,
                        "result": {
                            "forward_id": forward_id,
                            "content": forward_message.full_content,
                            "summary": forward_message.summary,
                            "message_count": forward_message.message_count,
                            "image_count": forward_message.image_count
                        },
                        "error": None
                    }
                else:
                    logger.warning(f"ğŸ” [Forward Tool] Forward message not found: {forward_id}")
                    return {
                        "success": False,
                        "result": None,
                        "error": f"æœªæ‰¾åˆ°IDä¸º {forward_id} çš„è½¬å‘æ¶ˆæ¯"
                    }
        
        except SQLAlchemyError as e:
            logger.error(f"âŒ [Forward Tool] Database error: {e}")
            return {
                "success": False,
                "result": None,
                "error": f"æ•°æ®åº“æŸ¥è¯¢é”™è¯¯: {str(e)}"
            }
        except Exception as e:
            logger.error(f"âŒ [Forward Tool] Unexpected error: {e}")
            return {
                "success": False,
                "result": None,
                "error": f"å‘ç”Ÿæ„å¤–é”™è¯¯: {str(e)}"
            }


class ListForwardMessagesTool(BaseTool):
    """
    åˆ—å‡ºæœ€è¿‘å­˜å‚¨çš„è½¬å‘æ¶ˆæ¯å·¥å…·ã€‚
    """
    name = "list_forward_messages"
    description = "åˆ—å‡ºæœ€è¿‘å­˜å‚¨çš„è½¬å‘æ¶ˆæ¯ã€‚"
    available_for_llm = True
    
    parameters = [
        ToolParam(
            name="limit",
            param_type="integer",
            description="è¿”å›çš„æœ€å¤§æ•°é‡ï¼Œé»˜è®¤10",
            required=False
        )
    ]
    
    async def execute(self, **kwargs) -> Dict[str, Any]:
        """
        æ‰§è¡Œåˆ—å‡ºè½¬å‘æ¶ˆæ¯çš„æ“ä½œ
        
        Args:
            limit: è¿”å›çš„æœ€å¤§æ•°é‡
            
        Returns:
            Dict[str, Any]: å·¥å…·æ‰§è¡Œç»“æœ
        """
        limit = kwargs.get("limit", 10)
        
        try:
            with SessionLocal() as db:
                # æŸ¥è¯¢æœ€è¿‘çš„è½¬å‘æ¶ˆæ¯
                forward_messages = db.query(ForwardMessageModel).order_by(ForwardMessageModel.created_at.desc()).limit(limit).all()
                
                result_list = []
                for forward in forward_messages:
                    result_list.append({
                        "forward_id": forward.forward_id,
                        "summary": forward.summary,
                        "message_count": forward.message_count,
                        "image_count": forward.image_count,
                        "created_at": forward.created_at.isoformat(),
                        "accessed_at": forward.accessed_at.isoformat()
                    })
                
                logger.info(f"ğŸ“‹ [Forward Tool] Listed {len(result_list)} forward messages")
                
                return {
                    "success": True,
                    "result": result_list,
                    "error": None
                }
        
        except SQLAlchemyError as e:
            logger.error(f"âŒ [Forward Tool] Database error: {e}")
            return {
                "success": False,
                "result": None,
                "error": f"æ•°æ®åº“æŸ¥è¯¢é”™è¯¯: {str(e)}"
            }
        except Exception as e:
            logger.error(f"âŒ [Forward Tool] Unexpected error: {e}")
            return {
                "success": False,
                "result": None,
                "error": f"å‘ç”Ÿæ„å¤–é”™è¯¯: {str(e)}"
            }
```
- **åŠŸèƒ½**: 
  - è·å–å®Œæ•´çš„è½¬å‘æ¶ˆæ¯å†…å®¹ï¼Œæ”¯æŒæŸ¥çœ‹è¢«çœç•¥çš„è½¬å‘æ¶ˆæ¯è¯¦æƒ…
  - åˆ—å‡ºæœ€è¿‘å­˜å‚¨çš„è½¬å‘æ¶ˆæ¯ï¼Œæ”¯æŒåˆ†é¡µæŸ¥è¯¢
- **è®¾è®¡æ€è·¯**: 
  - ä½¿ç”¨SQLAlchemyæ“ä½œæ•°æ®åº“ï¼ŒæŸ¥è¯¢è½¬å‘æ¶ˆæ¯è®°å½•
  - æä¾›ä¸¤ä¸ªç‹¬ç«‹å·¥å…·ç±»ï¼Œåˆ†åˆ«å¤„ç†è·å–å•ä¸ªæ¶ˆæ¯å’Œåˆ—å‡ºå¤šä¸ªæ¶ˆæ¯çš„éœ€æ±‚
  - å®ç°å®Œæ•´çš„é”™è¯¯å¤„ç†æœºåˆ¶ï¼ŒåŒ…æ‹¬æ•°æ®åº“é”™è¯¯å’Œæ„å¤–å¼‚å¸¸
  - æ·»åŠ è¯¦ç»†çš„æ—¥å¿—è®°å½•ï¼Œä¾¿äºè°ƒè¯•å’Œç›‘æ§
  - æ”¯æŒLLMè°ƒç”¨ï¼Œæä¾›æ ‡å‡†åŒ–çš„å‚æ•°å’Œè¿”å›æ ¼å¼
- **å½±å“èŒƒå›´**: 
  - æ™ºèƒ½ä½“å¤„ç†è½¬å‘æ¶ˆæ¯çš„èƒ½åŠ›
  - æ•°æ®åº“æ“ä½œå’Œæ€§èƒ½
  - ç”¨æˆ·æŸ¥çœ‹è½¬å‘æ¶ˆæ¯è¯¦æƒ…çš„ä½“éªŒ

#### app/tools/tool_registry.py
```python
class ToolRegistry:
    def __init__(self):
        self.tools = {}
    
    def register_tool(self, tool: BaseTool):
        # æ³¨å†Œå·¥å…·
        pass
    
    def get_tool(self, name: str) -> BaseTool:
        # è·å–å·¥å…·å®ä¾‹
        pass
    
    def get_all_tools(self) -> List[BaseTool]:
        # è·å–æ‰€æœ‰æ³¨å†Œçš„å·¥å…·
        pass
```
- **åŠŸèƒ½**: ç®¡ç†æ‰€æœ‰å¯ç”¨å·¥å…·ï¼Œæä¾›å·¥å…·æ³¨å†Œå’Œè·å–åŠŸèƒ½
- **è®¾è®¡æ€è·¯**: ä½¿ç”¨æ³¨å†Œè¡¨æ¨¡å¼ï¼Œæ–¹ä¾¿æ·»åŠ å’Œç®¡ç†å·¥å…·
- **å½±å“èŒƒå›´**: æ™ºèƒ½ä½“å¯ç”¨çš„å·¥å…·é›†ï¼Œå½±å“å…¶è§£å†³é—®é¢˜çš„èƒ½åŠ›

### 3.6 æ’ä»¶ç³»ç»Ÿ

#### app/plugins/base_plugin.py
```python
class BasePlugin:
    name: str = "base_plugin"
    description: str = "åŸºç¡€æ’ä»¶ç±»"
    
    async def initialize(self):
        # æ’ä»¶åˆå§‹åŒ–
        pass
    
    async def process(self, state: AgentState) -> AgentState:
        # å¤„ç†æ¶ˆæ¯
        return state
    
    async def cleanup(self):
        # æ’ä»¶æ¸…ç†
        pass
```
- **åŠŸèƒ½**: å®šä¹‰æ’ä»¶çš„åŸºç¡€æ¥å£ï¼Œæ˜¯æ‰€æœ‰æ’ä»¶çš„çˆ¶ç±»
- **è®¾è®¡æ€è·¯**: ä½¿ç”¨é¢å‘å¯¹è±¡è®¾è®¡ï¼Œæä¾›ç»Ÿä¸€çš„æ’ä»¶æ¥å£ï¼Œæ–¹ä¾¿æ‰©å±•
- **å½±å“èŒƒå›´**: æ’ä»¶ç³»ç»Ÿçš„æ‰©å±•æ€§ï¼Œå½±å“æ–°å¢æ’ä»¶çš„å¼€å‘éš¾åº¦

#### app/plugins/emoji_plugin/emoji_manager.py
```python
class EmojiManager:
    def __init__(self):
        # åŠ è½½è¡¨æƒ…åŒ…æ˜ å°„
        pass
    
    def get_emoji_by_name(self, name: str) -> str:
        # æ ¹æ®åç§°è·å–è¡¨æƒ…åŒ…è·¯å¾„
        pass
    
    def analyze_emoji(self, emoji_path: str) -> Dict[str, Any]:
        # åˆ†æè¡¨æƒ…åŒ…å†…å®¹
        pass
```
- **åŠŸèƒ½**: ç®¡ç†è¡¨æƒ…åŒ…ï¼Œæä¾›è¡¨æƒ…åŒ…çš„è·å–å’Œåˆ†æåŠŸèƒ½
- **è®¾è®¡æ€è·¯**: å°è£…è¡¨æƒ…åŒ…ç›¸å…³åŠŸèƒ½ï¼Œæ–¹ä¾¿æ™ºèƒ½ä½“ä½¿ç”¨å’Œç†è§£è¡¨æƒ…åŒ…
- **å½±å“èŒƒå›´**: æ™ºèƒ½ä½“å¯¹è¡¨æƒ…åŒ…çš„å¤„ç†èƒ½åŠ›ï¼Œå½±å“ä¸ç”¨æˆ·çš„æƒ…æ„Ÿäº¤äº’

#### app/plugins/emoji_plugin/emoji_service.py
```python
# === Pythonä»£ç æ–‡ä»¶: emoji_service.py ===
"""
è¡¨æƒ…åŒ…æœåŠ¡ - ç»Ÿä¸€çš„è¡¨æƒ…åŒ…åŠŸèƒ½å…¥å£ï¼Œæ•´åˆè¯†åˆ«ã€åˆ†æã€ç®¡ç†å’Œå›å¤åŠŸèƒ½
"""

import logging
import random
import re
import hashlib
from typing import List, Dict, Optional, Tuple, Any
from PIL import Image
import io
import base64
from functools import lru_cache

from .emoji_manager import EmojiInfo, get_emoji_manager
from app.graph.nodes.perception import _classify_image, _analyze_emoji_with_llm, _process_image_with_llm

logger = logging.getLogger("EmojiService")


class EmojiService:
    """è¡¨æƒ…åŒ…æœåŠ¡ç±» - ç»Ÿä¸€ç®¡ç†è¡¨æƒ…åŒ…ç›¸å…³åŠŸèƒ½"""
    
    # ç±»å¸¸é‡ï¼šæƒ…ç»ªå…³é”®è¯æ˜ å°„
    EMOTION_KEYWORDS = {
        "å¼€å¿ƒ": ["å¼€å¿ƒ", "å¿«ä¹", "é«˜å…´", "æ„‰æ‚¦", "å–œæ‚¦", "æ¬¢ä¹", "å…´å¥‹", "æ„‰å¿«", "æ¬¢å¿«", "å¼€æ€€", "ä¹å‘µ", "å–œç¬‘é¢œå¼€", "çœ‰å¼€çœ¼ç¬‘"],
        "éš¾è¿‡": ["éš¾è¿‡", "æ‚²ä¼¤", "ä¼¤å¿ƒ", "ç—›è‹¦", "éš¾å—", "å¿§ä¼¤", "å¿§éƒ", "æ²®ä¸§", "å¤±è½", "æ‚²å“€", "æ‚²ç—›", "å“€ä¼¤", "å¿ƒå¦‚åˆ€å‰²"],
        "ç”Ÿæ°”": ["ç”Ÿæ°”", "æ„¤æ€’", "æ¼ç«", "å‘ç«", "æ¼æ€’", "æ°”æ„¤", "åŠ¨æ€’", "æ€’ç«ä¸­çƒ§", "æ€’ä¸å¯é"],
        "æƒŠè®¶": ["æƒŠè®¶", "æƒŠå–œ", "åƒæƒŠ", "éœ‡æƒŠ", "è¯§å¼‚", "æƒŠå¼‚", "éª‡ç„¶", "æƒŠå¹", "ç ç›®ç»“èˆŒ", "ç›®çªå£å‘†"],
        "å¯çˆ±": ["å¯çˆ±", "èŒ", "èŒç‰©", "èŒåŒ–", "å¡å“‡ä¼Š"],
        "æç¬‘": ["æç¬‘", "å¹½é»˜", "é£è¶£", "å¥½ç¬‘", "æ»‘ç¨½", "é€—ä¹", "ç¬‘æ­»", "ç¬‘æ­»æˆ‘äº†", "å¤ªæç¬‘äº†"],
        "æ— å¥ˆ": ["æ— å¥ˆ", "æ— è¯­", "æ²¡æ³•", "æ²¡åŠæ³•", "æ— å¥ˆä½•", "æ— èƒ½ä¸ºåŠ›", "æ— å¯å¥ˆä½•"],
        "å°´å°¬": ["å°´å°¬", "éš¾å ª", "éš¾ä¸ºæƒ…", "ä¸å¥½æ„æ€", "å°´å°¬ç™Œ"],
        "å›°æƒ‘": ["å›°æƒ‘", "ç–‘é—®", "ç–‘æƒ‘", "ä¸è§£", "è¿·èŒ«", "æ‡µ", "æ‡µåœˆ", "ä¸€å¤´é›¾æ°´"],
        "å¹³é™": ["å¹³é™", "å¹³å’Œ", "å¹³ç¨³", "å®é™", "å®‰é™", "å¿ƒå¹³æ°”å’Œ", "å¹³é™å¦‚æ°´"]
    }
    
    # ç±»å¸¸é‡ï¼šå¦å®šè¯åˆ—è¡¨
    NEGATION_WORDS = ["ä¸", "æ²¡", "æ²¡æœ‰", "ä¸æ˜¯", "ä¸ä¼š", "ä¸è¦", "ä¸è¡Œ", "ä¸èƒ½", "æ— æ³•"]
    
    def __init__(self):
        self.emoji_manager = get_emoji_manager()
        # å›¾ç‰‡åˆ†ç±»ç»“æœç¼“å­˜
        self._image_classification_cache = {}
        # è¡¨æƒ…åŒ…åˆ†æç»“æœç¼“å­˜
        self._emoji_analysis_cache = {}
        # ä¸Šä¸‹æ–‡æƒ…ç»ªæå–ç¼“å­˜
        self._context_emotion_cache = {}
        # ç¼“å­˜å¤§å°é™åˆ¶
        self._CACHE_SIZE = 1000
        # è®°å½•æœ€è¿‘ä¿å­˜çš„è¡¨æƒ…åŒ…å“ˆå¸Œå€¼ï¼Œç”¨äºé¿å…é‡å¤å‘é€
        self._recently_saved_emojis = []
        # æœ€è¿‘ä¿å­˜çš„è¡¨æƒ…åŒ…æ•°é‡é™åˆ¶
        self._MAX_RECENT_EMOJIS = 2
    
    async def is_emoji(self, image: Image.Image, file_size_kb: float) -> bool:
        """
        åˆ¤æ–­å›¾ç‰‡æ˜¯å¦ä¸ºè¡¨æƒ…åŒ…
        
        Args:
            image: PIL Imageå¯¹è±¡
            file_size_kb: å›¾ç‰‡æ–‡ä»¶å¤§å°ï¼ˆKBï¼‰
            
        Returns:
            bool: æ˜¯å¦ä¸ºè¡¨æƒ…åŒ…
        """
        try:
            return await _classify_image(image, file_size_kb) == "sticker"
        except Exception as e:
            logger.error(f"âŒ å›¾ç‰‡åˆ†ç±»å¤±è´¥: {e}")
            # å‡ºé”™æ—¶ä½¿ç”¨æœ¬åœ°å¤‡ä»½é€»è¾‘
            try:
                width, height = image.size
                ratio = width / height if height > 0 else 0
                has_transparency = image.mode in ('RGBA', 'LA') or ('transparency' in image.info)
                return has_transparency or width <= 1024 or height <= 1024 or file_size_kb < 2048
            except:
                return False
    
    async def analyze_emoji(self, base64_data: str) -> Dict[str, Any]:
        """
        åˆ†æè¡¨æƒ…åŒ…ï¼Œç”Ÿæˆæƒ…ç»ªæ ‡ç­¾ã€æè¿°å’Œåˆ†ç±»
        
        Args:
            base64_data: å›¾ç‰‡çš„base64ç¼–ç æ•°æ®
            
        Returns:
            dict: åŒ…å«åˆ†æç»“æœçš„å­—å…¸
        """
        try:
            return await _analyze_emoji_with_llm(base64_data)
        except Exception as e:
            logger.error(f"âŒ åˆ†æè¡¨æƒ…åŒ…æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return {
                "emotions": ["æœªçŸ¥"],
                "description": "æ— æ³•åˆ†æçš„è¡¨æƒ…åŒ…",
                "category": "å…¶ä»–"
            }
    
    async def process_emoji(self, image_url: str, user_qq: str = "", user_nickname: str = "") -> Dict[str, Any]:
        """
        å®Œæ•´å¤„ç†è¡¨æƒ…åŒ…æµç¨‹ï¼šä¸‹è½½ã€è¯†åˆ«ã€åˆ†æã€ä¿å­˜
        
        æ˜ç¡®çš„å›¾ç‰‡ä¸è¡¨æƒ…åŒ…è¾¹ç•Œåˆ¤æ–­ï¼š
        1. é¦–å…ˆé€šè¿‡_classify_imageå‡½æ•°åˆ¤æ–­æ˜¯å¦ä¸ºè¡¨æƒ…åŒ…
        2. ä»…å¯¹åˆ†ç±»ä¸º"sticker"çš„å›¾ç‰‡è¿›è¡Œåç»­å¤„ç†
        3. å¯¹æ™®é€šå›¾ç‰‡ï¼ˆ"photo"ï¼‰ç›´æ¥è¿”å›å¤±è´¥ï¼Œé¿å…æ··æ·†å¤„ç†é€»è¾‘
        4. å¯¹å°å›¾æ ‡ï¼ˆ"icon"ï¼‰ä¹Ÿç›´æ¥è¿”å›å¤±è´¥ï¼Œå› ä¸ºå®ƒä»¬ä¸æ˜¯è¡¨æƒ…åŒ…
        
        Args:
            image_url: å›¾ç‰‡URL
            user_qq: å‘é€è€…QQå·ï¼ˆå¯é€‰ï¼‰
            user_nickname: å‘é€è€…æ˜µç§°ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            dict: åŒ…å«å¤„ç†ç»“æœçš„å­—å…¸
        """
        try:
            if not self.emoji_manager:
                logger.error("âŒ è¡¨æƒ…åŒ…ç®¡ç†å™¨æœªåˆå§‹åŒ–")
                return {"success": False, "message": "è¡¨æƒ…åŒ…ç®¡ç†å™¨æœªåˆå§‹åŒ–"}
            
            # ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64
            base64_data = self.emoji_manager.download_image_to_base64(image_url)
            if not base64_data:
                return {"success": False, "message": "ä¸‹è½½è¡¨æƒ…åŒ…å¤±è´¥"}
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºçœŸæ­£çš„è¡¨æƒ…åŒ…å¹¶åŒæ—¶åˆ†æ - å‡å°‘LLMè°ƒç”¨æ¬¡æ•°
            base64_clean = base64_data.encode("ascii", errors="ignore").decode("ascii")
            image_bytes = base64.b64decode(base64_clean)
            image = Image.open(io.BytesIO(image_bytes))
            width, height = image.size
            file_size_kb = len(image_bytes) / 1024
            
            # å°å›¾æ ‡åˆ¤æ–­ - ä»ç„¶ä½¿ç”¨æœ¬åœ°è§„åˆ™ï¼Œå› ä¸ºå°å›¾æ ‡æ˜æ˜¾ä¸æ˜¯è¡¨æƒ…åŒ…
            if width < 50 or height < 50:
                classification = "icon"
                logger.info(f"ğŸš« è·³è¿‡å°å›¾æ ‡ï¼Œä¸ä¿å­˜ä¸ºè¡¨æƒ…åŒ… ({width}x{height}, {file_size_kb:.1f}KB)")
                return {"success": False, "message": f"ä¸æ˜¯è¡¨æƒ…åŒ… (åˆ†ç±»: {classification})", "classification": classification}
            
            # ç¡®ä¿å›¾ç‰‡å°ºå¯¸é€‚ä¸­ï¼Œé¿å…è¿‡å¤§çš„å›¾ç‰‡è¢«è¯¯åˆ†ç±»ä¸ºè¡¨æƒ…åŒ…
            if width > 2048 or height > 2048:
                logger.info(f"ğŸ“ è·³è¿‡è¶…å¤§å›¾ç‰‡ï¼Œä¸ä¿å­˜ä¸ºè¡¨æƒ…åŒ… ({width}x{height})")
                return {"success": False, "message": "å›¾ç‰‡å°ºå¯¸è¿‡å¤§ï¼Œä¸æ˜¯è¡¨æƒ…åŒ…", "classification": "photo"}
            
            # ç¡®ä¿æ–‡ä»¶å¤§å°é€‚ä¸­ï¼Œé¿å…è¿‡å¤§çš„æ–‡ä»¶è¢«è¯¯åˆ†ç±»ä¸ºè¡¨æƒ…åŒ…
            if file_size_kb > 2048:  # 2MB
                logger.info(f"ğŸ’¾ è·³è¿‡è¶…å¤§æ–‡ä»¶ï¼Œä¸ä¿å­˜ä¸ºè¡¨æƒ…åŒ… ({file_size_kb:.1f}KB)")
                return {"success": False, "message": "æ–‡ä»¶å¤§å°è¿‡å¤§ï¼Œä¸æ˜¯è¡¨æƒ…åŒ…", "classification": "photo"}
            
            # ä½¿ç”¨å¤§æ¨¡å‹åŒæ—¶è¿›è¡Œåˆ¤æ–­å’Œåˆ†æï¼Œå‡å°‘LLMè°ƒç”¨æ¬¡æ•°
            is_emoji, llm_result = await _process_image_with_llm(base64_data)
            
            # æ˜ç¡®çš„è¾¹ç•Œï¼šåªæœ‰åˆ¤æ–­ä¸ºè¡¨æƒ…åŒ…çš„å›¾ç‰‡æ‰è¢«è§†ä¸ºè¡¨æƒ…åŒ…
            if not is_emoji:
                classification = "photo"
                logger.info(f"ğŸš« è·³è¿‡æ™®é€šç…§ç‰‡ï¼Œä¸ä¿å­˜ä¸ºè¡¨æƒ…åŒ… ({width}x{height}, {file_size_kb:.1f}KB)")
                return {"success": False, "message": f"ä¸æ˜¯è¡¨æƒ…åŒ… (åˆ†ç±»: {classification})", "classification": classification}
            
            classification = "sticker"
            logger.info(f"ğŸ” å›¾ç‰‡åˆ†ç±»ç»“æœ: {classification} ({width}x{height}, {file_size_kb:.1f}KB)")
            
            # ä»LLMç»“æœä¸­æå–ä¿¡æ¯ï¼Œå……åˆ†åˆ©ç”¨æ‰€æœ‰æœ‰ä»·å€¼çš„æƒ…ç»ªæ ‡ç­¾
            emotions = llm_result.get("emotions", ["æœªçŸ¥"])
            # è¿‡æ»¤æ‰é‡å¤å’Œæ— æ„ä¹‰çš„æƒ…ç»ªæ ‡ç­¾
            unique_emotions = []
            for emotion in emotions:
                if emotion and emotion != "æœªçŸ¥" and emotion not in unique_emotions:
                    unique_emotions.append(emotion)
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„æƒ…ç»ªæ ‡ç­¾ï¼Œä½¿ç”¨é»˜è®¤å€¼
            if not unique_emotions:
                unique_emotions = ["æœªçŸ¥"]
            
            description = llm_result.get("description", f"ç”¨æˆ·{user_nickname}å‘é€çš„è¡¨æƒ…åŒ…")
            category = llm_result.get("category", "å…¶ä»–")
            
            # è®¾ç½®æ ‡ç­¾
            tags = []
            if user_qq:
                tags.append("user_sent")
                tags.append(user_qq)
            else:
                tags.append("auto_detected")
            
            # ä¿å­˜è¡¨æƒ…åŒ…
            success, message, emoji_info = self.emoji_manager.add_emoji(
                base64_data=base64_data,
                description=description,
                emotions=unique_emotions,
                tags=tags,
                category=category
            )
            
            if success:
                logger.info(f"âœ… æˆåŠŸä¿å­˜è¡¨æƒ…åŒ…: {message}")
                # è®°å½•æœ€è¿‘ä¿å­˜çš„è¡¨æƒ…åŒ…ï¼Œç”¨äºé¿å…é‡å¤å‘é€
                self._recently_saved_emojis.append(emoji_info.emoji_hash)
                # é™åˆ¶æœ€è¿‘ä¿å­˜çš„è¡¨æƒ…åŒ…æ•°é‡
                if len(self._recently_saved_emojis) > self._MAX_RECENT_EMOJIS:
                    self._recently_saved_emojis.pop(0)
                return {
                    "success": True,
                    "message": message,
                    "emoji_info": emoji_info,
                    "description": description,
                    "emotions": unique_emotions,
                    "category": category,
                    "classification": classification
                }
            else:
                logger.error(f"âŒ ä¿å­˜è¡¨æƒ…åŒ…å¤±è´¥: {message}")
                return {"success": False, "message": message, "classification": classification}
                
        except Exception as e:
            logger.error(f"âŒ å¤„ç†è¡¨æƒ…åŒ…æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return {"success": False, "message": str(e)}
    
    def get_emoji_for_context(self, context: Dict[str, Any], count: int = 1) -> List[EmojiInfo]:
        """
        æ ¹æ®å¯¹è¯ä¸Šä¸‹æ–‡é€‰æ‹©åˆé€‚çš„è¡¨æƒ…åŒ…
        
        Args:
            context: åŒ…å«å¯¹è¯ä¸Šä¸‹æ–‡ä¿¡æ¯çš„å­—å…¸
            count: éœ€è¦è·å–çš„è¡¨æƒ…åŒ…æ•°é‡
            
        Returns:
            List[EmojiInfo]: é€‰æ‹©çš„è¡¨æƒ…åŒ…åˆ—è¡¨
        """
        try:
            if not self.emoji_manager:
                logger.error("âŒ è¡¨æƒ…åŒ…ç®¡ç†å™¨æœªåˆå§‹åŒ–")
                return []
            
            # ä»ä¸Šä¸‹æ–‡æå–æƒ…ç»ªä¿¡æ¯
            emotions = self._extract_emotions_from_context(context)
            
            # æå–å¯¹è¯å…ƒä¿¡æ¯
            conversation_type = context.get("conversation_type", "private")  # private/group
            intimacy_level = context.get("intimacy_level", "medium")  # low/medium/high
            
            logger.info(f"ğŸ¯ åˆ†æä¸Šä¸‹æ–‡: æƒ…ç»ª={emotions}, å¯¹è¯ç±»å‹={conversation_type}, äº²å¯†ç¨‹åº¦={intimacy_level}")
            
            # å¦‚æœæ²¡æœ‰æå–åˆ°æƒ…ç»ªä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤æƒ…ç»ªå¹¶è€ƒè™‘å¯¹è¯ç±»å‹
            if not emotions:
                logger.info(f"ğŸ“Š æœªä»ä¸Šä¸‹æ–‡æå–åˆ°æƒ…ç»ªä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤æƒ…ç»ª")
                return self.emoji_manager.get_random_emoji(count=count)
            
            # æ ¹æ®æƒ…ç»ªé€‰æ‹©è¡¨æƒ…åŒ…
            matching_emojis = []
            for emotion in emotions:
                matching_emojis.extend(self.emoji_manager.get_emojis_by_emotion(emotion))
            
            # å¦‚æœæœ‰åŒ¹é…çš„è¡¨æƒ…åŒ…ï¼Œä»ä¸­æ™ºèƒ½é€‰æ‹©
            if matching_emojis:
                # å»é‡
                unique_emojis = list({emoji.emoji_hash: emoji for emoji in matching_emojis}.values())
                
                # æ ¹æ®å¯¹è¯ç±»å‹å’Œäº²å¯†ç¨‹åº¦è¿‡æ»¤è¡¨æƒ…åŒ…
                filtered_emojis = self._filter_emojis_by_context(unique_emojis, conversation_type, intimacy_level)
                
                count = min(count, len(filtered_emojis))
                if count > 0:
                    # è€ƒè™‘ä½¿ç”¨é¢‘ç‡ï¼Œä¼˜å…ˆé€‰æ‹©ä½¿ç”¨è¾ƒå°‘çš„è¡¨æƒ…åŒ…
                    selected_emojis = self._select_balanced_emojis(filtered_emojis, count)
                    logger.info(f"ğŸ­ æ ¹æ®æƒ…ç»ªå’Œä¸Šä¸‹æ–‡é€‰æ‹©äº†{count}ä¸ªè¡¨æƒ…åŒ…: {[emoji.emoji_hash for emoji in selected_emojis]}")
                    return selected_emojis
            
            # å¦‚æœæ²¡æœ‰åŒ¹é…çš„ï¼Œä½¿ç”¨æœ€ç›¸ä¼¼çš„æƒ…ç»ªæ ‡ç­¾
            fallback_emojis = []
            for emotion in emotions:
                fallback_emojis.extend(self.emoji_manager.get_emoji_for_text(emotion, count=count*2))
            
            if fallback_emojis:
                unique_emojis = list({emoji.emoji_hash: emoji for emoji in fallback_emojis}.values())
                filtered_emojis = self._filter_emojis_by_context(unique_emojis, conversation_type, intimacy_level)
                
                count = min(count, len(filtered_emojis))
                if count > 0:
                    selected_emojis = self._select_balanced_emojis(filtered_emojis, count)
                    logger.info(f"ğŸ­ æ ¹æ®ç›¸ä¼¼æƒ…ç»ªå’Œä¸Šä¸‹æ–‡é€‰æ‹©äº†{count}ä¸ªè¡¨æƒ…åŒ…: {[emoji.emoji_hash for emoji in selected_emojis]}")
                    return selected_emojis
            
            # æœ€åå…œåº•ï¼Œéšæœºé€‰æ‹©ä½†è€ƒè™‘å¯¹è¯ç±»å‹
            logger.info(f"ğŸ² æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„è¡¨æƒ…åŒ…ï¼Œæ ¹æ®å¯¹è¯ç±»å‹éšæœºé€‰æ‹©{count}ä¸ª")
            return self.emoji_manager.get_random_emoji(count=count)
            
        except Exception as e:
            logger.error(f"âŒ é€‰æ‹©è¡¨æƒ…åŒ…å¤±è´¥: {e}")
            return self.emoji_manager.get_random_emoji(count=count) if self.emoji_manager else []
    
    def _extract_emotions_from_context(self, context: Dict[str, Any]) -> List[str]:
        """
        ä»å¯¹è¯ä¸Šä¸‹æ–‡ä¸­æå–æƒ…ç»ªä¿¡æ¯
        
        Args:
            context: åŒ…å«å¯¹è¯ä¸Šä¸‹æ–‡ä¿¡æ¯çš„å­—å…¸
            
        Returns:
            List[str]: æå–çš„æƒ…ç»ªæ ‡ç­¾åˆ—è¡¨
        """
        # åˆ›å»ºç¼“å­˜é”®
        cache_key = self._create_context_cache_key(context)
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self._context_emotion_cache:
            logger.debug(f"âš¡ ä¸Šä¸‹æ–‡æƒ…ç»ªæå–ç¼“å­˜å‘½ä¸­: {cache_key}")
            return self._context_emotion_cache[cache_key]
        
        emotions: list[str] = []
        
        # 1. ä»æœ€æ–°æ¶ˆæ¯ä¸­æå–æƒ…ç»ªæ ‡ç­¾
        last_message = context.get("last_message", "")
        if "ã€è¡¨æƒ…åŒ…:" in last_message:
            emotion_match = re.search(r"ã€è¡¨æƒ…åŒ…:(.*?)ã€‘", last_message)
            if emotion_match:
                emotion_tags = emotion_match.group(1).split("ã€")
                emotions.extend(emotion_tags)
        
        # 2. ä»å¯¹è¯å†å²ä¸­æå–æƒ…ç»ªä¿¡æ¯
        message_history = context.get("message_history", [])
        
        for message in message_history[-5:]:  # æŸ¥çœ‹æœ€è¿‘5æ¡æ¶ˆæ¯
            # ç»Ÿä¸€è·å–æ¶ˆæ¯å†…å®¹
            if isinstance(message, dict) and "content" in message:
                content = message["content"]
            elif hasattr(message, "content"):
                content = str(message.content)
            else:
                content = str(message)
            
            # æ£€æŸ¥æ¯æ¡æ¶ˆæ¯çš„æƒ…ç»ª
            for emotion, keywords in self.EMOTION_KEYWORDS.items():
                # ä½¿ç”¨é›†åˆå»é‡å…³é”®è¯ï¼Œæé«˜æ•ˆç‡
                for keyword in set(keywords):
                    if keyword in content:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯å¦å®šå¥
                        is_negated = False
                        for negation in self.NEGATION_WORDS:
                            # æ£€æŸ¥å¦å®šè¯æ˜¯å¦åœ¨å…³é”®è¯å‰é¢
                            neg_pos = content.find(negation)
                            keyword_pos = content.find(keyword)
                            if neg_pos != -1 and neg_pos < keyword_pos:
                                # ç®€å•åˆ¤æ–­ï¼šå¦‚æœå¦å®šè¯åœ¨å…³é”®è¯å‰é¢ï¼Œä¸”è·ç¦»ä¸è¶…è¿‡10ä¸ªå­—ç¬¦ï¼Œåˆ™è®¤ä¸ºæ˜¯å¦å®š
                                if keyword_pos - neg_pos < 10:
                                    is_negated = True
                                    break
                        
                        if not is_negated:
                            emotions.append(emotion)
        
        # 3. ä»é¢å¤–æƒ…ç»ªæ ‡ç­¾ä¸­æå–ï¼ˆå¦‚æœæœ‰ï¼‰
        additional_emotions = context.get("emotions", [])
        if isinstance(additional_emotions, list):
            emotions.extend(additional_emotions)
        
        # 4. å»é‡å¹¶é™åˆ¶æ•°é‡
        result = list(set(emotions))[:5]  # æœ€å¤šè¿”å›5ä¸ªæƒ…ç»ªæ ‡ç­¾
        
        # ä¿å­˜åˆ°ç¼“å­˜
        self._context_emotion_cache[cache_key] = result
        
        # æ¸…ç†ç¼“å­˜ï¼ˆä¿æŒå›ºå®šå¤§å°ï¼‰
        self._clean_cache(self._context_emotion_cache)
        
        return result
    
    def _create_context_cache_key(self, context: Dict[str, Any]) -> str:
        """
        åˆ›å»ºä¸Šä¸‹æ–‡ç¼“å­˜é”®
        
        Args:
            context: ä¸Šä¸‹æ–‡å­—å…¸
            
        Returns:
            str: ç¼“å­˜é”®
        """
        last_message = context.get("last_message", "")
        message_history = context.get("message_history", [])
        
        # åªä½¿ç”¨æœ€è¿‘5æ¡æ¶ˆæ¯çš„å†…å®¹åˆ›å»ºç¼“å­˜é”®
        history_content = ""
        for msg in message_history[-5:]:
            if isinstance(msg, dict) and "content" in msg:
                history_content += msg["content"]
            elif hasattr(msg, "content"):
                history_content += str(msg.content)
            else:
                history_content += str(msg)
        
        additional_emotions = context.get("emotions", [])
        
        # ä½¿ç”¨å†…å®¹çš„å“ˆå¸Œå€¼ä½œä¸ºç¼“å­˜é”®
        cache_content = f"{last_message}:{history_content}:{additional_emotions}"
        return hashlib.md5(cache_content.encode()).hexdigest()
    
    def _clean_cache(self, cache: Dict, max_size: int = None) -> None:
        """
        æ¸…ç†ç¼“å­˜ï¼Œä¿æŒå›ºå®šå¤§å°
        
        Args:
            cache: è¦æ¸…ç†çš„ç¼“å­˜å­—å…¸
            max_size: æœ€å¤§ç¼“å­˜å¤§å°ï¼ˆé»˜è®¤ä½¿ç”¨ç±»å®šä¹‰çš„å¤§å°ï¼‰
        """
        max_size = max_size or self._CACHE_SIZE
        
        if len(cache) > max_size:
            # åˆ é™¤æœ€æ—§çš„ç¼“å­˜é¡¹ï¼ˆé€šè¿‡æŒ‰é”®é¡ºåºï¼ŒPython 3.7+ å­—å…¸ä¿æŒæ’å…¥é¡ºåºï¼‰
            items_to_remove = len(cache) - max_size
            for key in list(cache.keys())[:items_to_remove]:
                del cache[key]
    
    def _filter_emojis_by_context(self, emojis: List[EmojiInfo], conversation_type: str, intimacy_level: str) -> List[EmojiInfo]:
        """
        æ ¹æ®å¯¹è¯ä¸Šä¸‹æ–‡è¿‡æ»¤è¡¨æƒ…åŒ…
        
        Args:
            emojis: è¡¨æƒ…åŒ…åˆ—è¡¨
            conversation_type: å¯¹è¯ç±»å‹ (private/group)
            intimacy_level: äº²å¯†ç¨‹åº¦ (low/medium/high)
            
        Returns:
            List[EmojiInfo]: è¿‡æ»¤åçš„è¡¨æƒ…åŒ…åˆ—è¡¨
        """
        filtered = []
        
        for emoji in emojis:
            # ç®€å•å®ç°ï¼šç¾¤èŠä¸­é¿å…ä½¿ç”¨è¿‡äºç§äººæˆ–æš§æ˜§çš„è¡¨æƒ…åŒ…
            if conversation_type == "group" and intimacy_level == "low":
                # å‡è®¾emojiå¯¹è±¡æœ‰categoryå±æ€§
                if hasattr(emoji, "category"):
                    # ç¾¤èŠä¸­é¿å…ä½¿ç”¨è¿‡äºç§äººçš„è¡¨æƒ…åŒ…ç±»å‹
                    if emoji.category not in ["äº²å¯†", "æš§æ˜§"]:
                        filtered.append(emoji)
                else:
                    filtered.append(emoji)
            else:
                filtered.append(emoji)
        
        return filtered if filtered else emojis  # å¦‚æœè¿‡æ»¤åä¸ºç©ºï¼Œè¿”å›åŸå§‹åˆ—è¡¨
    
    def _filter_recent_emojis(self, emojis: List[EmojiInfo]) -> List[EmojiInfo]:
        """
        è¿‡æ»¤æ‰æœ€è¿‘ä¿å­˜çš„è¡¨æƒ…åŒ…ï¼Œé¿å…é‡å¤å‘é€
        
        Args:
            emojis: è¡¨æƒ…åŒ…åˆ—è¡¨
            
        Returns:
            List[EmojiInfo]: è¿‡æ»¤åçš„è¡¨æƒ…åŒ…åˆ—è¡¨
        """
        if not self._recently_saved_emojis:
            return emojis
        
        # è¿‡æ»¤æ‰æœ€è¿‘ä¿å­˜çš„è¡¨æƒ…åŒ…
        filtered = [emoji for emoji in emojis if emoji.emoji_hash not in self._recently_saved_emojis]
        
        # å¦‚æœè¿‡æ»¤åæ²¡æœ‰è¡¨æƒ…åŒ…ï¼Œè¿”å›åŸå§‹åˆ—è¡¨ï¼ˆé¿å…ç©ºåˆ—è¡¨ï¼‰
        return filtered if filtered else emojis
    
    def _select_balanced_emojis(self, emojis: List[EmojiInfo], count: int) -> List[EmojiInfo]:
        """
        å¹³è¡¡é€‰æ‹©è¡¨æƒ…åŒ…ï¼Œè€ƒè™‘ä½¿ç”¨é¢‘ç‡
        
        Args:
            emojis: è¡¨æƒ…åŒ…åˆ—è¡¨
            count: éœ€è¦é€‰æ‹©çš„æ•°é‡
            
        Returns:
            List[EmojiInfo]: é€‰æ‹©çš„è¡¨æƒ…åŒ…åˆ—è¡¨
        """
        # è¿‡æ»¤æ‰æœ€è¿‘ä¿å­˜çš„è¡¨æƒ…åŒ…
        filtered_emojis = self._filter_recent_emojis(emojis)
        
        # å¦‚æœè¿‡æ»¤åæ²¡æœ‰è¡¨æƒ…åŒ…ï¼Œè¿”å›åŸå§‹åˆ—è¡¨
        if not filtered_emojis:
            filtered_emojis = emojis
        
        if len(filtered_emojis) <= count:
            return filtered_emojis
        
        # å‡è®¾emojiå¯¹è±¡æœ‰usage_countå±æ€§è®°å½•ä½¿ç”¨æ¬¡æ•°
        # è¿™é‡Œä½¿ç”¨éšæœºé€‰æ‹©ï¼Œå®é™…å¯ä»¥æ ¹æ®ä½¿ç”¨é¢‘ç‡åŠ æƒ
        return random.sample(filtered_emojis, count)
    
    def get_default_emoji(self) -> str:
        """
        è·å–é»˜è®¤è¡¨æƒ…ç¬¦å·
        
        Returns:
            str: é»˜è®¤è¡¨æƒ…ç¬¦å·
        """
        default_emojis = ["ğŸ¶", "ğŸ±", "ğŸ’–", "ğŸ’•", "ğŸ’", "ğŸ¤—", "ğŸ‘»", "ğŸ‘½"]
        return random.choice(default_emojis)
```
- **åŠŸèƒ½**: æä¾›ç»Ÿä¸€çš„è¡¨æƒ…åŒ…åŠŸèƒ½å…¥å£ï¼Œæ•´åˆè¯†åˆ«ã€åˆ†æã€ç®¡ç†å’Œå›å¤åŠŸèƒ½ï¼Œæ”¯æŒæ ¹æ®å¯¹è¯ä¸Šä¸‹æ–‡æ™ºèƒ½é€‰æ‹©è¡¨æƒ…åŒ…
- **è®¾è®¡æ€è·¯**: 
  - ä½¿ç”¨å•ä¾‹æ¨¡å¼ç®¡ç†è¡¨æƒ…åŒ…åŠŸèƒ½ï¼Œæ•´åˆè¯†åˆ«ã€åˆ†æã€ç®¡ç†å’Œå›å¤åŠŸèƒ½
  - å®ç°æƒ…ç»ªæå–å’ŒåŒ¹é…æœºåˆ¶ï¼Œæ ¹æ®å¯¹è¯ä¸Šä¸‹æ–‡é€‰æ‹©åˆé€‚çš„è¡¨æƒ…åŒ…
  - æ·»åŠ å¤šçº§ç¼“å­˜æœºåˆ¶ï¼Œæé«˜æ€§èƒ½å’Œå“åº”é€Ÿåº¦
  - å®ç°è¡¨æƒ…åŒ…è¿‡æ»¤å’Œå¹³è¡¡é€‰æ‹©ç®—æ³•ï¼Œé¿å…é‡å¤å‘é€å’Œè¿‡åº¦ä½¿ç”¨æŸäº›è¡¨æƒ…åŒ…
  - æ”¯æŒé”™è¯¯å¤„ç†å’Œé™çº§ç­–ç•¥ï¼Œæé«˜ç³»ç»Ÿç¨³å®šæ€§
- **å½±å“èŒƒå›´**: 
  - æ™ºèƒ½ä½“ä½¿ç”¨è¡¨æƒ…åŒ…çš„èƒ½åŠ›å’Œä½“éªŒ
  - ä¸ç”¨æˆ·çš„æƒ…æ„Ÿäº¤äº’è´¨é‡
  - ç³»ç»Ÿæ€§èƒ½å’Œèµ„æºä½¿ç”¨
  - è¡¨æƒ…åŒ…æ•°æ®çš„ç®¡ç†å’Œå­˜å‚¨

#### app/plugins/emoji_plugin/tools.py
```python
from typing import List, Dict, Any
from app.tools.base_tool import BaseTool, ToolParam
import logging

# ä½¿ç”¨åŠ¨æ€å¯¼å…¥æ¥é¿å…å¾ªç¯å¯¼å…¥é—®é¢˜
def get_emoji_manager():
    from app.plugins.emoji_plugin.emoji_manager import get_emoji_manager as _get_emoji_manager
    return _get_emoji_manager()

def get_emoji_info_class():
    from app.plugins.emoji_plugin.emoji_manager import EmojiInfo
    return EmojiInfo

logger = logging.getLogger("EmojiTools")


class AddEmojiTool(BaseTool):
    """æ·»åŠ è¡¨æƒ…åŒ…å·¥å…·"""
    
    name = "add_emoji"
    description = "æ·»åŠ æˆ–æ›´æ–°è¡¨æƒ…åŒ…ï¼Œæ”¯æŒè®¾ç½®æè¿°ã€æƒ…ç»ªæ ‡ç­¾ã€è‡ªå®šä¹‰æ ‡ç­¾å’Œåˆ†ç±»"
    parameters = [
        ToolParam("base64_data", "string", "è¡¨æƒ…åŒ…çš„base64ç¼–ç æ•°æ®", required=True),
        ToolParam("description", "string", "è¡¨æƒ…åŒ…çš„æè¿°", required=False),
        ToolParam("emotions", "array", "ä¸è¡¨æƒ…åŒ…ç›¸å…³çš„æƒ…ç»ªæ ‡ç­¾ï¼Œå¦‚ï¼š['å¼€å¿ƒ', 'æƒŠè®¶', 'éš¾è¿‡']", required=False),
        ToolParam("tags", "array", "è¡¨æƒ…åŒ…çš„è‡ªå®šä¹‰æ ‡ç­¾ï¼Œå¦‚ï¼š['æç¬‘', 'å¯çˆ±', 'å·¥ä½œ']", required=False),
        ToolParam("category", "string", "è¡¨æƒ…åŒ…çš„åˆ†ç±»ï¼Œå¦‚ï¼š'general', 'funny', 'sad'", required=False)
    ]
    available_for_llm = True
    
    async def execute(self, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡Œæ·»åŠ è¡¨æƒ…åŒ…æ“ä½œ"""
        emoji_manager = get_emoji_manager()
        if not emoji_manager:
            return {
                "success": False,
                "result": None,
                "error": "è¡¨æƒ…åŒ…ç®¡ç†å™¨æœªåˆå§‹åŒ–"
            }
        
        try:
            base64_data = kwargs.get("base64_data")
            description = kwargs.get("description", "")
            emotions = kwargs.get("emotions", [])
            tags = kwargs.get("tags", [])
            category = kwargs.get("category", "general")
            
            success, message, emoji_info = emoji_manager.add_emoji(
                base64_data=base64_data,
                description=description,
                emotions=emotions,
                tags=tags,
                category=category
            )
            
            if success:
                return {
                    "success": True,
                    "result": {
                        "message": message,
                        "emoji_hash": emoji_info.emoji_hash,
                        "description": emoji_info.description,
                        "emotions": emoji_info.emotions,
                        "tags": emoji_info.tags
                    },
                    "error": None
                }
            else:
                return {
                    "success": False,
                    "result": None,
                    "error": message
                }
                
        except Exception as e:
            logger.error(f"æ·»åŠ è¡¨æƒ…åŒ…å¤±è´¥: {e}")
            return {
                "success": False,
                "result": None,
                "error": f"æ·»åŠ è¡¨æƒ…åŒ…å¤±è´¥: {str(e)}"
            }


class DeleteEmojiTool(BaseTool):
    """åˆ é™¤è¡¨æƒ…åŒ…å·¥å…·"""
    
    name = "delete_emoji"
    description = "æ ¹æ®å“ˆå¸Œå€¼åˆ é™¤è¡¨æƒ…åŒ…"
    parameters = [
        ToolParam("emoji_hash", "string", "è¡¨æƒ…åŒ…çš„å“ˆå¸Œå€¼", required=True)
    ]
    available_for_llm = True
    
    async def execute(self, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡Œåˆ é™¤è¡¨æƒ…åŒ…æ“ä½œ"""
        emoji_manager = get_emoji_manager()
        if not emoji_manager:
            return {
                "success": False,
                "result": None,
                "error": "è¡¨æƒ…åŒ…ç®¡ç†å™¨æœªåˆå§‹åŒ–"
            }
        
        try:
            emoji_hash = kwargs.get("emoji_hash")
            
            if not emoji_hash:
                return {
                    "success": False,
                    "result": None,
                    "error": "ç¼ºå°‘è¡¨æƒ…åŒ…å“ˆå¸Œå€¼"
                }
            
            success, message, emoji_info = emoji_manager.delete_emoji(emoji_hash)
            
            if success:
                return {
                    "success": True,
                    "result": {
                        "message": message,
                        "emoji_hash": emoji_hash,
                        "description": emoji_info.description if emoji_info else ""
                    },
                    "error": None
                }
            else:
                return {
                    "success": False,
                    "result": None,
                    "error": message
                }
                
        except Exception as e:
            logger.error(f"åˆ é™¤è¡¨æƒ…åŒ…å¤±è´¥: {e}")
            return {
                "success": False,
                "result": None,
                "error": f"åˆ é™¤è¡¨æƒ…åŒ…å¤±è´¥: {str(e)}"
            }


class ListEmojisTool(BaseTool):
    """åˆ—å‡ºè¡¨æƒ…åŒ…å·¥å…·"""
    
    name = "list_emojis"
    description = "åˆ—å‡ºæ‰€æœ‰è¡¨æƒ…åŒ…ä¿¡æ¯ï¼Œæ”¯æŒæ ¹æ®æƒ…ç»ªæˆ–æ ‡ç­¾è¿‡æ»¤"
    parameters = [
        ToolParam("emotion", "string", "å¯é€‰ï¼ŒæŒ‰æƒ…ç»ªæ ‡ç­¾è¿‡æ»¤", required=False),
        ToolParam("tag", "string", "å¯é€‰ï¼ŒæŒ‰è‡ªå®šä¹‰æ ‡ç­¾è¿‡æ»¤", required=False),
        ToolParam("limit", "integer", "å¯é€‰ï¼Œè¿”å›ç»“æœçš„æœ€å¤§æ•°é‡", required=False, enum_values=None)
    ]
    available_for_llm = True
    
    async def execute(self, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡Œåˆ—å‡ºè¡¨æƒ…åŒ…æ“ä½œ"""
        emoji_manager = get_emoji_manager()
        if not emoji_manager:
            return {
                "success": False,
                "result": None,
                "error": "è¡¨æƒ…åŒ…ç®¡ç†å™¨æœªåˆå§‹åŒ–"
            }
        
        try:
            emotion = kwargs.get("emotion")
            tag = kwargs.get("tag")
            limit = kwargs.get("limit", 100)
            
            if emotion:
                emojis = emoji_manager.get_emojis_by_emotion(emotion)
            elif tag:
                emojis = emoji_manager.get_emojis_by_tag(tag)
            else:
                emojis = emoji_manager.get_all_emojis()
            
            # é™åˆ¶ç»“æœæ•°é‡
            if limit > 0:
                emojis = emojis[:limit]
            
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            emoji_list = []
            for emoji in emojis:
                emoji_list.append({
                    "emoji_hash": emoji.emoji_hash,
                    "description": emoji.description,
                    "emotions": emoji.emotions,
                    "tags": emoji.tags,
                    "usage_count": emoji.usage_count,
                    "created_at": emoji.created_at
                })
            
            return {
                "success": True,
                "result": {
                    "total_count": len(emoji_list),
                    "emojis": emoji_list,
                    "filter_emotion": emotion,
                    "filter_tag": tag
                },
                "error": None
            }
            
        except Exception as e:
            logger.error(f"åˆ—å‡ºè¡¨æƒ…åŒ…å¤±è´¥: {e}")
            return {
                "success": False,
                "result": None,
                "error": f"åˆ—å‡ºè¡¨æƒ…åŒ…å¤±è´¥: {str(e)}"
            }


class GetEmojiTool(BaseTool):
    """è·å–è¡¨æƒ…åŒ…å·¥å…·"""
    
    name = "get_emoji"
    description = "æ ¹æ®å“ˆå¸Œå€¼è·å–è¡¨æƒ…åŒ…ä¿¡æ¯"
    parameters = [
        ToolParam("emoji_hash", "string", "è¡¨æƒ…åŒ…çš„å“ˆå¸Œå€¼", required=True)
    ]
    available_for_llm = True
    
    async def execute(self, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡Œè·å–è¡¨æƒ…åŒ…æ“ä½œ"""
        emoji_manager = get_emoji_manager()
        if not emoji_manager:
            return {
                "success": False,
                "result": None,
                "error": "è¡¨æƒ…åŒ…ç®¡ç†å™¨æœªåˆå§‹åŒ–"
            }
        
        try:
            emoji_hash = kwargs.get("emoji_hash")
            
            if not emoji_hash:
                return {
                    "success": False,
                    "result": None,
                    "error": "ç¼ºå°‘è¡¨æƒ…åŒ…å“ˆå¸Œå€¼"
                }
            
            emoji_info = emoji_manager.get_emoji(emoji_hash)
            
            if emoji_info:
                return {
                    "success": True,
                    "result": {
                        "emoji_hash": emoji_info.emoji_hash,
                        "base64_data": emoji_info.base64_data,
                        "description": emoji_info.description,
                        "emotions": emoji_info.emotions,
                        "tags": emoji_info.tags,
                        "usage_count": emoji_info.usage_count,
                        "created_at": emoji_info.created_at,
                        "last_used_at": emoji_info.last_used_at
                    },
                    "error": None
                }
            else:
                return {
                    "success": False,
                    "result": None,
                    "error": f"æœªæ‰¾åˆ°å“ˆå¸Œå€¼ä¸º {emoji_hash} çš„è¡¨æƒ…åŒ…"
                }
                
        except Exception as e:
            logger.error(f"è·å–è¡¨æƒ…åŒ…å¤±è´¥: {e}")
            return {
                "success": False,
                "result": None,
                "error": f"è·å–è¡¨æƒ…åŒ…å¤±è´¥: {str(e)}"
            }


class GetRandomEmojiTool(BaseTool):
    """è·å–éšæœºè¡¨æƒ…åŒ…å·¥å…·"""
    
    name = "get_random_emoji"
    description = "è·å–éšæœºè¡¨æƒ…åŒ…ï¼Œæ”¯æŒæ ¹æ®æƒ…ç»ªã€æ ‡ç­¾æˆ–åˆ†ç±»è¿‡æ»¤"
    parameters = [
        ToolParam("count", "integer", "è·å–çš„è¡¨æƒ…åŒ…æ•°é‡ï¼Œé»˜è®¤1", required=False),
        ToolParam("emotion", "string", "å¯é€‰ï¼ŒæŒ‰æƒ…ç»ªæ ‡ç­¾è¿‡æ»¤", required=False),
        ToolParam("tag", "string", "å¯é€‰ï¼ŒæŒ‰è‡ªå®šä¹‰æ ‡ç­¾è¿‡æ»¤", required=False),
        ToolParam("category", "string", "å¯é€‰ï¼ŒæŒ‰åˆ†ç±»è¿‡æ»¤", required=False)
    ]
    available_for_llm = True
    
    async def execute(self, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡Œè·å–éšæœºè¡¨æƒ…åŒ…æ“ä½œ"""
        emoji_manager = get_emoji_manager()
        if not emoji_manager:
            return {
                "success": False,
                "result": None,
                "error": "è¡¨æƒ…åŒ…ç®¡ç†å™¨æœªåˆå§‹åŒ–"
            }
        
        try:
            count = kwargs.get("count", 1)
            emotion = kwargs.get("emotion")
            tag = kwargs.get("tag")
            category = kwargs.get("category")
            
            # é™åˆ¶æ•°é‡èŒƒå›´
            count = max(1, min(count, 10))
            
            random_emojis = emoji_manager.get_random_emoji(count=count, emotion=emotion, tag=tag, category=category)
            
            if not random_emojis:
                return {
                    "success": False,
                    "result": None,
                    "error": "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è¡¨æƒ…åŒ…"
                }
            
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            emoji_list = []
            for emoji in random_emojis:
                # å¢åŠ ä½¿ç”¨æ¬¡æ•°
                emoji.increment_usage()
                
                emoji_list.append({
                    "emoji_hash": emoji.emoji_hash,
                    "base64_data": emoji.base64_data,
                    "description": emoji.description,
                    "emotions": emoji.emotions,
                    "tags": emoji.tags,
                    "usage_count": emoji.usage_count
                })
            
            # ä¿å­˜ä½¿ç”¨æ¬¡æ•°æ›´æ–°
            emoji_manager._save_emojis()
            
            return {
                "success": True,
                "result": {
                    "count": len(emoji_list),
                    "emojis": emoji_list,
                    "filter_emotion": emotion,
                    "filter_tag": tag
                },
                "error": None
            }
            
        except Exception as e:
            logger.error(f"è·å–éšæœºè¡¨æƒ…åŒ…å¤±è´¥: {e}")
            return {
                "success": False,
                "result": None,
                "error": f"è·å–éšæœºè¡¨æƒ…åŒ…å¤±è´¥: {str(e)}"
            }


class GetEmojiStatsTool(BaseTool):
    """è·å–è¡¨æƒ…åŒ…ç»Ÿè®¡ä¿¡æ¯å·¥å…·"""
    
    name = "get_emoji_stats"
    description = "è·å–è¡¨æƒ…åŒ…çš„ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ€»æ•°ã€æƒ…ç»ªæ ‡ç­¾ç»Ÿè®¡ã€ä½¿ç”¨æ¬¡æ•°ç­‰"
    parameters = []
    available_for_llm = True
    
    async def execute(self, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡Œè·å–è¡¨æƒ…åŒ…ç»Ÿè®¡ä¿¡æ¯æ“ä½œ"""
        emoji_manager = get_emoji_manager()
        if not emoji_manager:
            return {
                "success": False,
                "result": None,
                "error": "è¡¨æƒ…åŒ…ç®¡ç†å™¨æœªåˆå§‹åŒ–"
            }
        
        try:
            stats = emoji_manager.get_info()
            
            return {
                "success": True,
                "result": {
                    "total_count": stats["total_count"],
                    "emotion_counts": stats["emotion_counts"],
                    "tag_counts": stats["tag_counts"],
                    "total_usage": stats["total_usage"],
                    "average_usage": stats["average_usage"]
                },
                "error": None
            }
            
        except Exception as e:
            logger.error(f"è·å–è¡¨æƒ…åŒ…ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {
                "success": False,
                "result": None,
                "error": f"è·å–è¡¨æƒ…åŒ…ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}"
            }


class AddEmojiFromUrlTool(BaseTool):
    """ä»URLæ·»åŠ è¡¨æƒ…åŒ…å·¥å…·"""
    
    name = "add_emoji_from_url"
    description = "ä»å›¾ç‰‡URLæ·»åŠ è¡¨æƒ…åŒ…ï¼Œè‡ªåŠ¨ä¸‹è½½å›¾ç‰‡å¹¶åˆ†ææƒ…ç»ªæ ‡ç­¾"
    parameters = [
        ToolParam("image_url", "string", "å›¾ç‰‡çš„URLåœ°å€", required=True),
        ToolParam("description", "string", "è¡¨æƒ…åŒ…çš„æè¿°ï¼Œå¯é€‰", required=False),
        ToolParam("emotions", "array", "ä¸è¡¨æƒ…åŒ…ç›¸å…³çš„æƒ…ç»ªæ ‡ç­¾ï¼Œå¦‚ï¼š['å¼€å¿ƒ', 'æƒŠè®¶', 'éš¾è¿‡']ï¼Œä¸æä¾›åˆ™è‡ªåŠ¨åˆ†æ", required=False),
        ToolParam("tags", "array", "è¡¨æƒ…åŒ…çš„è‡ªå®šä¹‰æ ‡ç­¾ï¼Œå¦‚ï¼š['æç¬‘', 'å¯çˆ±', 'å·¥ä½œ']ï¼Œå¯é€‰", required=False),
        ToolParam("category", "string", "è¡¨æƒ…åŒ…çš„åˆ†ç±»ï¼Œå¦‚ï¼š'general', 'funny', 'sad'", required=False)
    ]
    available_for_llm = True
    
    async def execute(self, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡Œä»URLæ·»åŠ è¡¨æƒ…åŒ…æ“ä½œ"""
        emoji_manager = get_emoji_manager()
        if not emoji_manager:
            return {
                "success": False,
                "result": None,
                "error": "è¡¨æƒ…åŒ…ç®¡ç†å™¨æœªåˆå§‹åŒ–"
            }
        
        try:
            image_url = kwargs.get("image_url")
            description = kwargs.get("description", "")
            emotions = kwargs.get("emotions", [])
            tags = kwargs.get("tags", [])
            category = kwargs.get("category", "general")
            
            if not image_url:
                return {
                    "success": False,
                    "result": None,
                    "error": "ç¼ºå°‘å›¾ç‰‡URL"
                }
            
            success, message, emoji_info = emoji_manager.add_emoji_from_url(
                image_url=image_url,
                description=description,
                emotions=emotions,
                tags=tags,
                category=category
            )
            
            if success:
                return {
                    "success": True,
                    "result": {
                        "message": message,
                        "emoji_hash": emoji_info.emoji_hash,
                        "description": emoji_info.description,
                        "emotions": emoji_info.emotions,
                        "tags": emoji_info.tags
                    },
                    "error": None
                }
            else:
                return {
                    "success": False,
                    "result": None,
                    "error": message
                }
                
        except Exception as e:
            logger.error(f"ä»URLæ·»åŠ è¡¨æƒ…åŒ…å¤±è´¥: {e}")
            return {
                "success": False,
                "result": None,
                "error": f"ä»URLæ·»åŠ è¡¨æƒ…åŒ…å¤±è´¥: {str(e)}"
            }


class GetEmojisByCategoryTool(BaseTool):
    """æ ¹æ®åˆ†ç±»è·å–è¡¨æƒ…åŒ…å·¥å…·"""
    
    name = "get_emojis_by_category"
    description = "æ ¹æ®åˆ†ç±»è·å–è¡¨æƒ…åŒ…åˆ—è¡¨"
    parameters = [
        ToolParam("category", "string", "è¡¨æƒ…åŒ…åˆ†ç±»", required=True)
    ]
    available_for_llm = True
    
    async def execute(self, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡Œæ ¹æ®åˆ†ç±»è·å–è¡¨æƒ…åŒ…æ“ä½œ"""
        emoji_manager = get_emoji_manager()
        if not emoji_manager:
            return {
                "success": False,
                "error": "è¡¨æƒ…åŒ…ç®¡ç†å™¨æœªåˆå§‹åŒ–"
            }
        
        try:
            category = kwargs.get("category")
            
            if not category:
                return {
                    "success": False,
                    "error": "ç¼ºå°‘åˆ†ç±»å‚æ•°"
                }
            
            emojis = emoji_manager.get_emojis_by_category(category)
            
            return {
                "success": True,
                "result": {
                    "category": category,
                    "count": len(emojis),
                    "emojis": [{
                        "emoji_hash": emoji.emoji_hash,
                        "description": emoji.description,
                        "emotions": emoji.emotions,
                        "tags": emoji.tags,
                        "category": emoji.category
                    } for emoji in emojis]
                },
                "error": None
            }
            
        except Exception as e:
            logger.error(f"æ ¹æ®åˆ†ç±»è·å–è¡¨æƒ…åŒ…å¤±è´¥: {e}")
            return {
                "success": False,
                "result": None,
                "error": f"æ ¹æ®åˆ†ç±»è·å–è¡¨æƒ…åŒ…å¤±è´¥: {str(e)}"
            }


class UpdateEmojiCategoryTool(BaseTool):
    """æ›´æ–°è¡¨æƒ…åŒ…åˆ†ç±»å·¥å…·"""
    
    name = "update_emoji_category"
    description = "æ›´æ–°è¡¨æƒ…åŒ…çš„åˆ†ç±»"
    parameters = [
        ToolParam("emoji_hash", "string", "è¡¨æƒ…åŒ…çš„å“ˆå¸Œå€¼", required=True),
        ToolParam("category", "string", "æ–°çš„åˆ†ç±»", required=True)
    ]
    available_for_llm = True
    
    async def execute(self, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡Œæ›´æ–°è¡¨æƒ…åŒ…åˆ†ç±»æ“ä½œ"""
        emoji_manager = get_emoji_manager()
        if not emoji_manager:
            return {
                "success": False,
                "error": "è¡¨æƒ…åŒ…ç®¡ç†å™¨æœªåˆå§‹åŒ–"
            }
        
        try:
            emoji_hash = kwargs.get("emoji_hash")
            category = kwargs.get("category")
            
            if not emoji_hash:
                return {
                    "success": False,
                    "error": "ç¼ºå°‘è¡¨æƒ…åŒ…å“ˆå¸Œå€¼"
                }
            
            if not category:
                return {
                    "success": False,
                    "error": "ç¼ºå°‘æ–°åˆ†ç±»å‚æ•°"
                }
            
            success, message, emoji_info = emoji_manager.update_emoji_category(emoji_hash, category)
            
            if success:
                return {
                    "success": True,
                    "result": {
                        "message": message,
                        "emoji_hash": emoji_info.emoji_hash,
                        "description": emoji_info.description,
                        "old_category": emoji_info.category,
                        "new_category": category
                    },
                    "error": None
                }
            else:
                return {
                    "success": False,
                    "result": None,
                    "error": message
                }
                
        except Exception as e:
            logger.error(f"æ›´æ–°è¡¨æƒ…åŒ…åˆ†ç±»å¤±è´¥: {e}")
            return {
                "success": False,
                "result": None,
                "error": f"æ›´æ–°è¡¨æƒ…åŒ…åˆ†ç±»å¤±è´¥: {str(e)}"
            }


class GetAllCategoriesTool(BaseTool):
    """è·å–æ‰€æœ‰åˆ†ç±»å·¥å…·"""
    
    name = "get_all_categories"
    description = "è·å–æ‰€æœ‰è¡¨æƒ…åŒ…åˆ†ç±»"
    parameters = []
    available_for_llm = True
    
    async def execute(self, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡Œè·å–æ‰€æœ‰åˆ†ç±»æ“ä½œ"""
        emoji_manager = get_emoji_manager()
        if not emoji_manager:
            return {
                "success": False,
                "error": "è¡¨æƒ…åŒ…ç®¡ç†å™¨æœªåˆå§‹åŒ–"
            }
        
        try:
            categories = emoji_manager.get_all_categories()
            
            return {
                "success": True,
                "result": {
                    "categories": categories,
                    "count": len(categories)
                },
                "error": None
            }
            
        except Exception as e:
            logger.error(f"è·å–æ‰€æœ‰åˆ†ç±»å¤±è´¥: {e}")
            return {
                "success": False,
                "result": None,
                "error": f"è·å–æ‰€æœ‰åˆ†ç±»å¤±è´¥: {str(e)}"
            }


class SearchEmojisTool(BaseTool):
    """æœç´¢è¡¨æƒ…åŒ…å·¥å…·"""
    
    name = "search_emojis"
    description = "æ ¹æ®å…³é”®è¯æœç´¢è¡¨æƒ…åŒ…ï¼Œæ”¯æŒåœ¨æè¿°ã€æƒ…ç»ªæ ‡ç­¾ã€è‡ªå®šä¹‰æ ‡ç­¾å’Œåˆ†ç±»ä¸­æœç´¢"
    parameters = [
        ToolParam("keyword", "string", "æœç´¢å…³é”®è¯", required=True)
    ]
    available_for_llm = True
    
    async def execute(self, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡Œæœç´¢è¡¨æƒ…åŒ…æ“ä½œ"""
        emoji_manager = get_emoji_manager()
        if not emoji_manager:
            return {
                "success": False,
                "error": "è¡¨æƒ…åŒ…ç®¡ç†å™¨æœªåˆå§‹åŒ–"
            }
        
        try:
            keyword = kwargs.get("keyword")
            
            if not keyword:
                return {
                    "success": False,
                    "error": "ç¼ºå°‘æœç´¢å…³é”®è¯"
                }
            
            emojis = emoji_manager.search_emojis(keyword)
            
            return {
                "success": True,
                "result": {
                    "keyword": keyword,
                    "count": len(emojis),
                    "emojis": [{
                        "emoji_hash": emoji.emoji_hash,
                        "description": emoji.description,
                        "emotions": emoji.emotions,
                        "tags": emoji.tags,
                        "category": emoji.category
                    } for emoji in emojis]
                },
                "error": None
            }
            
        except Exception as e:
            logger.error(f"æœç´¢è¡¨æƒ…åŒ…å¤±è´¥: {e}")
            return {
                "success": False,
                "result": None,
                "error": f"æœç´¢è¡¨æƒ…åŒ…å¤±è´¥: {str(e)}"
            }
```
- **åŠŸèƒ½**: æä¾›ä¸°å¯Œçš„è¡¨æƒ…åŒ…æ“ä½œå·¥å…·ï¼Œæ”¯æŒæ·»åŠ ã€åˆ é™¤ã€æŸ¥è¯¢ã€éšæœºè·å–ã€åˆ†ç±»ç®¡ç†ç­‰åŠŸèƒ½
- **è®¾è®¡æ€è·¯**: 
  - åŸºäºBaseToolç±»å®ç°å¤šç§è¡¨æƒ…åŒ…æ“ä½œå·¥å…·
  - ä½¿ç”¨åŠ¨æ€å¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥é—®é¢˜
  - æä¾›ç»Ÿä¸€çš„å·¥å…·æ¥å£ï¼Œæ”¯æŒLLMè°ƒç”¨
  - å®ç°é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•ï¼Œæé«˜ç³»ç»Ÿç¨³å®šæ€§
  - æ”¯æŒå‚æ•°éªŒè¯å’Œæ ¼å¼è½¬æ¢ï¼Œç¡®ä¿è¾“å…¥è¾“å‡ºçš„æ­£ç¡®æ€§
- **å½±å“èŒƒå›´**: 
  - è¡¨æƒ…åŒ…çš„ç®¡ç†å’Œæ“ä½œèƒ½åŠ›
  - æ™ºèƒ½ä½“ä¸è¡¨æƒ…åŒ…çš„äº¤äº’æ–¹å¼
  - ç”¨æˆ·ä½¿ç”¨è¡¨æƒ…åŒ…åŠŸèƒ½çš„ä½“éªŒ
  - è¡¨æƒ…åŒ…æ•°æ®çš„å®Œæ•´æ€§å’Œå®‰å…¨æ€§

#### app/plugins/emoji_plugin/plugin.py
```python
from typing import List, Dict, Any, Optional, Type
from app.plugins.base_plugin import BasePlugin, PluginInfo
from app.tools.base_tool import BaseTool
from .emoji_manager import initialize_emoji_manager
from .tools import (
    AddEmojiTool,
    DeleteEmojiTool,
    ListEmojisTool,
    GetEmojiTool,
    GetRandomEmojiTool,
    GetEmojiStatsTool,
    AddEmojiFromUrlTool
)
import logging

logger = logging.getLogger("EmojiPlugin")


class EmojiPlugin(BasePlugin):
    """è¡¨æƒ…åŒ…æ’ä»¶"""
    
    plugin_info = PluginInfo(
        name="emoji_plugin",
        version="1.0.0",
        description="æä¾›è¡¨æƒ…åŒ…ç®¡ç†åŠŸèƒ½ï¼Œæ”¯æŒæ·»åŠ ã€åˆ é™¤ã€æŸ¥è¯¢å’Œéšæœºè·å–è¡¨æƒ…åŒ…",
        author="Your Name"
    )
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """åˆå§‹åŒ–æ’ä»¶
        
        Args:
            config: æ’ä»¶é…ç½®
        """
        super().__init__(config)
        self.data_dir = self.config.get("data_dir", "emoji_data")
    
    def get_tools(self) -> List[Type[BaseTool]]:
        """è·å–æ’ä»¶æä¾›çš„å·¥å…·åˆ—è¡¨"""
        return [
            AddEmojiTool,
            DeleteEmojiTool,
            ListEmojisTool,
            GetEmojiTool,
            GetRandomEmojiTool,
            GetEmojiStatsTool,
            AddEmojiFromUrlTool
        ]
    
    async def _initialize(self) -> bool:
        """æ’ä»¶è‡ªå®šä¹‰åˆå§‹åŒ–é€»è¾‘"""
        try:
            # åˆå§‹åŒ–è¡¨æƒ…åŒ…ç®¡ç†å™¨
            if initialize_emoji_manager(self.data_dir):
                logger.info(f"è¡¨æƒ…åŒ…ç®¡ç†å™¨å·²åˆå§‹åŒ–ï¼Œæ•°æ®ç›®å½•: {self.data_dir}")
                return True
            else:
                logger.error("è¡¨æƒ…åŒ…ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥")
                return False
        except Exception as e:
            logger.error(f"æ’ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    async def shutdown(self) -> bool:
        """å…³é—­æ’ä»¶"""
        try:
            logger.info("è¡¨æƒ…åŒ…æ’ä»¶å·²å…³é—­")
            return True
        except Exception as e:
            logger.error(f"æ’ä»¶å…³é—­å¤±è´¥: {e}")
            return False
```
- **åŠŸèƒ½**: æä¾›è¡¨æƒ…åŒ…ç®¡ç†åŠŸèƒ½ï¼Œæ”¯æŒæ·»åŠ ã€åˆ é™¤ã€æŸ¥è¯¢å’Œéšæœºè·å–è¡¨æƒ…åŒ…
- **è®¾è®¡æ€è·¯**: 
  - ç»§æ‰¿è‡ªåŸºç¡€æ’ä»¶ç±»ï¼Œå®ç°æ’ä»¶æ¥å£
  - åˆå§‹åŒ–è¡¨æƒ…åŒ…ç®¡ç†å™¨ï¼Œè´Ÿè´£è¡¨æƒ…åŒ…æ•°æ®çš„å­˜å‚¨å’ŒåŠ è½½
  - æä¾›å¤šç§è¡¨æƒ…åŒ…æ“ä½œå·¥å…·ï¼Œæ–¹ä¾¿æ™ºèƒ½ä½“è°ƒç”¨
  - æ”¯æŒä»URLæ·»åŠ è¡¨æƒ…åŒ…ï¼Œæ‰©å±•è¡¨æƒ…åŒ…æ¥æº
- **å½±å“èŒƒå›´**: 
  - æ™ºèƒ½ä½“ä½¿ç”¨è¡¨æƒ…åŒ…çš„èƒ½åŠ›
  - ç”¨æˆ·ä¸æ™ºèƒ½ä½“çš„æƒ…æ„Ÿäº¤äº’ä½“éªŒ
  - è¡¨æƒ…åŒ…æ•°æ®çš„ç®¡ç†å’Œå­˜å‚¨

#### app/plugins/plugin_manager.py
```python
class PluginManager:
    """
    æ’ä»¶ç®¡ç†å™¨
    ç”¨äºåŠ è½½ã€åˆå§‹åŒ–å’Œç®¡ç†æ‰€æœ‰æ’ä»¶
    """
    
    def __init__(self):
        """åˆå§‹åŒ–æ’ä»¶ç®¡ç†å™¨"""
        self._plugins: Dict[str, BasePlugin] = {}  # æ’ä»¶åç§° -> æ’ä»¶å®ä¾‹
        self._plugin_classes: Dict[str, Type[BasePlugin]] = {}  # æ’ä»¶åç§° -> æ’ä»¶ç±»
    
    def load_plugins_from_directory(self, directory: str) -> int:
        """
        ä»ç›®å½•åŠ è½½æ’ä»¶
        - æ”¯æŒåŠ è½½å•ä¸ªæ’ä»¶æ–‡ä»¶å’Œæ’ä»¶ç›®å½•
        - è‡ªåŠ¨è·³è¿‡ __pycache__ ç›®å½•å’Œç‰¹æ®Šæ–‡ä»¶
        
        Args:
            directory: æ’ä»¶ç›®å½•
            
        Returns:
            int: åŠ è½½çš„æ’ä»¶æ•°é‡
        """
        # å®ç°ä»£ç ...
    
    async def initialize_plugins(self) -> int:
        """
        åˆå§‹åŒ–æ‰€æœ‰æ’ä»¶
        - åˆ›å»ºæ’ä»¶å®ä¾‹
        - è°ƒç”¨æ’ä»¶çš„ initialize æ–¹æ³•
        
        Returns:
            int: åˆå§‹åŒ–æˆåŠŸçš„æ’ä»¶æ•°é‡
        """
        # å®ç°ä»£ç ...
    
    async def shutdown_plugins(self) -> int:
        """
        å…³é—­æ‰€æœ‰æ’ä»¶
        - è°ƒç”¨æ’ä»¶çš„ shutdown æ–¹æ³•
        - æ¸…ç†æ’ä»¶å®ä¾‹
        
        Returns:
            int: å…³é—­æˆåŠŸçš„æ’ä»¶æ•°é‡
        """
        # å®ç°ä»£ç ...
    
    def get_plugin(self, plugin_name: str) -> Optional[BasePlugin]:
        """è·å–æ’ä»¶å®ä¾‹"""
        # å®ç°ä»£ç ...
    
    def get_all_plugins(self) -> Dict[str, BasePlugin]:
        """è·å–æ‰€æœ‰æ’ä»¶å®ä¾‹"""
        # å®ç°ä»£ç ...
    
    def get_plugins_stats(self) -> Dict[str, Any]:
        """è·å–æ’ä»¶ç»Ÿè®¡ä¿¡æ¯"""
        # å®ç°ä»£ç ...


# åˆ›å»ºå…¨å±€æ’ä»¶ç®¡ç†å™¨å®ä¾‹
plugin_manager = PluginManager()
```
- **åŠŸèƒ½**: ç®¡ç†æ’ä»¶ç³»ç»Ÿçš„åŠ è½½ã€åˆå§‹åŒ–ã€è¿è¡Œå’Œå…³é—­
- **è®¾è®¡æ€è·¯**: 
  - æä¾›ç»Ÿä¸€çš„æ’ä»¶ç®¡ç†æ¥å£
  - æ”¯æŒä»ç›®å½•è‡ªåŠ¨åŠ è½½æ’ä»¶
  - æ”¯æŒæ’ä»¶çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼ˆåˆå§‹åŒ–ã€è¿è¡Œã€å…³é—­ï¼‰
  - æä¾›æ’ä»¶ç»Ÿè®¡å’ŒæŸ¥è¯¢åŠŸèƒ½
  - ä½¿ç”¨å•ä¾‹æ¨¡å¼ï¼Œæ–¹ä¾¿å…¨å±€è®¿é—®
- **å½±å“èŒƒå›´**: 
  - æ‰€æœ‰æ’ä»¶çš„åŠ è½½å’Œè¿è¡Œ
  - æ’ä»¶ç³»ç»Ÿçš„æ‰©å±•æ€§å’Œç¨³å®šæ€§
  - æ–°æ’ä»¶çš„å¼€å‘å’Œé›†æˆéš¾åº¦

#### app/plugins/example_plugin.py
```python
from app.plugins.base_plugin import BasePlugin, PluginInfo
from app.tools.base_tool import BaseTool, ToolParam


class ExampleTool(BaseTool):
    """ç¤ºä¾‹å·¥å…·"""
    
    name = "example_tool"
    description = "ä¸€ä¸ªç¤ºä¾‹å·¥å…·ï¼Œç”¨äºæ¼”ç¤ºæ’ä»¶ç³»ç»Ÿçš„ä½¿ç”¨"
    parameters = [
        ToolParam(
            name="message",
            param_type="string",
            description="è¦å¤„ç†çš„æ¶ˆæ¯",
            required=True
        )
    ]
    available_for_llm = True
    
    async def execute(self, message: str, **kwargs) -> dict:
        """æ‰§è¡Œç¤ºä¾‹å·¥å…·"""
        try:
            result = f"ç¤ºä¾‹å·¥å…·å·²å¤„ç†æ¶ˆæ¯: {message}"
            return {
                "success": True,
                "result": result,
                "error": ""
            }
        except Exception as e:
            error_msg = f"ç¤ºä¾‹å·¥å…·æ‰§è¡Œå¤±è´¥: {e}"
            return {
                "success": False,
                "result": "",
                "error": error_msg
            }


class ExamplePlugin(BasePlugin):
    """ç¤ºä¾‹æ’ä»¶"""
    
    plugin_info = PluginInfo(
        name="example_plugin",
        version="1.0.0",
        description="ä¸€ä¸ªç¤ºä¾‹æ’ä»¶ï¼Œç”¨äºæ¼”ç¤ºæ’ä»¶ç³»ç»Ÿçš„ä½¿ç”¨",
        author="AliceBot Team"
    )
    
    def get_tools(self) -> list[type[BaseTool]]:
        """è·å–æ’ä»¶æä¾›çš„å·¥å…·åˆ—è¡¨"""
        return [ExampleTool]
    
    async def _initialize(self) -> bool:
        """æ’ä»¶è‡ªå®šä¹‰åˆå§‹åŒ–é€»è¾‘"""
        logger.info(f"ç¤ºä¾‹æ’ä»¶ '{self.plugin_info.name}' v{self.plugin_info.version} åˆå§‹åŒ–å®Œæˆ")
        return True
    
    async def _shutdown(self) -> bool:
        """æ’ä»¶è‡ªå®šä¹‰å…³é—­é€»è¾‘"""
        logger.info(f"ç¤ºä¾‹æ’ä»¶ '{self.plugin_info.name}' v{self.plugin_info.version} å·²å…³é—­")
        return True
```
- **åŠŸèƒ½**: æä¾›æ’ä»¶å¼€å‘çš„ç¤ºä¾‹ä»£ç ï¼Œå±•ç¤ºå¦‚ä½•åˆ›å»ºå’Œä½¿ç”¨æ’ä»¶
- **è®¾è®¡æ€è·¯**: 
  - ç»§æ‰¿ BasePlugin ç±»ï¼Œå®ç°è‡ªå®šä¹‰æ’ä»¶
  - æ¼”ç¤ºå¦‚ä½•åœ¨æ’ä»¶ä¸­å®šä¹‰å’Œæ³¨å†Œå·¥å…·
  - å±•ç¤ºæ’ä»¶çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†æ–¹æ³•
- **å½±å“èŒƒå›´**: 
  - æ’ä»¶å¼€å‘çš„å‚è€ƒç¤ºä¾‹
  - æ–°æ’ä»¶å¼€å‘è€…çš„å­¦ä¹ èµ„æº
  - æ’ä»¶ç³»ç»Ÿçš„ä½¿ç”¨æ–¹å¼ç¤ºä¾‹

### 3.7 é¡¹ç›®å…¥å£æ–‡ä»¶

#### qq_server.py
```python
# === Pythonä»£ç æ–‡ä»¶: qq_server.py ===

# é¦–å…ˆé…ç½®æ—¥å¿—å’Œè­¦å‘Šè¿‡æ»¤
import logging
import warnings
import builtins
from langchain_core._api.deprecation import LangChainDeprecationWarning

# è¿‡æ»¤ç¬¬ä¸‰æ–¹åº“è­¦å‘Š
warnings.filterwarnings("ignore", category=builtins.UserWarning, module="langchain_tavily")
warnings.filterwarnings("ignore", category=LangChainDeprecationWarning)

import uvicorn
import asyncio
import uuid
import re
import time
import os
from contextlib import asynccontextmanager
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Request
from langchain_core.messages import HumanMessage, AIMessage

from app.core.global_store import global_store
from app.graph.graph_builder import build_graph
from app.memory.relation_db import relation_db
from app.memory.local_history import LocalHistoryManager
from app.background.dream import dream_machine
from app.utils.qq_utils import parse_onebot_array_msg
from app.plugins.emoji_plugin.emoji_service import get_emoji_service


class SessionManager:
    """
    ä¼šè¯æ´»è·ƒç®¡ç†å™¨
    ç”¨äºè·Ÿè¸ªå’Œç®¡ç†ç”¨æˆ·ä¼šè¯çš„æ´»è·ƒçŠ¶æ€
    """
    def __init__(self):
        # è®°å½• session_id -> {last_active: timestamp, type: 'group'/'private', target_id: str, self_id: str}
        self.sessions = {}
        self.lock = asyncio.Lock()
    
    async def update_activity(self, session_id: str, msg_type: str, target_id: str, self_id: str):
        # æ›´æ–°ä¼šè¯æ´»è·ƒçŠ¶æ€
        pass
    
    async def get_active_sessions(self, timeout_seconds=3600):
        # è·å–æœ€è¿‘æ´»è·ƒçš„ä¼šè¯
        pass


class MessageBuffer:
    """
    å¢å¼ºç‰ˆæ¶ˆæ¯æ‰¹å¤„ç†å™¨
    æ”¯æŒåŸºäºæ—¶é—´å’Œæ•°é‡çš„åŒé‡æ‰¹å¤„ç†æ¡ä»¶ï¼Œä»¥åŠä¸åŒä¼šè¯ç±»å‹çš„æ™ºèƒ½ç­–ç•¥
    """
    def __init__(self):
        self.buffers = {}
        self.lock = asyncio.Lock()
        
        # æ‰¹å¤„ç†ç­–ç•¥é…ç½®
        self.strategies = {
            "group": {"wait_time": 0.3, "max_batch_size": 8, "max_wait_time": 1.0},
            "private": {"wait_time": 0.5, "max_batch_size": 3, "max_wait_time": 1.2}
        }
    
    async def add(self, session_id: str, message_data: dict, callback):
        # æ·»åŠ æ¶ˆæ¯åˆ°ç¼“å†²åŒº
        pass


class QQBotManager:
    """
    QQæœºå™¨äººç®¡ç†å™¨
    é¡¹ç›®çš„æ ¸å¿ƒæ§åˆ¶å™¨ï¼Œè´Ÿè´£å¤„ç†æ‰€æœ‰ç”¨æˆ·æ¶ˆæ¯å’Œç³»ç»Ÿäº‹ä»¶
    """
    def __init__(self):
        self.connections: dict[str, WebSocket] = {}  # WebSocketè¿æ¥ç®¡ç†
        self.graph = build_graph()  # æ„å»ºLangGraphå·¥ä½œæµ
        self.msg_buffer = MessageBuffer()  # æ¶ˆæ¯æ‰¹å¤„ç†å™¨
        self.api_futures: dict[str, asyncio.Future] = {}  # APIè°ƒç”¨ç»“æœç®¡ç†
        self.session_locks: dict[str, asyncio.Lock] = {}  # ä¼šè¯é”ç®¡ç†
    
    async def call_api(self, self_id: str, action: str, params: dict):
        # è°ƒç”¨OneBot API
        pass
    
    async def send_msg(self, self_id: str, target_type: str, target_id: int, message: str):
        # å‘é€æ¶ˆæ¯
        pass
    
    async def process_batch(self, session_id: str, raw_messages: list):
        # å¤„ç†æ‰¹é‡ç”¨æˆ·æ¶ˆæ¯
        pass
    
    async def run_proactive_check(self):
        # è¿è¡Œä¸»åŠ¨ç¤¾äº¤æ£€æŸ¥
        pass


@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    FastAPIç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨
    è´Ÿè´£å¯åŠ¨å’Œå…³é—­åå°ä»»åŠ¡
    """
    # å¯åŠ¨åå°ä»»åŠ¡
    proactive_task = asyncio.create_task(qq_bot.run_proactive_check())
    dream_task = asyncio.create_task(dream_machine())
    
    yield
    
    # å…³é—­åå°ä»»åŠ¡
    proactive_task.cancel()
    dream_task.cancel()
    await asyncio.gather(proactive_task, dream_task, return_exceptions=True)


# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(lifespan=lifespan)

# åˆ›å»ºQQæœºå™¨äººç®¡ç†å™¨å®ä¾‹
qq_bot = QQBotManager()


@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """
    WebSocketç«¯ç‚¹
    å¤„ç†OneBotå®¢æˆ·ç«¯çš„è¿æ¥å’Œæ¶ˆæ¯
    """
    # å¤„ç†WebSocketè¿æ¥
    pass


if __name__ == "__main__":
    # å¯åŠ¨FastAPIæœåŠ¡å™¨
    uvicorn.run("qq_server:app", host="0.0.0.0", port=6199, log_level="info")
```
- **åŠŸèƒ½**: é¡¹ç›®çš„å…¥å£æ–‡ä»¶ï¼Œè´Ÿè´£å¯åŠ¨FastAPIæœåŠ¡å™¨ï¼Œå¤„ç†OneBotå®¢æˆ·ç«¯çš„è¿æ¥å’Œæ¶ˆæ¯ï¼Œç®¡ç†ä¼šè¯çŠ¶æ€å’Œåå°ä»»åŠ¡
- **è®¾è®¡æ€è·¯**: 
  - ä½¿ç”¨FastAPIæ¡†æ¶æ„å»ºWebSocketæœåŠ¡å™¨ï¼Œä¸OneBotå®¢æˆ·ç«¯è¿›è¡Œé€šä¿¡
  - å®ç°ä¼šè¯æ´»è·ƒç®¡ç†ï¼Œè·Ÿè¸ªç”¨æˆ·ä¼šè¯çš„æ´»è·ƒçŠ¶æ€
  - æä¾›æ¶ˆæ¯æ‰¹å¤„ç†åŠŸèƒ½ï¼Œä¼˜åŒ–å¤šæ¶ˆæ¯çš„å¤„ç†æ•ˆç‡
  - é›†æˆLangGraphå·¥ä½œæµï¼Œå¤„ç†ç”¨æˆ·æ¶ˆæ¯çš„ç”Ÿæˆå’Œå“åº”
  - ç®¡ç†åå°ä»»åŠ¡ï¼ŒåŒ…æ‹¬ä¸»åŠ¨ç¤¾äº¤æ£€æŸ¥å’Œè®°å¿†æ•´ç†
  - ä½¿ç”¨å¼‚æ­¥ç¼–ç¨‹æ¨¡å‹ï¼Œæé«˜ç³»ç»Ÿçš„å¹¶å‘å¤„ç†èƒ½åŠ›
- **å½±å“èŒƒå›´**: 
  - æ•´ä¸ªé¡¹ç›®çš„å¯åŠ¨å’Œè¿è¡Œ
  - OneBotå®¢æˆ·ç«¯çš„è¿æ¥å’Œæ¶ˆæ¯å¤„ç†
  - ç”¨æˆ·ä¼šè¯çš„ç®¡ç†å’ŒçŠ¶æ€ç»´æŠ¤
  - åå°ä»»åŠ¡çš„æ‰§è¡Œå’Œè°ƒåº¦
  - ç³»ç»Ÿçš„æ€§èƒ½å’Œç¨³å®šæ€§

### 3.8 åå°ä»»åŠ¡æ¨¡å— (Background)

#### app/background/__init__.py
```python
# ç©ºæ–‡ä»¶ï¼Œç”¨äºæ ‡è¯† background ç›®å½•ä¸º Python åŒ…
```
- **åŠŸèƒ½**: æ ‡è¯† background ç›®å½•ä¸º Python åŒ…ï¼Œæ–¹ä¾¿å¯¼å…¥
- **è®¾è®¡æ€è·¯**: æ¨¡å—åŒ–è®¾è®¡ï¼Œå°†åå°ä»»åŠ¡ç›¸å…³çš„ä»£ç é›†ä¸­ç®¡ç†
- **å½±å“èŒƒå›´**: æ— ç›´æ¥å½±å“ï¼Œä»…ä½œä¸ºåŒ…æ ‡è¯†

#### app/background/dream.py
```python
import asyncio
import json
import logging
import os
from datetime import datetime, timedelta
from typing import List, Dict

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

from app.core.config import config
from app.memory.vector_store import vector_db
from app.core.global_store import global_store
from app.utils.cache import cached_llm_invoke

logger = logging.getLogger("DreamCycle")

# --- è®°å¿†å›ºåŒ– Prompt ---
CONSOLIDATION_PROMPT = """
ä½ æ˜¯ Alice çš„æ½œæ„è¯†æ•´ç†è€…ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ç¢ç‰‡åŒ–çš„çŸ­æœŸè®°å¿†åˆå¹¶ä¸ºæœ‰ä»·å€¼çš„é•¿æœŸè®°å¿†ã€‚

ã€å¾…æ•´ç†çš„è®°å¿†ç¢ç‰‡ã€‘
{fragments}

ã€ä»»åŠ¡è¦æ±‚ã€‘
1. åˆ†æè¿™äº›ç¢ç‰‡ä¹‹é—´æ˜¯å¦å­˜åœ¨å…³è”ï¼ˆä¾‹å¦‚ï¼šéƒ½æ˜¯å…³äºé¥®é£Ÿåå¥½ã€éƒ½æ˜¯å…³äºæŸä¸ªç‰¹å®šé¡¹ç›®ã€æˆ–è€…æ˜¯è¿ç»­çš„äº‹ä»¶ï¼‰ã€‚
2. å¦‚æœå­˜åœ¨å…³è”ï¼Œè¯·å°†å®ƒä»¬**æ¦‚æ‹¬**ä¸ºä¸€æ¡ç®€æ´çš„ã€åŒ…å«æ ¸å¿ƒä¿¡æ¯çš„é™ˆè¿°å¥ã€‚
3. æ¦‚æ‹¬åçš„è®°å¿†åº”å½“å»é™¤æ—¶é—´çŠ¶è¯­ï¼ˆå¦‚â€œåˆšæ‰â€ã€â€œä»Šå¤©â€ï¼‰ï¼Œè½¬å˜ä¸ºæŒä¹…çš„äº‹å®æè¿°ã€‚
4. å¦‚æœç¢ç‰‡ä¹‹é—´æ²¡æœ‰æ˜æ˜¾å…³è”ï¼Œæˆ–è€…ä¿¡æ¯å¤ªæ‚ä¹±æ— æ³•åˆå¹¶ï¼Œè¯·è¾“å‡º "SKIP"ã€‚

ã€è¾“å‡ºç¤ºä¾‹ã€‘
è¾“å…¥ç¢ç‰‡: ["ç”¨æˆ·è¯´ä»Šå¤©æƒ³åƒè¾£", "ä¸­åˆç‚¹äº†éº»è¾£çƒ«", "æ™šä¸Šè¿˜åœ¨æ‰¾ç«é”…åº—"]
è¾“å‡º: ç”¨æˆ·éå¸¸å–œæ¬¢åƒè¾£çš„é£Ÿç‰©ï¼Œå°¤å…¶æ˜¯éº»è¾£çƒ«å’Œç«é”…ã€‚

è¯·è¾“å‡ºç»“æœ (çº¯æ–‡æœ¬):
"""


class DreamCycle:
    def __init__(self, interval_seconds=1800):
        """
        :param interval_seconds: åšæ¢¦å¾ªç¯çš„é—´éš”ï¼Œé»˜è®¤ 30 åˆ†é’Ÿ (1800ç§’)
        """
        self.interval = interval_seconds
        self.running = False
        self._task = None

        # ä¸“é—¨ç”¨äºæ•´ç†è®°å¿†çš„ LLMï¼Œå¯ä»¥ä½¿ç”¨ä¾¿å®œçš„æ¨¡å‹
        self.llm = ChatOpenAI(
            model=config.MODEL_NAME,
            temperature=0.1,
            api_key=config.MODEL_API_KEY,
            base_url=config.MODEL_URL
        )

    async def start(self):
        # åœ¨Windowsä¸Šä½¿ç”¨æ–‡ä»¶é”ç¡®ä¿åªæœ‰ä¸€ä¸ªè¿›ç¨‹èƒ½å¯åŠ¨DreamCycle
        # å®ç°æ–‡ä»¶é”é€»è¾‘
        pass

    async def stop(self):
        self.running = False
        if self._task:
            self._task.cancel()
            try:
                await self._task
            except asyncio.CancelledError:
                pass
        # é‡Šæ”¾æ–‡ä»¶é”
        pass

    async def _dream_loop(self):
        while self.running:
            try:
                await asyncio.sleep(self.interval)
                
                # æ£€æŸ¥ç”¨æˆ·æ´»è·ƒåº¦
                last_active_str = global_store.get_emotion_snapshot().last_updated
                last_active = datetime.strptime(last_active_str, "%Y-%m-%d %H:%M:%S")
                if (datetime.now() - last_active).total_seconds() < 300:
                    continue

                # æ‰§è¡Œæ¸…ç†é€»è¾‘
                deleted_count = self._prune_garbage_memories(days_threshold=3)

                # æ‰§è¡Œå›ºåŒ–é€»è¾‘
                consolidated_count = await self._consolidate_memories()

                # æ¢å¤ä½“åŠ›
                if deleted_count > 0 or consolidated_count > 0:
                    global_store.update_emotion(0, 0, stamina_delta=30.0)

            except Exception as e:
                logger.error(f"âŒ [Dream Error] {e}", exc_info=True)

    def _prune_garbage_memories(self, days_threshold: int = 3) -> int:
        """
        æ¸…ç†é€»è¾‘ï¼šåˆ é™¤ [importance=1] ä¸” [åˆ›å»ºæ—¶é—´ > 3å¤©] çš„è®°å¿†
        """
        # å®ç°è®°å¿†æ¸…ç†é€»è¾‘
        pass

    async def _consolidate_memories(self) -> int:
        """
        å›ºåŒ–é€»è¾‘ï¼š
        1. æ‰¾å‡ºæœ€è¿‘ 24 å°æ—¶äº§ç”Ÿçš„ã€importance=2 (Context) æˆ– 3 (Preference) çš„è®°å¿†ã€‚
        2. å¦‚æœç¢ç‰‡æ•°é‡ > 3ï¼Œå°è¯•è®© LLM æ€»ç»“ã€‚
        3. å¦‚æœæ€»ç»“æˆåŠŸï¼Œå†™å…¥ä¸€æ¡ importance=4 çš„æ–°è®°å¿†ï¼Œå¹¶åˆ é™¤æ—§ç¢ç‰‡ã€‚
        """
        # å®ç°è®°å¿†å›ºåŒ–é€»è¾‘
        pass


# å•ä¾‹å¯¼å‡º
dream_machine = DreamCycle(interval_seconds=1800)
```
- **åŠŸèƒ½**: é¡¹ç›®çš„è®°å¿†æ•´ç†æ¨¡å—ï¼Œè´Ÿè´£å°†ç¢ç‰‡åŒ–çš„çŸ­æœŸè®°å¿†åˆå¹¶ä¸ºæœ‰ä»·å€¼çš„é•¿æœŸè®°å¿†ï¼Œå¹¶æ¸…ç†è¿‡æœŸçš„ä½é‡è¦æ€§è®°å¿†
- **è®¾è®¡æ€è·¯**: 
  - æ¨¡æ‹Ÿäººç±»çš„æ¢¦å¢ƒå‘¨æœŸï¼Œå®šæœŸåœ¨åå°è¿è¡Œè®°å¿†æ•´ç†ä»»åŠ¡
  - ä½¿ç”¨æ–‡ä»¶é”ç¡®ä¿åªæœ‰ä¸€ä¸ªè¿›ç¨‹èƒ½å¯åŠ¨DreamCycleï¼Œé¿å…èµ„æºå†²çª
  - å®ç°è®°å¿†çš„"æ–°é™ˆä»£è°¢"æœºåˆ¶ï¼šæ¸…ç†ä½é‡è¦æ€§çš„æ—§è®°å¿†ï¼Œåˆå¹¶ç›¸å…³çš„çŸ­æœŸè®°å¿†ä¸ºé•¿æœŸè®°å¿†
  - ä½¿ç”¨ç¼“å­˜çš„LLMè°ƒç”¨ï¼Œå‡å°‘APIè¯·æ±‚æ¬¡æ•°å’Œæˆæœ¬
  - åªåœ¨ç”¨æˆ·ä¸æ´»è·ƒæ—¶è¿è¡Œï¼Œé¿å…å¹²æ‰°ç”¨æˆ·çš„æ­£å¸¸äº¤äº’
- **å½±å“èŒƒå›´**: 
  - è®°å¿†ç³»ç»Ÿçš„æ€§èƒ½å’Œå­˜å‚¨ç©ºé—´ä½¿ç”¨
  - é•¿æœŸè®°å¿†çš„è´¨é‡å’Œå‡†ç¡®æ€§
  - ç³»ç»Ÿçš„èµ„æºæ¶ˆè€—ï¼ˆå¦‚CPUã€å†…å­˜ã€APIè°ƒç”¨ï¼‰
  - ç”¨æˆ·ä½“éªŒçš„æµç•…æ€§ï¼ˆé¿å…åœ¨ç”¨æˆ·æ´»è·ƒæ—¶è¿è¡Œï¼‰

### 3.9 æ ¸å¿ƒæ¨¡å— (Core)

#### app/core/__init__.py
```python
# ç©ºæ–‡ä»¶ï¼Œç”¨äºæ ‡è¯† core ç›®å½•ä¸º Python åŒ…
```
- **åŠŸèƒ½**: æ ‡è¯† core ç›®å½•ä¸º Python åŒ…ï¼Œæ–¹ä¾¿å¯¼å…¥
- **è®¾è®¡æ€è·¯**: æ¨¡å—åŒ–è®¾è®¡ï¼Œå°†æ ¸å¿ƒåŠŸèƒ½ç›¸å…³çš„ä»£ç é›†ä¸­ç®¡ç†
- **å½±å“èŒƒå›´**: æ— ç›´æ¥å½±å“ï¼Œä»…ä½œä¸ºåŒ…æ ‡è¯†

#### app/core/config.py
```python
import os
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()

# è·å–AliceBotæ ¹ç›®å½•
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


class Config:
    # --- LLM Settings ---

    SILICONFLOW_API_KEY = os.getenv("SILICONFLOW_API_KEY") or os.getenv("SILICON_API_KEY")
    SILICONFLOW_BASE_URL = os.getenv("SILICONFLOW_BASE_URL", "https://api.siliconflow.cn/v1") or os.getenv("SILICON_URL")

    MIMO_API_KEY = os.getenv("MIMO_API_KEY")
    MIMO_BASE_URL = os.getenv("MIMO_BASE_URL", "https://api.xiaomimimo.com/v1")
    MIMO_MODEL = os.getenv("MIMO_MODEL")

    AIZEX_API_KEY = os.getenv("AIZEX_API_KEY")
    AIZEX_URL = os.getenv("AIZEX_URL", "https://a1.aizex.me/v1")
    AIZEX_MODEL = os.getenv("AIZEX_MODEL")

    # æ¨èä½¿ç”¨æ”¯æŒ Function Calling å’Œå¼ºé€»è¾‘èƒ½åŠ›çš„æ¨¡å‹
    LLM_MODEL_NAME = os.getenv("LLM_MODEL_NAME", "Qwen/Qwen3-VL-30B-A3B-Instruct")
    SMALL_LLM_MODEL_NAME = os.getenv("SMALL_LLM_MODEL_NAME", "Qwen/Qwen3-VL-8B-Instruct")
    EMBEDDING_MODEL_NAME = os.getenv("EMBEDDING_MODEL_NAME", "Qwen/Qwen3-Embedding-8B")
    TEMPERATURE = 0.7

    # vision_router context_filter memory_saver psychology summarizer
    SMALL_PROVIDER = "siliconflow"
    PROVIDER = "siliconflow"
    # mimo
    # aizex
    if SMALL_PROVIDER == "aizex":
        SMALL_MODEL_API_KEY = AIZEX_API_KEY
        SMALL_MODEL_URL = AIZEX_URL
        SMALL_MODEL = AIZEX_MODEL
    elif SMALL_PROVIDER == "siliconflow":
        SMALL_MODEL_API_KEY = SILICONFLOW_API_KEY
        SMALL_MODEL_URL = SILICONFLOW_BASE_URL
        SMALL_MODEL = SMALL_LLM_MODEL_NAME
    elif SMALL_PROVIDER == "mimo":
        SMALL_MODEL_API_KEY = MIMO_API_KEY
        SMALL_MODEL_URL = MIMO_BASE_URL
        SMALL_MODEL = MIMO_MODEL

    # dream proactive_agent unified_agent
    if PROVIDER == "aizex":
        MODEL_API_KEY = AIZEX_API_KEY
        MODEL_URL = AIZEX_URL
        MODEL_NAME = AIZEX_MODEL
    elif PROVIDER == "siliconflow":
        MODEL_API_KEY = SILICONFLOW_API_KEY
        MODEL_URL = SILICONFLOW_BASE_URL
        MODEL_NAME = LLM_MODEL_NAME
    elif PROVIDER == "mimo":
        MODEL_API_KEY = MIMO_API_KEY
        MODEL_URL = MIMO_BASE_URL
        MODEL_NAME = MIMO_MODEL

    # --- Vector DB Settings ---
    VECTOR_DB_PATH = os.getenv("VECTOR_DB_PATH", os.path.join(BASE_DIR, "data", "chroma_db"))
    COLLECTION_NAME = "anima_memories"

    # --- Tool Settings ---
    MAX_SEARCH_RESULTS = 3

    # --- Emotion & Personality Settings ---
    # åˆå§‹æƒ…ç»ªçŠ¶æ€
    DEFAULT_VALENCE = 0.1  # ç•¥å¾®ç§¯æ
    DEFAULT_AROUSAL = 0.5  # å¹³é™ä¸”ä¸“æ³¨

    # --- System Paths ---
    LOG_DIR = os.getenv("LOG_DIR", os.path.join(BASE_DIR, "log"))


config = Config()
```
- **åŠŸèƒ½**: é¡¹ç›®çš„é…ç½®ç®¡ç†æ¨¡å—ï¼Œè´Ÿè´£åŠ è½½å’Œç®¡ç†æ‰€æœ‰ç³»ç»Ÿé…ç½®å‚æ•°
- **è®¾è®¡æ€è·¯**: 
  - ä½¿ç”¨å•ä¾‹æ¨¡å¼ï¼Œç¡®ä¿é…ç½®çš„ä¸€è‡´æ€§å’Œå…¨å±€å¯è®¿é—®æ€§
  - ä»ç¯å¢ƒå˜é‡å’Œ.envæ–‡ä»¶ä¸­åŠ è½½é…ç½®ï¼Œæ”¯æŒçµæ´»çš„éƒ¨ç½²å’Œé…ç½®ç®¡ç†
  - æ”¯æŒå¤šç§LLMæä¾›å•†ï¼ˆå¦‚SiliconFlowã€MIMOã€AIZEXï¼‰ï¼Œæ–¹ä¾¿åˆ‡æ¢å’Œæ‰©å±•
  - åˆ†ç¦»ä¸åŒç±»å‹çš„é…ç½®ï¼ˆLLMè®¾ç½®ã€å‘é‡æ•°æ®åº“è®¾ç½®ã€å·¥å…·è®¾ç½®ã€æƒ…ç»ªä¸ªæ€§è®¾ç½®ç­‰ï¼‰ï¼Œæé«˜ä»£ç çš„å¯è¯»æ€§å’Œå¯ç»´æŠ¤æ€§
  - è®¾ç½®åˆç†çš„é»˜è®¤å€¼ï¼Œç¡®ä¿ç³»ç»Ÿåœ¨æ²¡æœ‰å®Œæ•´é…ç½®çš„æƒ…å†µä¸‹ä¹Ÿèƒ½æ­£å¸¸å¯åŠ¨
- **å½±å“èŒƒå›´**: 
  - æ•´ä¸ªç³»ç»Ÿçš„åŠŸèƒ½å’Œè¡Œä¸º
  - LLMçš„é€‰æ‹©å’Œè°ƒç”¨å‚æ•°
  - å‘é‡æ•°æ®åº“çš„è¿æ¥å’Œå­˜å‚¨ä½ç½®
  - å·¥å…·çš„ä½¿ç”¨é™åˆ¶å’Œå‚æ•°
  - æƒ…ç»ªå’Œä¸ªæ€§çš„åˆå§‹çŠ¶æ€
  - ç³»ç»Ÿçš„æ—¥å¿—å’Œæ•°æ®å­˜å‚¨è·¯å¾„

#### app/core/global_store.py
```python
from dataclasses import dataclass, field
from typing import Dict, Any, Optional


@dataclass
class EmotionSnapshot:
    current_mood: str = "Calm"
    valence: float = 0.0
    arousal: float = 0.0
    timestamp: float = 0.0
    emotional_trigger: Optional[str] = None


@dataclass
class GlobalStore:
    """
    å…¨å±€çŠ¶æ€ç®¡ç†å™¨
    ç”¨äºå­˜å‚¨å’Œç®¡ç†ç³»ç»Ÿçš„å…¨å±€çŠ¶æ€ä¿¡æ¯
    """
    # æƒ…ç»ªå¿«ç…§
    _emotion_snapshot: EmotionSnapshot = field(default_factory=EmotionSnapshot)
    
    # å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯
    _context: Dict[str, Any] = field(default_factory=dict)
    
    def update_emotion(self, valence_delta: float = 0.0, arousal_delta: float = 0.0, stamina_delta: float = 0.0):
        """
        æ›´æ–°æƒ…ç»ªçŠ¶æ€
        """
        # å®ç°æƒ…ç»ªæ›´æ–°é€»è¾‘
        pass
    
    def get_emotion_snapshot(self) -> EmotionSnapshot:
        """
        è·å–å½“å‰æƒ…ç»ªå¿«ç…§
        """
        return self._emotion_snapshot
    
    def set_global_context(self, key: str, value: Any):
        """
        è®¾ç½®å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯
        """
        self._context[key] = value
    
    def get_global_context(self, key: str, default: Any = None) -> Any:
        """
        è·å–å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯
        """
        return self._context.get(key, default)


# å•ä¾‹å¯¼å‡º
global_store = GlobalStore()
```
- **åŠŸèƒ½**: é¡¹ç›®çš„å…¨å±€çŠ¶æ€ç®¡ç†æ¨¡å—ï¼Œè´Ÿè´£å­˜å‚¨å’Œç®¡ç†ç³»ç»Ÿçš„å…¨å±€çŠ¶æ€ä¿¡æ¯ï¼Œç‰¹åˆ«æ˜¯æƒ…ç»ªçŠ¶æ€
- **è®¾è®¡æ€è·¯**: 
  - ä½¿ç”¨å•ä¾‹æ¨¡å¼ï¼Œç¡®ä¿å…¨å±€çŠ¶æ€çš„ä¸€è‡´æ€§å’Œå¯è®¿é—®æ€§
  - ä½¿ç”¨æ•°æ®ç±»å®šä¹‰æƒ…ç»ªå¿«ç…§ï¼Œæé«˜ä»£ç çš„ç±»å‹å®‰å…¨æ€§å’Œå¯è¯»æ€§
  - æä¾›ç»Ÿä¸€çš„æ¥å£æ¥æ›´æ–°å’Œè·å–æƒ…ç»ªçŠ¶æ€
  - æ”¯æŒå…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯çš„å­˜å‚¨å’Œè·å–ï¼Œæ–¹ä¾¿æ¨¡å—é—´çš„ä¿¡æ¯å…±äº«
  - å°è£…å…¨å±€çŠ¶æ€çš„å®ç°ç»†èŠ‚ï¼Œæé«˜ä»£ç çš„å¯ç»´æŠ¤æ€§å’Œå¯æ‰©å±•æ€§
- **å½±å“èŒƒå›´**: 
  - ç³»ç»Ÿçš„æƒ…ç»ªçŠ¶æ€ç®¡ç†
  - æ¨¡å—é—´çš„ä¿¡æ¯å…±äº«å’Œé€šä¿¡
  - ç”¨æˆ·äº¤äº’çš„ä¸ªæ€§åŒ–å’Œæƒ…æ„ŸåŒ–
  - ä¸»åŠ¨ç¤¾äº¤è¡Œä¸ºçš„è§¦å‘å’Œæ§åˆ¶

#### app/core/database.py
```python
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, Session

# åˆ›å»ºæ•°æ®åº“å¼•æ“
engine = create_engine("sqlite:///./alicebot.db", connect_args={"check_same_thread": False})

# åˆ›å»ºä¼šè¯å·¥å‚
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# åˆ›å»ºåŸºç¡€æ¨¡å‹ç±»
Base = declarative_base()


class ForwardMessageModel(Base):
    """
    åˆå¹¶è½¬å‘æ¶ˆæ¯æ¨¡å‹
    ç”¨äºå­˜å‚¨åˆå¹¶è½¬å‘æ¶ˆæ¯çš„å†…å®¹å’Œå…ƒæ•°æ®
    """
    __tablename__ = "forward_messages"
    
    id = Column(Integer, primary_key=True, index=True)
    forward_id = Column(String, unique=True, index=True)
    full_content = Column(JSON)
    summary = Column(String)
    message_count = Column(Integer)
    image_count = Column(Integer)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)


# åˆ›å»ºæ•°æ®åº“è¡¨
Base.metadata.create_all(bind=engine)
```
- **åŠŸèƒ½**: é¡¹ç›®çš„æ•°æ®åº“ç®¡ç†æ¨¡å—ï¼Œè´Ÿè´£åˆ›å»ºæ•°æ®åº“å¼•æ“ã€ä¼šè¯å·¥å‚å’ŒåŸºç¡€æ¨¡å‹ç±»ï¼Œç‰¹åˆ«æ˜¯ç”¨äºå­˜å‚¨åˆå¹¶è½¬å‘æ¶ˆæ¯çš„æ¨¡å‹
- **è®¾è®¡æ€è·¯**: 
  - ä½¿ç”¨SQLAlchemy ORMæ¡†æ¶ï¼Œæé«˜æ•°æ®åº“æ“ä½œçš„å®‰å…¨æ€§å’Œå¯ç»´æŠ¤æ€§
  - ä½¿ç”¨SQLiteæ•°æ®åº“ï¼Œç®€åŒ–éƒ¨ç½²å’Œé…ç½®
  - å®šä¹‰æ˜ç¡®çš„æ•°æ®æ¨¡å‹ï¼Œç¡®ä¿æ•°æ®çš„ä¸€è‡´æ€§å’Œå®Œæ•´æ€§
  - æä¾›ä¼šè¯å·¥å‚ï¼Œæ–¹ä¾¿åœ¨å…¶ä»–æ¨¡å—ä¸­è·å–æ•°æ®åº“ä¼šè¯
  - è‡ªåŠ¨åˆ›å»ºæ•°æ®åº“è¡¨ï¼Œç®€åŒ–ç³»ç»Ÿåˆå§‹åŒ–è¿‡ç¨‹
- **å½±å“èŒƒå›´**: 
  - åˆå¹¶è½¬å‘æ¶ˆæ¯çš„å­˜å‚¨å’Œæ£€ç´¢
  - ç³»ç»Ÿçš„æŒä¹…åŒ–æ•°æ®ç®¡ç†
  - æ•°æ®åº“çš„æ€§èƒ½å’Œå­˜å‚¨ç©ºé—´ä½¿ç”¨
  - æ•°æ®çš„å®‰å…¨æ€§å’Œä¸€è‡´æ€§

### 3.10 å†…å­˜æ¨¡å— (Memory)

#### app/memory/__init__.py
```python
# ç©ºæ–‡ä»¶ï¼Œç”¨äºæ ‡è¯† memory ç›®å½•ä¸º Python åŒ…
```
- **åŠŸèƒ½**: æ ‡è¯† memory ç›®å½•ä¸º Python åŒ…ï¼Œæ–¹ä¾¿å¯¼å…¥
- **è®¾è®¡æ€è·¯**: æ¨¡å—åŒ–è®¾è®¡ï¼Œå°†å†…å­˜ç®¡ç†ç›¸å…³çš„ä»£ç é›†ä¸­ç®¡ç†
- **å½±å“èŒƒå›´**: æ— ç›´æ¥å½±å“ï¼Œä»…ä½œä¸ºåŒ…æ ‡è¯†

#### app/memory/combined_memory.py
```python
import json
import logging
from datetime import datetime
from typing import List, Dict, Any, Optional
from langchain_openai import ChatOpenAI
from langchain_community.memory.kg import ConversationKGMemory
from langchain_core.prompts import PromptTemplate
from langchain_core.messages import HumanMessage, AIMessage
from app.core.config import config
from app.memory.vector_store import vector_db
from app.memory.relation_db import relation_db
from app.memory.smart_retrieval import get_smart_memory_retriever

# é…ç½®æ—¥å¿—
logger = logging.getLogger("CombinedMemory")

class CombinedMemoryManager:
    """
    ç»„åˆå†…å­˜ç®¡ç†å™¨ï¼Œé›†æˆäº†ä¸‰ç§LangChainå†…å­˜æ–¹æ³•ï¼š
    1. ConversationEntityMemory - å®ä½“è®°å¿†
    2. ConversationKGMemory - çŸ¥è¯†å›¾è°±è®°å¿†
    3. VectorStoreRetrieverMemory - å‘é‡å­˜å‚¨æ£€ç´¢è®°å¿†
    """
    
    def __init__(self):
        # åˆå§‹åŒ–LLM - ChatOpenAIæœ¬èº«æ”¯æŒå¼‚æ­¥æ“ä½œ
        self.llm = ChatOpenAI(
            model=config.SMALL_MODEL,
            temperature=0.0,
            api_key=config.SMALL_MODEL_API_KEY,
            base_url=config.SMALL_MODEL_URL
        )
        
        # 1. è‡ªå®šä¹‰å®ä½“è®°å¿†å®ç°ï¼ˆæ›¿ä»£ConversationEntityMemoryï¼‰
        self.entity_store = {}
        self.entity_k = 5
        
        # 2. åˆå§‹åŒ–çŸ¥è¯†å›¾è°±è®°å¿†
        self.kg_memory = ConversationKGMemory(
            llm=self.llm,
            return_messages=True,
            k=10  # ä¿ç•™æœ€è¿‘10ä¸ªå…³ç³»
        )
    
    async def update_memory(self, user_input: str, ai_response: str, user_id: str, user_name: str):
        """
        æ›´æ–°æ‰€æœ‰è®°å¿†ç±»å‹
        """
        # æ›´æ–°å®ä½“è®°å¿†ï¼ˆç®€åŒ–å®ç°ï¼‰
        user_key = f"User {user_name}: {user_input}"
        self.entity_store[user_key] = ai_response
        
        # ä¿æŒå®ä½“è®°å¿†çš„å¤§å°é™åˆ¶
        if len(self.entity_store) > self.entity_k:
            # åˆ é™¤æœ€æ—§çš„æ¡ç›®
            first_key = next(iter(self.entity_store))
            del self.entity_store[first_key]
        
        # æ›´æ–°çŸ¥è¯†å›¾è°±è®°å¿†ï¼ˆå°†åŒæ­¥æ–¹æ³•åŒ…è£…åœ¨å¼‚æ­¥çº¿ç¨‹ä¸­æ‰§è¡Œï¼‰
        import asyncio
        await asyncio.to_thread(self.kg_memory.save_context, {
            "input": f"User {user_name}: {user_input}"
        }, {
            "output": ai_response
        })
        
        # æ›´æ–°å‘é‡å­˜å‚¨è®°å¿†ï¼ˆç›´æ¥ä½¿ç”¨vector_dbï¼‰
        memory_content = f"User {user_name}: {user_input}\nAI: {ai_response}"
        await vector_db.add_texts([memory_content], metadatas=[{"user_id": user_id}])
    
    async def get_relevant_memory(self, input_text: str, user_id: str) -> Dict[str, Any]:
        """
        è·å–æ‰€æœ‰ç›¸å…³è®°å¿†ï¼Œä¼˜åŒ–ç‰ˆæœ¬
        """
        # å®ç°ç›¸å…³è®°å¿†æ£€ç´¢é€»è¾‘
        pass
    
    async def get_relationship_insights(self, user_name: str, target_name: str) -> List[Dict[str, Any]]:
        """
        è·å–ä¸¤ä¸ªäººä¹‹é—´çš„å…³ç³»æ´å¯Ÿ
        """
        # å®ç°å…³ç³»æ´å¯Ÿè·å–é€»è¾‘
        pass
    
    async def clear_session(self):
        """
        æ¸…é™¤ä¼šè¯è®°å¿†ï¼ˆä¿ç•™é•¿æœŸè®°å¿†ï¼‰
        """
        # å®ç°ä¼šè¯è®°å¿†æ¸…é™¤é€»è¾‘
        pass
    
    async def smart_retrieve(self, query: str, chat_history: str, sender: str, user_id: str) -> Dict[str, Any]:
        """
        æ™ºèƒ½è®°å¿†æ£€ç´¢ï¼Œæ ¹æ®æŸ¥è¯¢å’ŒèŠå¤©å†å²è‡ªåŠ¨ç”Ÿæˆæ£€ç´¢é—®é¢˜å¹¶æ£€ç´¢ç›¸å…³è®°å¿†
        """
        # å®ç°æ™ºèƒ½è®°å¿†æ£€ç´¢é€»è¾‘
        pass


# åˆ›å»ºå…¨å±€å®ä¾‹
combined_memory = CombinedMemoryManager()
```
- **åŠŸèƒ½**: é¡¹ç›®çš„å†…å­˜ç®¡ç†æ ¸å¿ƒæ¨¡å—ï¼Œé›†æˆäº†ä¸‰ç§ä¸åŒç±»å‹çš„è®°å¿†ç®¡ç†æ–¹æ³•ï¼ˆå®ä½“è®°å¿†ã€çŸ¥è¯†å›¾è°±è®°å¿†ã€å‘é‡å­˜å‚¨æ£€ç´¢è®°å¿†ï¼‰ï¼Œæä¾›ç»Ÿä¸€çš„æ¥å£æ¥æ›´æ–°å’Œæ£€ç´¢è®°å¿†
- **è®¾è®¡æ€è·¯**: 
  - é‡‡ç”¨ç»„åˆè®¾è®¡æ¨¡å¼ï¼Œé›†æˆå¤šç§è®°å¿†ç®¡ç†æ–¹æ³•ï¼Œå……åˆ†åˆ©ç”¨æ¯ç§æ–¹æ³•çš„ä¼˜åŠ¿
  - ä½¿ç”¨å¼‚æ­¥ç¼–ç¨‹æ¨¡å‹ï¼Œæé«˜ç³»ç»Ÿçš„å¹¶å‘å¤„ç†èƒ½åŠ›
  - å°†åŒæ­¥æ–¹æ³•åŒ…è£…åœ¨å¼‚æ­¥çº¿ç¨‹ä¸­æ‰§è¡Œï¼Œè§£å†³å…¼å®¹æ€§é—®é¢˜
  - æä¾›ä¸°å¯Œçš„è®°å¿†ç®¡ç†åŠŸèƒ½ï¼ŒåŒ…æ‹¬è®°å¿†æ›´æ–°ã€æ£€ç´¢ã€å…³ç³»æ´å¯Ÿã€ä¼šè¯æ¸…é™¤ã€æ™ºèƒ½æ£€ç´¢ç­‰
  - ä½¿ç”¨å…¨å±€å®ä¾‹ï¼Œç¡®ä¿å†…å­˜ç®¡ç†çš„ä¸€è‡´æ€§å’Œå¯è®¿é—®æ€§
- **å½±å“èŒƒå›´**: 
  - å¯¹è¯å†å²çš„å­˜å‚¨å’Œæ£€ç´¢
  - ç”¨æˆ·ä¿¡æ¯å’Œåå¥½çš„è®°å¿†
  - çŸ¥è¯†å›¾è°±çš„æ„å»ºå’Œç»´æŠ¤
  - ç³»ç»Ÿçš„ä¸ªæ€§åŒ–å’Œæ™ºèƒ½åŒ–ç¨‹åº¦
  - å†…å­˜èµ„æºçš„ä½¿ç”¨å’Œæ€§èƒ½

#### app/memory/vector_store.py
```python
import asyncio
from typing import List, Dict, Any, Optional
import chromadb
from chromadb.config import Settings
from app.core.config import config


class VectorDB:
    """
    å‘é‡æ•°æ®åº“ç®¡ç†å™¨
    ç”¨äºå­˜å‚¨å’Œæ£€ç´¢æ–‡æœ¬çš„å‘é‡è¡¨ç¤º
    """
    
    def __init__(self):
        self.client = None
        self.collection = None
        self._initialize_db()
    
    def _initialize_db(self):
        """
        åˆå§‹åŒ–å‘é‡æ•°æ®åº“
        """
        # å®ç°å‘é‡æ•°æ®åº“åˆå§‹åŒ–é€»è¾‘
        pass
    
    async def add_texts(self, texts: List[str], metadatas: Optional[List[Dict[str, Any]]] = None) -> List[str]:
        """
        æ·»åŠ æ–‡æœ¬åˆ°å‘é‡æ•°æ®åº“
        """
        # å®ç°æ–‡æœ¬æ·»åŠ é€»è¾‘
        pass
    
    async def search(self, query: str, k: int = 5, filter: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
        """
        æœç´¢ç›¸å…³æ–‡æœ¬
        """
        # å®ç°æ–‡æœ¬æœç´¢é€»è¾‘
        pass


# åˆ›å»ºå…¨å±€å‘é‡æ•°æ®åº“å®ä¾‹
vector_db = VectorDB()
```
- **åŠŸèƒ½**: é¡¹ç›®çš„å‘é‡æ•°æ®åº“ç®¡ç†æ¨¡å—ï¼Œè´Ÿè´£æ–‡æœ¬çš„å‘é‡è¡¨ç¤ºå­˜å‚¨å’Œæ£€ç´¢
- **è®¾è®¡æ€è·¯**: 
  - ä½¿ç”¨ChromaDBä½œä¸ºå‘é‡æ•°æ®åº“ï¼Œæä¾›é«˜æ•ˆçš„å‘é‡å­˜å‚¨å’Œæ£€ç´¢åŠŸèƒ½
  - å°è£…å‘é‡æ•°æ®åº“çš„æ“ä½œï¼Œæä¾›ç®€æ´çš„APIæ¥å£
  - æ”¯æŒå…ƒæ•°æ®è¿‡æ»¤ï¼Œæé«˜æ£€ç´¢çš„å‡†ç¡®æ€§
  - ä½¿ç”¨å…¨å±€å®ä¾‹ï¼Œç¡®ä¿å‘é‡æ•°æ®åº“çš„ä¸€è‡´æ€§å’Œå¯è®¿é—®æ€§
- **å½±å“èŒƒå›´**: 
  - è®°å¿†çš„å­˜å‚¨å’Œæ£€ç´¢æ€§èƒ½
  - æ–‡æœ¬ç›¸ä¼¼åº¦åŒ¹é…çš„å‡†ç¡®æ€§
  - ç³»ç»Ÿçš„å“åº”é€Ÿåº¦
  - å­˜å‚¨ç©ºé—´çš„ä½¿ç”¨

#### app/memory/relation_db.py
```python
import json
import logging
from typing import Dict, Any, Optional
from dataclasses import dataclass, field

logger = logging.getLogger("RelationDB")


@dataclass
class UserProfile:
    """
    ç”¨æˆ·ä¸ªäººèµ„æ–™æ•°æ®ç±»
    """
    user_qq: str
    current_name: str
    known_names: list = field(default_factory=list)
    nicknames: list = field(default_factory=list)
    avatar_url: Optional[str] = None
    gender: Optional[str] = None
    age: Optional[int] = None
    
    def model_dump(self) -> dict:
        """
        è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        """
        return {
            "user_qq": self.user_qq,
            "current_name": self.current_name,
            "known_names": self.known_names,
            "nicknames": self.nicknames,
            "avatar_url": self.avatar_url,
            "gender": self.gender,
            "age": self.age
        }


class RelationDatabase:
    """
    å…³ç³»å‹æ•°æ®åº“ç®¡ç†å™¨
    ç”¨äºå­˜å‚¨å’Œç®¡ç†ç”¨æˆ·å…³ç³»æ•°æ®
    """
    
    def __init__(self):
        self.user_profiles: Dict[str, UserProfile] = {}
    
    def get_user_profile(self, user_qq: str, current_name: str = None) -> UserProfile:
        """
        è·å–ç”¨æˆ·ä¸ªäººèµ„æ–™
        """
        # å®ç°ç”¨æˆ·ä¸ªäººèµ„æ–™è·å–é€»è¾‘
        pass
    
    def update_user_profile(self, user_profile: UserProfile):
        """
        æ›´æ–°ç”¨æˆ·ä¸ªäººèµ„æ–™
        """
        # å®ç°ç”¨æˆ·ä¸ªäººèµ„æ–™æ›´æ–°é€»è¾‘
        pass


# åˆ›å»ºå…¨å±€å…³ç³»æ•°æ®åº“å®ä¾‹
relation_db = RelationDatabase()
```
- **åŠŸèƒ½**: é¡¹ç›®çš„å…³ç³»å‹æ•°æ®åº“ç®¡ç†æ¨¡å—ï¼Œè´Ÿè´£å­˜å‚¨å’Œç®¡ç†ç”¨æˆ·å…³ç³»æ•°æ®
- **è®¾è®¡æ€è·¯**: 
  - ä½¿ç”¨æ•°æ®ç±»å®šä¹‰ç”¨æˆ·ä¸ªäººèµ„æ–™ï¼Œæé«˜ä»£ç çš„ç±»å‹å®‰å…¨æ€§å’Œå¯è¯»æ€§
  - å°è£…å…³ç³»æ•°æ®åº“çš„æ“ä½œï¼Œæä¾›ç®€æ´çš„APIæ¥å£
  - æ”¯æŒç”¨æˆ·ä¸ªäººèµ„æ–™çš„è·å–å’Œæ›´æ–°
  - ä½¿ç”¨å…¨å±€å®ä¾‹ï¼Œç¡®ä¿å…³ç³»æ•°æ®åº“çš„ä¸€è‡´æ€§å’Œå¯è®¿é—®æ€§
- **å½±å“èŒƒå›´**: 
  - ç”¨æˆ·ä¸ªäººèµ„æ–™çš„å­˜å‚¨å’Œç®¡ç†
  - ç”¨æˆ·å…³ç³»çš„è·Ÿè¸ªå’Œç»´æŠ¤
  - ä¸ªæ€§åŒ–äº¤äº’çš„å®ç°
  - ç³»ç»Ÿçš„ç”¨æˆ·ä½“éªŒ

#### app/memory/local_history.py
```python
import os
import json
import aiofiles
import logging
from datetime import datetime
from typing import List, Tuple, Dict, Any
from langchain_core.messages import BaseMessage, messages_to_dict, messages_from_dict
from pathlib import Path

# é…ç½®æ—¥å¿—
logger = logging.getLogger("LocalHistory")

# å®šä¹‰å­˜å‚¨è·¯å¾„ï¼ˆç”¨äºJSONæ–‡ä»¶å­˜å‚¨ï¼‰
import os
# è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•çš„çˆ¶ç›®å½•
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
HISTORY_DIR = os.path.join(BASE_DIR, "data", "history")


class LocalHistoryManager:
    """
    è´Ÿè´£ä¼šè¯å†å²å­˜å‚¨ï¼Œä½¿ç”¨JSONæ–‡ä»¶ã€‚
    æ ¹æ® session_id è¿›è¡Œæ•°æ®éš”ç¦»ã€‚
    """

    @classmethod
    async def save_state(cls, messages: List[BaseMessage], summary: str, session_id: str):
        """
        å¼‚æ­¥ä¿å­˜å½“å‰å¯¹è¯çŠ¶æ€åˆ°JSONæ–‡ä»¶ã€‚
        :param messages: LangChain æ¶ˆæ¯åˆ—è¡¨
        :param summary: å½“å‰çš„å¯¹è¯æ€»ç»“
        :param session_id: ä¼šè¯å”¯ä¸€æ ‡è¯† (private_xxx æˆ– group_xxx)
        """
        if not session_id:
            logger.warning("âš ï¸ [History] Cannot save: session_id is missing.")
            return

        # ç¡®ä¿å­˜å‚¨ç›®å½•å­˜åœ¨
        os.makedirs(HISTORY_DIR, exist_ok=True)
        
        # å®‰å…¨å¤„ç†æ–‡ä»¶å
        safe_id = "".join([c for c in session_id if c.isalnum() or c in ('_', '-')])
        file_path = os.path.join(HISTORY_DIR, f"{safe_id}.json")
        
        # å‡†å¤‡è¦ä¿å­˜çš„æ•°æ®
        data = {
            "session_id": session_id,
            "summary": summary,
            "messages": messages_to_dict(messages),
            "updated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }

        try:
            async with aiofiles.open(file_path, mode='w', encoding='utf-8') as f:
                await f.write(json.dumps(data, ensure_ascii=False, indent=2))
        except Exception as e:
            logger.error(f"âŒ [History] Save failed for {session_id}: {e}")

    @classmethod
    async def load_state(cls, session_id: str) -> Tuple[List[BaseMessage], str]:
        """
        å¼‚æ­¥è¯»å–ä¼šè¯çŠ¶æ€ã€‚
        :param session_id: ä¼šè¯å”¯ä¸€æ ‡è¯†
        :return: (messages, summary)
        """
        if not session_id:
            return [], ""

        try:
            # å®‰å…¨å¤„ç†æ–‡ä»¶å
            safe_id = "".join([c for c in session_id if c.isalnum() or c in ('_', '-')])
            file_path = os.path.join(HISTORY_DIR, f"{safe_id}.json")
            
            if not os.path.exists(file_path):
                return [], ""
            
            async with aiofiles.open(file_path, mode='r', encoding='utf-8') as f:
                content = await f.read()
                if not content:
                    return [], ""
                
                data = json.loads(content)
                summary = data.get("summary", "")
                msgs_dict = data.get("messages", [])
                
                # ååºåˆ—åŒ–æ¶ˆæ¯
                messages = messages_from_dict(msgs_dict)
                return messages, summary

        except Exception as e:
            logger.error(f"âŒ [History] Load failed for {session_id}: {e}")
            return [], ""

    @classmethod
    def get_existing_summary_sync(cls, session_id: str) -> str:
        """
        åŒæ­¥è¾…åŠ©æ–¹æ³•ï¼šä»…è·å– Summary (ç”¨äºåˆå§‹åŒ–æ—¶å¿«é€Ÿè¯»å–)
        """
        if not session_id: return ""

        try:
            # å®‰å…¨å¤„ç†æ–‡ä»¶å
            safe_id = "".join([c for c in session_id if c.isalnum() or c in ('_', '-')])
            file_path = os.path.join(HISTORY_DIR, f"{safe_id}.json")
            
            if not os.path.exists(file_path):
                return ""
            
            with open(file_path, mode='r', encoding='utf-8') as f:
                content = f.read()
                if not content:
                    return ""
                
                data = json.loads(content)
                return data.get("summary", "")
        except Exception as e:
            logger.error(f"âŒ [History] Get summary failed for {session_id}: {e}")
            return ""
    
    @classmethod
    async def _migrate_from_json(cls, session_id: str):
        """
        æ£€æŸ¥JSONæ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆå‘åå…¼å®¹æ—§ä»£ç è°ƒç”¨ï¼‰
        """
        if not os.path.exists(HISTORY_DIR):
            return
        
        # è·å–æ–‡ä»¶è·¯å¾„
        safe_id = "".join([c for c in session_id if c.isalnum() or c in ('_', '-')])
        file_path = os.path.join(HISTORY_DIR, f"{safe_id}.json")
        
        if not os.path.exists(file_path):
            return
        
        logger.info(f"âœ… [History] JSON file found for {session_id}")
```
- **åŠŸèƒ½**: è´Ÿè´£ä¼šè¯å†å²çš„æŒä¹…åŒ–å­˜å‚¨å’ŒåŠ è½½ï¼Œä½¿ç”¨JSONæ–‡ä»¶æ ¹æ®session_idè¿›è¡Œæ•°æ®éš”ç¦»
- **è®¾è®¡æ€è·¯**: 
  - ä½¿ç”¨å¼‚æ­¥IOæ“ä½œæå‡æ€§èƒ½ï¼Œé¿å…é˜»å¡ä¸»çº¿ç¨‹
  - å®‰å…¨å¤„ç†æ–‡ä»¶åï¼Œé˜²æ­¢è·¯å¾„æ³¨å…¥æ”»å‡»
  - è‡ªåŠ¨åˆ›å»ºå­˜å‚¨ç›®å½•ï¼Œç¡®ä¿æ•°æ®å­˜å‚¨çš„å¯é æ€§
  - æä¾›åŒæ­¥å’Œå¼‚æ­¥ä¸¤ç§æ¥å£ï¼Œæ»¡è¶³ä¸åŒåœºæ™¯çš„éœ€æ±‚
  - æ”¯æŒå‘åå…¼å®¹ï¼Œç¡®ä¿ç³»ç»Ÿçš„ç¨³å®šæ€§
- **å½±å“èŒƒå›´**: 
  - ä¼šè¯å†å²çš„æŒä¹…åŒ–å­˜å‚¨å’Œæ¢å¤
  - å¯¹è¯ä¸Šä¸‹æ–‡çš„ç»´æŠ¤
  - ç³»ç»Ÿçš„æ€§èƒ½å’Œå¯é æ€§
  - ç”¨æˆ·ä½“éªŒçš„è¿è´¯æ€§

#### app/memory/relation_db.py
```python
# æ ¸å¿ƒç±»å®šä¹‰
class Relationship(BaseModel):
    target_id: str
    relation_type: str = "acquaintance"
    intimacy: int = Field(default=60, ge=0, le=100)  # å¥½æ„Ÿåº¦
    familiarity: int = Field(default=50, ge=0, le=100)  # ç†Ÿæ‚‰åº¦
    trust: int = Field(default=50, ge=0, le=100)  # ä¿¡ä»»åº¦
    interest_match: int = Field(default=50, ge=0, le=100)  # å…´è¶£åŒ¹é…åº¦
    tags: List[str] = Field(default_factory=list)
    notes: str = ""
    nickname_for_user: str = ""
    memory_points: List[str] = Field(default_factory=list)  # è®°å¿†ç‚¹åˆ—è¡¨
    expression_habits: List[str] = Field(default_factory=list)  # è¡¨è¾¾ä¹ æƒ¯åˆ—è¡¨
    group_nicknames: List[Dict[str, str]] = Field(default_factory=list)  # ç¾¤æ˜µç§°åˆ—è¡¨
    last_interaction_time: float = Field(default_factory=time.time)  # æœ€åä¸€æ¬¡äº¤äº’æ—¶é—´
    stamina: float = Field(default=80.0)  # ä½“åŠ›å€¼
    
    # æ–°å¢å­—æ®µ
    communication_style: str = "casual"  # æ²Ÿé€šé£æ ¼: casual, formal, playful
    favorite_topics: List[str] = Field(default_factory=list)  # æ„Ÿå…´è¶£çš„è¯é¢˜
    avoid_topics: List[str] = Field(default_factory=list)  # é¿å…çš„è¯é¢˜
    interaction_patterns: Dict[str, Any] = Field(default_factory=dict)  # äº¤äº’æ¨¡å¼
    sentiment_trends: List[Dict[str, Any]] = Field(default_factory=list)  # æƒ…æ„Ÿå˜åŒ–è¶‹åŠ¿

# æ•°æ®åº“æ¨¡å‹
class UserProfileModel(Base):
    __tablename__ = "user_profiles"
    
    qq_id = Column(String(50), primary_key=True, index=True)
    name = Column(String(255), nullable=False)
    relationship_data = Column(JSON, nullable=False)  # å­˜å‚¨Relationshipå¯¹è±¡çš„JSONæ•°æ®
    updated_at = Column(String(50), default=lambda: str(time.time()))

# æ ¸å¿ƒå…³ç³»ç®¡ç†ç±»
class GlobalRelationDB:
    def __init__(self):
        # åˆå§‹åŒ–æ•°æ®åº“
        init_db()
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ä»JSONè¿ç§»æ•°æ®
        self._migrate_from_json()
        
        # æ ‡è®°æ¸…ç†ä»»åŠ¡æœªå¯åŠ¨
        self._cleanup_task_started = False

    async def get_user_profile(self, user_qq: str, current_name: str = None) -> UserProfile:
        from app.utils.cache import cached_user_info_get, cached_user_info_set
        
        user_qq = str(user_qq)
        
        # å…ˆæ£€æŸ¥ç¼“å­˜
        cached_profile = await cached_user_info_get(user_qq)
        if cached_profile:
            # æ£€æŸ¥cached_profileæ˜¯å¦ä¸ºå­—å…¸ï¼Œå¦‚æœæ˜¯åˆ™è½¬æ¢ä¸ºUserProfileå¯¹è±¡
            if isinstance(cached_profile, dict):
                # ä»å­—å…¸é‡å»ºUserProfileå¯¹è±¡
                try:
                    # å…ˆæå–relationshipæ•°æ®
                    relationship_data = cached_profile.get("relationship", {})
                    if isinstance(relationship_data, dict) and "target_id" not in relationship_data:
                        relationship_data["target_id"] = user_qq
                    
                    cached_profile = UserProfile(
                        name=cached_profile.get("name", f"User_{user_qq}"),
                        qq_id=cached_profile.get("qq_id", user_qq),
                        relationship=Relationship(**relationship_data)
                    )
                except Exception as e:
                    logger.error(f"[RelationDB] ä»å­—å…¸è½¬æ¢UserProfileå¤±è´¥: {str(e)}")
                    # è½¬æ¢å¤±è´¥æ—¶ï¼Œæ¸…é™¤ç¼“å­˜å¹¶é‡æ–°è·å–
                    await cached_user_info_set(user_qq, None)
                    cached_profile = None
            
            if cached_profile:
                # å¦‚æœç”¨æˆ·åæœ‰æ›´æ–°ï¼Œéœ€è¦åŒæ­¥åˆ°æ•°æ®åº“å’Œç¼“å­˜
                if current_name and cached_profile.name != current_name:
                    cached_profile.name = current_name
                db = SessionLocal()
                try:
                    db_profile = db.query(UserProfileModel).filter(UserProfileModel.qq_id == user_qq).first()
                    if db_profile:
                        # åªæœ‰å½“current_nameä¸ä¸ºNoneä¸”ä¸ä¸ºç©ºå­—ç¬¦ä¸²æ—¶æ‰æ›´æ–°ç”¨æˆ·å
                        if current_name is not None and current_name.strip():
                            db_profile.name = current_name
                            db_profile.updated_at = str(time.time())
                            db.commit()
                            await cached_user_info_set(user_qq, cached_profile)
                except SQLAlchemyError as e:
                    db.rollback()
                    logger.error(f"[RelationDB] æ›´æ–°ç”¨æˆ·åå¤±è´¥: {str(e)}")
                finally:
                    db.close()
            return cached_profile
        
        db = SessionLocal()
        
        try:
            # æŸ¥è¯¢ç”¨æˆ·
            db_profile = db.query(UserProfileModel).filter(UserProfileModel.qq_id == user_qq).first()
            
            if db_profile:
                # ä»æ•°æ®åº“è®°å½•æ„å»ºUserProfileå¯¹è±¡
                relationship_data = db_profile.relationship_data
                if not relationship_data:
                    relationship_data = {"target_id": user_qq}
                
                profile = UserProfile(
                    name=db_profile.name,
                    qq_id=db_profile.qq_id,
                    relationship=Relationship(**relationship_data)
                )
                
                # æ›´æ–°ç”¨æˆ·å
                if current_name is not None and current_name.strip() and profile.name != current_name:
                    db_profile.name = current_name
                    db_profile.updated_at = str(time.time())
                    db.commit()
                    profile.name = current_name
                
                # å­˜å…¥ç¼“å­˜
                await cached_user_info_set(user_qq, profile)
                return profile
            else:
                # åˆ›å»ºæ–°ç”¨æˆ·
                display_name = current_name if current_name else f"User_{user_qq}"
                relationship = Relationship(target_id=user_qq)
                
                new_db_profile = UserProfileModel(
                    qq_id=user_qq,
                    name=display_name,
                    relationship_data=relationship.model_dump()
                )
                
                db.add(new_db_profile)
                db.commit()
                
                profile = UserProfile(
                    name=display_name,
                    qq_id=user_qq,
                    relationship=relationship
                )
                
                # å­˜å…¥ç¼“å­˜
                await cached_user_info_set(user_qq, profile)
                return profile
                
        except SQLAlchemyError as e:
            db.rollback()
            logger.error(f"[RelationDB] è·å–ç”¨æˆ·èµ„æ–™å¤±è´¥: {str(e)}")
            # å‡ºé”™æ—¶è¿”å›é»˜è®¤å€¼
            display_name = current_name if current_name else f"User_{user_qq}"
            profile = UserProfile(
                name=display_name,
                qq_id=user_qq,
                relationship=Relationship(target_id=user_qq)
            )
            # å­˜å…¥ç¼“å­˜
            await cached_user_info_set(user_qq, profile)
            return profile
        finally:
            db.close()

    def update_relationship_dimensions(self, user_qq: str, deltas: Dict[str, int]):
        """
        æ›´æ–°å…³ç³»çš„å¤šä¸ªç»´åº¦ï¼ˆå¥½æ„Ÿåº¦ã€ç†Ÿæ‚‰åº¦ã€ä¿¡ä»»åº¦ã€å…´è¶£åŒ¹é…ç­‰ï¼‰
        """
        user_qq = str(user_qq)
        db = SessionLocal()
        
        try:
            profile = db.query(UserProfileModel).filter(UserProfileModel.qq_id == user_qq).first()
            
            if profile:
                relationship_data = profile.relationship_data
                if not relationship_data:
                    relationship_data = {
                        "target_id": user_qq,
                        "intimacy": 60,
                        "familiarity": 50,
                        "trust": 50,
                        "interest_match": 50
                    }
                
                # åˆ›å»ºä¸€ä¸ªå…¨æ–°çš„å­—å…¸æ¥ç¡®ä¿SQLAlchemyæ£€æµ‹åˆ°å˜åŒ–
                updated_relationship_data = dict(relationship_data)
                
                # ç¡®ä¿æ‰€æœ‰ç»´åº¦éƒ½æœ‰é»˜è®¤å€¼
                for dimension in ["intimacy", "familiarity", "trust", "interest_match"]:
                    if dimension not in updated_relationship_data:
                        if dimension == "intimacy":
                            updated_relationship_data[dimension] = 60
                        else:
                            updated_relationship_data[dimension] = 50
                
                # æ›´æ–°å„ä¸ªç»´åº¦
                updated_dimensions = {}
                for dimension, delta in deltas.items():
                    if dimension in ["intimacy", "familiarity", "trust", "interest_match"]:
                        current_value = updated_relationship_data.get(dimension, 50)
                        new_value = max(0, min(100, current_value + delta))
                        updated_relationship_data[dimension] = new_value
                        updated_dimensions[dimension] = new_value
                
                # æ›´æ–°å…³ç³»æ•°æ®ï¼ˆä½¿ç”¨å…¨æ–°å­—å…¸ç¡®ä¿SQLAlchemyæ£€æµ‹åˆ°å˜åŒ–ï¼‰
                profile.relationship_data = updated_relationship_data
                profile.updated_at = str(time.time())
                
                # æäº¤æ›´æ”¹
                db.commit()
                
                # æ›´æ–°åæ¸…é™¤ç¼“å­˜
                import asyncio
                from app.utils.cache import cached_user_info_set
                asyncio.create_task(cached_user_info_set(user_qq, None))
                
                return updated_dimensions
            else:
                # ç”¨æˆ·ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°ç”¨æˆ·
                relationship_data = {
                    "target_id": user_qq,
                    "intimacy": 60,
                    "familiarity": 50,
                    "trust": 50,
                    "interest_match": 50
                }
                
                # åº”ç”¨å˜åŒ–å€¼
                updated_dimensions = {}
                for dimension, delta in deltas.items():
                    if dimension in ["intimacy", "familiarity", "trust", "interest_match"]:
                        new_value = max(0, min(100, relationship_data[dimension] + delta))
                        relationship_data[dimension] = new_value
                        updated_dimensions[dimension] = new_value
                
                new_profile = UserProfileModel(
                    qq_id=user_qq,
                    name=f"User_{user_qq}",
                    relationship_data=relationship_data
                )
                
                db.add(new_profile)
                db.commit()
                
                return updated_dimensions
                
        except SQLAlchemyError as e:
            db.rollback()
            logger.error(f"[RelationDB] æ›´æ–°å…³ç³»ç»´åº¦å¤±è´¥: {str(e)}")
            return {}
        finally:
            db.close()
```
- **åŠŸèƒ½**: è´Ÿè´£ç”¨æˆ·å…³ç³»æ•°æ®çš„æŒä¹…åŒ–å­˜å‚¨å’Œç®¡ç†ï¼ŒåŒ…æ‹¬å¤šç»´åº¦çš„å…³ç³»æ•°æ®ï¼ˆå¥½æ„Ÿåº¦ã€ç†Ÿæ‚‰åº¦ã€ä¿¡ä»»åº¦ç­‰ï¼‰ã€ç”¨æˆ·è®°å¿†ç‚¹å’Œè¡¨è¾¾ä¹ æƒ¯çš„ç®¡ç†
- **è®¾è®¡æ€è·¯**: 
  - ä½¿ç”¨Pydanticæ¨¡å‹å®šä¹‰å…³ç³»æ•°æ®ç»“æ„ï¼Œç¡®ä¿æ•°æ®å®Œæ•´æ€§å’Œç±»å‹å®‰å…¨
  - é‡‡ç”¨SQLAlchemyä½œä¸ºORMæ¡†æ¶ï¼Œæ”¯æŒå¤šç§æ•°æ®åº“åç«¯
  - é›†æˆç¼“å­˜ç³»ç»Ÿï¼ˆapp/utils/cacheï¼‰æé«˜æ€§èƒ½ï¼Œå‡å°‘æ•°æ®åº“æŸ¥è¯¢
  - æ”¯æŒæ•°æ®è¿ç§»åŠŸèƒ½ï¼Œå®ç°ä»æ—§JSONæ ¼å¼åˆ°æ•°æ®åº“çš„å¹³æ»‘è¿‡æ¸¡
  - è®¾è®¡å¤šç»´åº¦çš„å…³ç³»æ•°æ®æ¨¡å‹ï¼Œæ”¯æŒæƒ…æ„ŸåŒ–äº¤äº’
  - æä¾›ä¸°å¯Œçš„APIæ¥å£ï¼Œæ”¯æŒå…³ç³»æ•°æ®çš„å¢åˆ æ”¹æŸ¥å’Œç»´åº¦æ›´æ–°
- **å½±å“èŒƒå›´**: 
  - ç”¨æˆ·å…³ç³»æ•°æ®çš„æŒä¹…åŒ–å­˜å‚¨å’Œæ¢å¤
  - æƒ…æ„ŸåŒ–äº¤äº’ç³»ç»Ÿçš„æ ¸å¿ƒæ•°æ®æ”¯æ’‘
  - ä¸ªæ€§åŒ–å›å¤ç”Ÿæˆçš„åŸºç¡€
  - å¤šç»´åº¦å…³ç³»æ•°æ®çš„åˆ†æå’Œåº”ç”¨
  - ç³»ç»Ÿæ€§èƒ½å’Œæ•°æ®ä¸€è‡´æ€§çš„ç»´æŠ¤

### 3.11 å›¾æ¨¡å— (Graph)

#### app/graph/__init__.py
```python
# ç©ºæ–‡ä»¶ï¼Œç”¨äºæ ‡è¯† graph ç›®å½•ä¸º Python åŒ…
```
- **åŠŸèƒ½**: æ ‡è¯† graph ç›®å½•ä¸º Python åŒ…ï¼Œæ–¹ä¾¿å¯¼å…¥
- **è®¾è®¡æ€è·¯**: æ¨¡å—åŒ–è®¾è®¡ï¼Œå°†å›¾ç›¸å…³çš„ä»£ç é›†ä¸­ç®¡ç†
- **å½±å“èŒƒå›´**: æ— ç›´æ¥å½±å“ï¼Œä»…ä½œä¸ºåŒ…æ ‡è¯†

#### app/graph/graph_builder.py
```python
"""
èŠå¤©æœºå™¨äººå·¥ä½œæµç¨‹å›¾æ„å»ºæ¨¡å—

è¯¥æ¨¡å—ä½¿ç”¨ LangGraph æ„å»º ProjectAlice èŠå¤©æœºå™¨äººçš„å®Œæ•´å·¥ä½œæµç¨‹ï¼Œ
åŒ…æ‹¬å“åº”å¼å›å¤å’Œä¸»åŠ¨å‘èµ·å¯¹è¯ä¸¤ç§æ¨¡å¼ï¼Œä»¥åŠå„èŠ‚ç‚¹ä¹‹é—´çš„è·¯ç”±é€»è¾‘ã€‚
"""
from langgraph.graph import StateGraph, END
from app.core.state import AgentState

# èŠ‚ç‚¹å¼•å…¥
from app.graph.nodes.context_filter import context_filter_node
from app.graph.nodes.parallel_processor import parallel_processing_node
from app.graph.nodes.unified_agent import agent_node
from app.graph.nodes.tool_handler import tool_node
from app.graph.nodes.memory_saver import memory_saver_node
from app.graph.nodes.summarizer import summarizer_node
from app.graph.nodes.proactive_agent import proactive_node
from app.graph.nodes.perception import perception_node


def route_agent_output(state: AgentState) -> str:
    """
    è·¯ç”±æ™ºèƒ½ä½“è¾“å‡ºåˆ°å·¥å…·å¤„ç†æˆ–è®°å¿†ä¿å­˜
    
    Args:
        state: å½“å‰æ™ºèƒ½ä½“çŠ¶æ€
    
    Returns:
        str: ä¸‹ä¸€ä¸ªèŠ‚ç‚¹çš„åç§°
    """
    step = state.get("next_step", "save")
    if step == "tool":
        return "tools"
    return "saver"


def route_root(state: AgentState) -> str:
    """
    æ ¹è·¯ç”±ï¼šæ ¹æ®æ¨¡å¼é€‰æ‹©è¿›å…¥å“åº”å¼æˆ–ä¸»åŠ¨å¼æµç¨‹
    
    Args:
        state: å½“å‰æ™ºèƒ½ä½“çŠ¶æ€
    
    Returns:
        str: ä¸‹ä¸€ä¸ªèŠ‚ç‚¹çš„åç§°
    """
    if state.get("is_proactive_mode", False):
        return "proactive"
    return "filter"


def route_filter(state: AgentState) -> str:
    """
    ä¸Šä¸‹æ–‡è¿‡æ»¤å™¨è·¯ç”±ï¼šæ ¹æ®æ˜¯å¦éœ€è¦å›å¤é€‰æ‹©æµç¨‹åˆ†æ”¯
    
    Args:
        state: å½“å‰æ™ºèƒ½ä½“çŠ¶æ€
    
    Returns:
        str: ä¸‹ä¸€ä¸ªèŠ‚ç‚¹çš„åç§°
    """
    if not state.get("should_reply", False):
        # ä¸éœ€è¦å›å¤æ—¶ï¼Œç›´æ¥ä¿å­˜è®°å¿†å¹¶ç»“æŸ
        return "summarizer"
    
    # å¦‚æœæœ‰çŸ­è·¯å›å¤å­—æ®µï¼Œç›´æ¥ä¼ é€’åˆ°agent_nodeï¼Œé¿å…å¤æ‚çš„æ„ŸçŸ¥å’Œæ¨ç†
    if "short_circuit_emoji" in state or "short_circuit_text" in state:
        return "agent"
    
    # éœ€è¦å›å¤ä¸”æ²¡æœ‰çŸ­è·¯å­—æ®µæ—¶ï¼Œè¿›è¡Œå¤æ‚çš„æ„ŸçŸ¥å’Œæ¨ç†
    return "parallel_processor"


def build_graph():
    """
    æ„å»ºå®Œæ•´çš„èŠå¤©æœºå™¨äººå·¥ä»¶æµç¨‹å›¾
    
    èŠ‚ç‚¹è¯´æ˜ï¼š
    - filter: ä¸Šä¸‹æ–‡è¿‡æ»¤å™¨ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦å›å¤
    - parallel_processor: å¹¶è¡Œå¤„ç†å™¨ï¼ŒåŒæ—¶è¿›è¡Œè§†è§‰æ„ŸçŸ¥å’Œå¿ƒç†åˆ†æ
    - agent: ç»Ÿä¸€æ™ºèƒ½ä½“ï¼Œç”Ÿæˆå›å¤å†…å®¹
    - tools: å·¥å…·å¤„ç†èŠ‚ç‚¹ï¼Œæ‰§è¡Œéœ€è¦çš„å·¥å…·è°ƒç”¨
    - saver: é•¿æœŸè®°å¿†ä¿å­˜èŠ‚ç‚¹
    - summarizer: çŸ­æœŸè®°å¿†æ€»ç»“å’Œæ–‡ä»¶IOèŠ‚ç‚¹
    - perception: è§†è§‰æ„ŸçŸ¥èŠ‚ç‚¹ï¼Œåˆ†æå›¾ç‰‡å†…å®¹
    - proactive: ä¸»åŠ¨ç¤¾äº¤å¼•æ“èŠ‚ç‚¹ï¼Œå†³å®šæ˜¯å¦ä¸»åŠ¨å‘èµ·å¯¹è¯
    
    Returns:
        StateGraph: ç¼–è¯‘åçš„å·¥ä½œæµç¨‹å›¾
    """
    workflow = StateGraph(AgentState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("filter", context_filter_node)            # ä¸Šä¸‹æ–‡è¿‡æ»¤å™¨
    workflow.add_node("parallel_processor", parallel_processing_node)  # å¹¶è¡Œå¤„ç†å™¨
    workflow.add_node("agent", agent_node)                    # ç»Ÿä¸€æ™ºèƒ½ä½“
    workflow.add_node("tools", tool_node)                    # å·¥å…·å¤„ç†
    workflow.add_node("saver", memory_saver_node)              # é•¿æœŸè®°å¿†ä¿å­˜
    workflow.add_node("summarizer", summarizer_node)            # çŸ­æœŸè®°å¿†æ€»ç»“
    workflow.add_node("perception", perception_node)            # è§†è§‰æ„ŸçŸ¥
    workflow.add_node("proactive", proactive_node)              # ä¸»åŠ¨ç¤¾äº¤å¼•æ“

    # å…¥å£è·¯ç”±ï¼šæ ¹æ®æ¨¡å¼é€‰æ‹©æµç¨‹
    workflow.set_conditional_entry_point(
        route_root,
        {
            "filter": "filter",    # å“åº”å¼æ¨¡å¼ï¼šå…ˆç»è¿‡ä¸Šä¸‹æ–‡è¿‡æ»¤å™¨
            "proactive": "proactive"  # ä¸»åŠ¨å¼æ¨¡å¼ï¼šç›´æ¥è¿›å…¥ä¸»åŠ¨ç¤¾äº¤å¼•æ“
        }
    )

    # ä¸Šä¸‹æ–‡è¿‡æ»¤å™¨è·¯ç”±ï¼šå†³å®šæ˜¯å¦éœ€è¦å¤æ‚å¤„ç†
    workflow.add_conditional_edges(
        "filter",
        route_filter,
        {
            "parallel_processor": "parallel_processor",  # éœ€è¦å›å¤ï¼šè¿›è¡Œå¹¶è¡Œå¤„ç†
            "summarizer": "summarizer",                # ä¸éœ€è¦å›å¤ï¼šç›´æ¥ä¿å­˜è®°å¿†
            "agent": "agent"                        # çŸ­è·¯å›å¤ï¼šç›´æ¥ä¼ é€’åˆ°æ™ºèƒ½ä½“
        }
    )

    # å“åº”å¼æµç¨‹ä¸»çº¿
    workflow.add_edge("parallel_processor", "agent")  # å¹¶è¡Œå¤„ç†åè¿›å…¥æ™ºèƒ½ä½“
    workflow.add_conditional_edges(
        "agent",
        route_agent_output,
        {"tools": "tools", "saver": "saver"}  # æ™ºèƒ½ä½“è¾“å‡ºåˆ°å·¥å…·æˆ–è®°å¿†ä¿å­˜
    )
    workflow.add_edge("tools", "agent")  # å·¥å…·æ‰§è¡Œåå›åˆ°æ™ºèƒ½ä½“

    # è®°å¿†å¤„ç†æµç¨‹
    workflow.add_edge("saver", "summarizer")  # é•¿æœŸè®°å¿†ä¿å­˜åè¿›è¡ŒçŸ­æœŸè®°å¿†æ€»ç»“
    workflow.add_edge("summarizer", END)      # æ€»ç»“å®Œæˆåç»“æŸæµç¨‹

    # ä¸»åŠ¨å¼æµç¨‹
    workflow.add_edge("proactive", "summarizer")  # ä¸»åŠ¨ç¤¾äº¤å¼•æ“ç›´æ¥è¿›å…¥è®°å¿†æ€»ç»“

    return workflow.compile()
```
- **åŠŸèƒ½**: é¡¹ç›®çš„å›¾æ„å»ºæ¨¡å—ï¼Œè´Ÿè´£ä½¿ç”¨LangGraphæ„å»ºèŠå¤©æœºå™¨äººçš„å®Œæ•´å·¥ä½œæµç¨‹ï¼ŒåŒ…æ‹¬å“åº”å¼å›å¤å’Œä¸»åŠ¨å‘èµ·å¯¹è¯ä¸¤ç§æ¨¡å¼
- **è®¾è®¡æ€è·¯**: 
  - ä½¿ç”¨LangGraphæ¡†æ¶æ„å»ºæœ‰çŠ¶æ€çš„å·¥ä½œæµç¨‹ï¼Œç®¡ç†æ™ºèƒ½ä½“çš„çŠ¶æ€å’Œå†³ç­–è·¯å¾„
  - é‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œå°†ä¸åŒåŠŸèƒ½æ‹†åˆ†ä¸ºç‹¬ç«‹çš„èŠ‚ç‚¹ï¼Œæé«˜ä»£ç çš„å¯ç»´æŠ¤æ€§å’Œå¯æ‰©å±•æ€§
  - å®ç°å“åº”å¼å’Œä¸»åŠ¨å¼ä¸¤ç§å·¥ä½œæ¨¡å¼ï¼Œæ»¡è¶³ä¸åŒçš„äº¤äº’åœºæ™¯
  - ä½¿ç”¨æ¡ä»¶è·¯ç”±ï¼Œæ ¹æ®å½“å‰çŠ¶æ€å’Œæ™ºèƒ½ä½“çš„è¾“å‡ºå†³å®šå·¥ä½œæµçš„èµ°å‘
  - æ”¯æŒå¹¶è¡Œå¤„ç†ï¼Œæé«˜ç³»ç»Ÿçš„å¤„ç†æ•ˆç‡
- **å½±å“èŒƒå›´**: 
  - æ•´ä¸ªèŠå¤©æœºå™¨äººçš„å·¥ä½œæµç¨‹å’Œå†³ç­–é€»è¾‘
  - å“åº”å¼å’Œä¸»åŠ¨å¼äº¤äº’çš„å®ç°
  - å„ä¸ªåŠŸèƒ½æ¨¡å—ä¹‹é—´çš„åä½œå’Œæ•°æ®æµè½¬
  - ç³»ç»Ÿçš„æ€§èƒ½å’Œå“åº”é€Ÿåº¦
  - ç”¨æˆ·ä½“éªŒçš„æµç•…æ€§å’Œè‡ªç„¶åº¦

#### app/graph/nodes/__init__.py
```python
# ç©ºæ–‡ä»¶ï¼Œç”¨äºæ ‡è¯† nodes ç›®å½•ä¸º Python åŒ…
```
- **åŠŸèƒ½**: æ ‡è¯† nodes ç›®å½•ä¸º Python åŒ…ï¼Œæ–¹ä¾¿å¯¼å…¥
- **è®¾è®¡æ€è·¯**: æ¨¡å—åŒ–è®¾è®¡ï¼Œå°†å›¾èŠ‚ç‚¹ç›¸å…³çš„ä»£ç é›†ä¸­ç®¡ç†
- **å½±å“èŒƒå›´**: æ— ç›´æ¥å½±å“ï¼Œä»…ä½œä¸ºåŒ…æ ‡è¯†

### 3.12 å·¥å…·æ¨¡å— (Tools)

#### app/tools/__init__.py
```python
# ç©ºæ–‡ä»¶ï¼Œç”¨äºæ ‡è¯† tools ç›®å½•ä¸º Python åŒ…
```
- **åŠŸèƒ½**: æ ‡è¯† tools ç›®å½•ä¸º Python åŒ…ï¼Œæ–¹ä¾¿å¯¼å…¥
- **è®¾è®¡æ€è·¯**: æ¨¡å—åŒ–è®¾è®¡ï¼Œå°†å·¥å…·ç›¸å…³çš„ä»£ç é›†ä¸­ç®¡ç†
- **å½±å“èŒƒå›´**: æ— ç›´æ¥å½±å“ï¼Œä»…ä½œä¸ºåŒ…æ ‡è¯†

#### app/tools/base_tool.py
```python
from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional, Tuple
import logging

logger = logging.getLogger("BaseTool")


class ToolParam:
    """å·¥å…·å‚æ•°å®šä¹‰"""
    def __init__(self, name: str, param_type: str, description: str, required: bool = True, enum_values: Optional[List[str]] = None):
        self.name = name
        self.param_type = param_type
        self.description = description
        self.required = required
        self.enum_values = enum_values

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        result = {
            "name": self.name,
            "type": self.param_type,
            "description": self.description,
            "required": self.required
        }
        if self.enum_values:
            result["enum"] = self.enum_values
        return result


class BaseTool(ABC):
    """æ‰€æœ‰å·¥å…·çš„åŸºç±»"""
    
    name: str = ""  # å·¥å…·åç§°
    description: str = ""  # å·¥å…·æè¿°
    parameters: List[ToolParam] = []  # å·¥å…·å‚æ•°åˆ—è¡¨
    available_for_llm: bool = True  # æ˜¯å¦å¯ä¾›LLMä½¿ç”¨
    
    def __init__(self):
        """åˆå§‹åŒ–å·¥å…·"""
        # éªŒè¯å·¥å…·å®šä¹‰æ˜¯å¦å®Œæ•´
        if not self.name or not self.description:
            raise ValueError(f"å·¥å…·ç±» {self.__class__.__name__} å¿…é¡»å®šä¹‰ name å’Œ description å±æ€§")
    
    @classmethod
    def get_tool_definition(cls) -> Dict[str, Any]:
        """è·å–å·¥å…·å®šä¹‰ï¼Œç”¨äºLLMå·¥å…·è°ƒç”¨"""
        return {
            "name": cls.name,
            "description": cls.description,
            "parameters": {
                "type": "object",
                "properties": {param.name: param.to_dict() for param in cls.parameters},
                "required": [param.name for param in cls.parameters if param.required]
            }
        }
    
    @abstractmethod
    async def execute(self, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡Œå·¥å…·å‡½æ•°
        
        Args:
            **kwargs: å·¥å…·è°ƒç”¨å‚æ•°
            
        Returns:
            Dict[str, Any]: å·¥å…·æ‰§è¡Œç»“æœï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
                - success: boolï¼Œæ‰§è¡Œæ˜¯å¦æˆåŠŸ
                - result: Anyï¼Œæ‰§è¡Œç»“æœ
                - error: strï¼Œé”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæ‰§è¡Œå¤±è´¥ï¼‰
        """
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç°executeæ–¹æ³•")
    
    def validate_params(self, **kwargs) -> Tuple[bool, str]:
        """éªŒè¯å·¥å…·å‚æ•°
        
        Args:
            **kwargs: å·¥å…·è°ƒç”¨å‚æ•°
            
        Returns:
            Tuple[bool, str]: (æ˜¯å¦éªŒè¯é€šè¿‡, é”™è¯¯ä¿¡æ¯)
        """
        # æ£€æŸ¥å¿…å¡«å‚æ•°
        for param in self.parameters:
            if param.required and param.name not in kwargs:
                return False, f"ç¼ºå°‘å¿…å¡«å‚æ•°: {param.name}"
        
        # æ£€æŸ¥å‚æ•°ç±»å‹
        for param in self.parameters:
            if param.name in kwargs:
                value = kwargs[param.name]
                if param.param_type == "string" and not isinstance(value, str):
                    return False, f"å‚æ•° {param.name} å¿…é¡»æ˜¯å­—ç¬¦ä¸²ç±»å‹"
                elif param.param_type == "integer" and not isinstance(value, int):
                    return False, f"å‚æ•° {param.name} å¿…é¡»æ˜¯æ•´æ•°ç±»å‹"
                elif param.param_type == "float" and not isinstance(value, float):
                    return False, f"å‚æ•° {param.name} å¿…é¡»æ˜¯æµ®ç‚¹æ•°ç±»å‹"
                elif param.param_type == "boolean" and not isinstance(value, bool):
                    return False, f"å‚æ•° {param.name} å¿…é¡»æ˜¯å¸ƒå°”ç±»å‹"
                
                # æ£€æŸ¥æšä¸¾å€¼
                if param.enum_values and value not in param.enum_values:
                    return False, f"å‚æ•° {param.name} å¿…é¡»æ˜¯ä»¥ä¸‹å€¼ä¹‹ä¸€: {', '.join(param.enum_values)}"
        
        return True, ""
```
- **åŠŸèƒ½**: é¡¹ç›®çš„å·¥å…·åŸºç±»æ¨¡å—ï¼Œå®šä¹‰äº†æ‰€æœ‰å·¥å…·å¿…é¡»å®ç°çš„æ¥å£å’Œé€šç”¨åŠŸèƒ½
- **è®¾è®¡æ€è·¯**: 
  - ä½¿ç”¨æŠ½è±¡åŸºç±»(ABC)å®šä¹‰å·¥å…·æ¥å£ï¼Œç¡®ä¿æ‰€æœ‰å·¥å…·éƒ½å®ç°ç»Ÿä¸€çš„æ–¹æ³•
  - æä¾›å·¥å…·å‚æ•°å®šä¹‰ç±»(ToolParam)ï¼Œæ”¯æŒå‚æ•°ç±»å‹ã€æè¿°ã€å¿…å¡«é¡¹å’Œæšä¸¾å€¼çš„å®šä¹‰
  - å®ç°å·¥å…·å®šä¹‰ç”Ÿæˆæ–¹æ³•ï¼Œç”¨äºLLMå·¥å…·è°ƒç”¨
  - æä¾›å‚æ•°éªŒè¯åŠŸèƒ½ï¼Œç¡®ä¿å·¥å…·è°ƒç”¨å‚æ•°çš„æ­£ç¡®æ€§
  - å®šä¹‰æ ‡å‡†çš„å·¥å…·æ‰§è¡Œç»“æœæ ¼å¼ï¼ŒåŒ…å«æ‰§è¡ŒçŠ¶æ€ã€ç»“æœå’Œé”™è¯¯ä¿¡æ¯
- **å½±å“èŒƒå›´**: 
  - æ‰€æœ‰å·¥å…·ç±»çš„å®ç°å’Œä½¿ç”¨
  - LLMå·¥å…·è°ƒç”¨çš„æ ¼å¼å’Œå‚æ•°éªŒè¯
  - å·¥å…·æ‰§è¡Œç»“æœçš„ç»Ÿä¸€æ€§å’Œå¯é¢„æµ‹æ€§

#### app/tools/tool_registry.py
```python
import importlib
import logging
import os
from typing import Dict, List, Type, Optional

from app.tools.base_tool import BaseTool

logger = logging.getLogger("ToolRegistry")


class ToolRegistry:
    """
    å·¥å…·æ³¨å†Œè¡¨
    ç”¨äºæ³¨å†Œã€å‘ç°å’Œç®¡ç†æ‰€æœ‰å¯ç”¨çš„å·¥å…·
    """
    
    def __init__(self):
        self.tools: Dict[str, BaseTool] = {}
        self.tool_classes: Dict[str, Type[BaseTool]] = {}
        
    def register_tool(self, tool_class: Type[BaseTool]):
        """
        æ³¨å†Œå·¥å…·ç±»
        
        Args:
            tool_class: å·¥å…·ç±»
        """
        try:
            # åˆ›å»ºå·¥å…·å®ä¾‹
            tool_instance = tool_class()
            
            # æ£€æŸ¥å·¥å…·æ˜¯å¦å·²æ³¨å†Œ
            if tool_instance.name in self.tools:
                logger.warning(f"å·¥å…· {tool_instance.name} å·²å­˜åœ¨ï¼Œå°†è¢«è¦†ç›–")
            
            # æ³¨å†Œå·¥å…·
            self.tools[tool_instance.name] = tool_instance
            self.tool_classes[tool_instance.name] = tool_class
            
            logger.info(f"å·¥å…· {tool_instance.name} æ³¨å†ŒæˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"å·¥å…· {tool_class.__name__} æ³¨å†Œå¤±è´¥: {e}")
            return False
    
    def get_tool(self, tool_name: str) -> Optional[BaseTool]:
        """
        è·å–å·¥å…·å®ä¾‹
        
        Args:
            tool_name: å·¥å…·åç§°
            
        Returns:
            Optional[BaseTool]: å·¥å…·å®ä¾‹ï¼Œå¦‚æœå·¥å…·ä¸å­˜åœ¨åˆ™è¿”å›None
        """
        return self.tools.get(tool_name)
    
    def get_tool_class(self, tool_name: str) -> Optional[Type[BaseTool]]:
        """
        è·å–å·¥å…·ç±»
        
        Args:
            tool_name: å·¥å…·åç§°
            
        Returns:
            Optional[Type[BaseTool]]: å·¥å…·ç±»ï¼Œå¦‚æœå·¥å…·ä¸å­˜åœ¨åˆ™è¿”å›None
        """
        return self.tool_classes.get(tool_name)
    
    def get_all_tools(self) -> List[BaseTool]:
        """
        è·å–æ‰€æœ‰æ³¨å†Œçš„å·¥å…·å®ä¾‹
        
        Returns:
            List[BaseTool]: æ‰€æœ‰å·¥å…·å®ä¾‹çš„åˆ—è¡¨
        """
        return list(self.tools.values())
    
    def get_available_llm_tools(self) -> List[Dict[str, any]]:
        """
        è·å–æ‰€æœ‰å¯ä¾›LLMä½¿ç”¨çš„å·¥å…·å®šä¹‰
        
        Returns:
            List[Dict[str, any]]: å·¥å…·å®šä¹‰åˆ—è¡¨
        """
        return [
            tool.get_tool_definition()
            for tool in self.tools.values()
            if tool.available_for_llm
        ]
    
    def load_tools_from_directory(self, directory: str):
        """
        ä»æŒ‡å®šç›®å½•åŠ è½½æ‰€æœ‰å·¥å…·
        
        Args:
            directory: å·¥å…·ç›®å½•è·¯å¾„
        """
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            if not os.path.exists(directory):
                logger.error(f"å·¥å…·ç›®å½• {directory} ä¸å­˜åœ¨")
                return
            
            # è·å–ç›®å½•ä¸‹æ‰€æœ‰Pythonæ–‡ä»¶
            files = [f for f in os.listdir(directory) if f.endswith(".py") and f != "__init__.py" and f != "base_tool.py"]
            
            # å¯¼å…¥å¹¶æ³¨å†Œæ¯ä¸ªå·¥å…·æ–‡ä»¶
            for file in files:
                module_name = file[:-3]  # å»æ‰.pyæ‰©å±•å
                
                try:
                    # åŠ¨æ€å¯¼å…¥æ¨¡å—
                    module = importlib.import_module(f"app.tools.{module_name}")
                    
                    # æŸ¥æ‰¾æ¨¡å—ä¸­çš„æ‰€æœ‰å·¥å…·ç±»
                    for name in dir(module):
                        obj = getattr(module, name)
                        
                        # æ£€æŸ¥æ˜¯å¦æ˜¯BaseToolçš„å­ç±»ä¸”ä¸æ˜¯æŠ½è±¡ç±»
                        if isinstance(obj, type) and issubclass(obj, BaseTool) and obj != BaseTool:
                            # æ³¨å†Œå·¥å…·
                            self.register_tool(obj)
                            
                except Exception as e:
                    logger.error(f"åŠ è½½å·¥å…·æ–‡ä»¶ {file} å¤±è´¥: {e}")
            
        except Exception as e:
            logger.error(f"ä»ç›®å½• {directory} åŠ è½½å·¥å…·å¤±è´¥: {e}")


# åˆ›å»ºå…¨å±€å·¥å…·æ³¨å†Œè¡¨å®ä¾‹
tool_registry = ToolRegistry()
```
- **åŠŸèƒ½**: é¡¹ç›®çš„å·¥å…·æ³¨å†Œè¡¨ï¼Œè´Ÿè´£æ³¨å†Œã€å‘ç°å’Œç®¡ç†æ‰€æœ‰å¯ç”¨çš„å·¥å…·
- **è®¾è®¡æ€è·¯**: 
  - ä½¿ç”¨å•ä¾‹æ¨¡å¼ï¼Œç¡®ä¿å·¥å…·æ³¨å†Œè¡¨çš„ä¸€è‡´æ€§å’Œå¯è®¿é—®æ€§
  - æä¾›å·¥å…·æ³¨å†Œã€è·å–å’Œç®¡ç†çš„æ¥å£
  - æ”¯æŒä»æŒ‡å®šç›®å½•åŠ¨æ€åŠ è½½å·¥å…·ï¼Œæé«˜ç³»ç»Ÿçš„å¯æ‰©å±•æ€§
  - åŒºåˆ†å¯ä¾›LLMä½¿ç”¨çš„å·¥å…·å’Œå†…éƒ¨å·¥å…·
  - å®ç°å·¥å…·ç±»å’Œå·¥å…·å®ä¾‹çš„åŒé‡ç®¡ç†
- **å½±å“èŒƒå›´**: 
  - æ‰€æœ‰å·¥å…·çš„æ³¨å†Œå’Œä½¿ç”¨
  - LLMå·¥å…·è°ƒç”¨çš„å¯ç”¨å·¥å…·åˆ—è¡¨
  - å·¥å…·çš„åŠ¨æ€åŠ è½½å’Œæ‰©å±•

#### app/tools/web_search.py
```python
import logging
from typing import Any, Dict, List

from app.tools.base_tool import BaseTool, ToolParam

logger = logging.getLogger("WebSearchTool")


class WebSearchTool(BaseTool):
    """
    ç½‘é¡µæœç´¢å·¥å…·
    ç”¨äºæœç´¢äº’è”ç½‘ä¸Šçš„ä¿¡æ¯
    """
    name = "web_search"
    description = "æœç´¢äº’è”ç½‘ä¸Šçš„ä¿¡æ¯ï¼Œè¿”å›ç›¸å…³çš„ç½‘é¡µæ‘˜è¦"
    parameters = [
        ToolParam("query", "string", "æœç´¢æŸ¥è¯¢è¯", required=True),
        ToolParam("max_results", "integer", "è¿”å›ç»“æœæ•°é‡", required=False, enum_values=[1, 2, 3, 4, 5])
    ]
    available_for_llm = True
    
    async def execute(self, **kwargs) -> Dict[str, Any]:
        """
        æ‰§è¡Œç½‘é¡µæœç´¢
        
        Args:
            query: æœç´¢æŸ¥è¯¢è¯
            max_results: è¿”å›ç»“æœæ•°é‡ï¼Œé»˜è®¤3
            
        Returns:
            Dict[str, Any]: æœç´¢ç»“æœ
        """
        try:
            # éªŒè¯å‚æ•°
            is_valid, error_msg = self.validate_params(**kwargs)
            if not is_valid:
                return {"success": False, "error": error_msg}
            
            query = kwargs["query"]
            max_results = kwargs.get("max_results", 3)
            
            # å®ç°ç½‘é¡µæœç´¢é€»è¾‘
            # ...
            
            return {
                "success": True,
                "result": [
                    {"title": "æœç´¢ç»“æœ1", "url": "https://example.com/1", "snippet": "è¿™æ˜¯æœç´¢ç»“æœ1çš„æ‘˜è¦"},
                    {"title": "æœç´¢ç»“æœ2", "url": "https://example.com/2", "snippet": "è¿™æ˜¯æœç´¢ç»“æœ2çš„æ‘˜è¦"}
                ]
            }
            
        except Exception as e:
            logger.error(f"ç½‘é¡µæœç´¢å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
```
- **åŠŸèƒ½**: é¡¹ç›®çš„ç½‘é¡µæœç´¢å·¥å…·ï¼Œç”¨äºæœç´¢äº’è”ç½‘ä¸Šçš„ä¿¡æ¯
- **è®¾è®¡æ€è·¯**: 
  - ç»§æ‰¿BaseToolåŸºç±»ï¼Œå®ç°æ ‡å‡†åŒ–çš„å·¥å…·æ¥å£
  - å®šä¹‰æœç´¢æŸ¥è¯¢è¯å’Œç»“æœæ•°é‡å‚æ•°
  - å®ç°å¼‚æ­¥æ‰§è¡Œæ–¹æ³•ï¼Œæ”¯æŒå¹¶å‘æœç´¢
  - è¿”å›ç»“æ„åŒ–çš„æœç´¢ç»“æœï¼ŒåŒ…å«æ ‡é¢˜ã€URLå’Œæ‘˜è¦
- **å½±å“èŒƒå›´**: 
  - äº’è”ç½‘ä¿¡æ¯çš„è·å–å’Œæ£€ç´¢
  - LLMçš„çŸ¥è¯†æ‰©å±•å’Œä¿¡æ¯è¡¥å……
  - ç”¨æˆ·æŸ¥è¯¢çš„å“åº”è´¨é‡

### 3.13 å·¥å…·æ¨¡å— (Utils)

#### app/utils/__init__.py
```python
# ç©ºæ–‡ä»¶ï¼Œç”¨äºæ ‡è¯† utils ç›®å½•ä¸º Python åŒ…
```
- **åŠŸèƒ½**: æ ‡è¯† utils ç›®å½•ä¸º Python åŒ…ï¼Œæ–¹ä¾¿å¯¼å…¥
- **è®¾è®¡æ€è·¯**: ç®€å•çš„åŒ…æ ‡è¯†æ–‡ä»¶ï¼Œæ— å®é™…åŠŸèƒ½
- **å½±å“èŒƒå›´**: æ•´ä¸ªé¡¹ç›®çš„å¯¼å…¥ç»“æ„

#### app/utils/cache.py
```python
class LLMCache:
    """
    LLMè°ƒç”¨ç¼“å­˜ç³»ç»Ÿ
    ç”¨äºç¼“å­˜LLMè°ƒç”¨çš„è¯·æ±‚å’Œå“åº”ï¼Œå‡å°‘é‡å¤è°ƒç”¨ï¼Œæé«˜æ€§èƒ½
    """
    
    def __init__(self, max_size: int = 1000, default_ttl: int = 7200, persist_file: Optional[str] = None, persist_interval: int = 300):
        """
        åˆå§‹åŒ–ç¼“å­˜ç³»ç»Ÿ
        
        Args:
            max_size: ç¼“å­˜çš„æœ€å¤§æ¡ç›®æ•°
            default_ttl: é»˜è®¤çš„ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
            persist_file: ç¼“å­˜æŒä¹…åŒ–æ–‡ä»¶è·¯å¾„ï¼ŒNoneè¡¨ç¤ºä¸æŒä¹…åŒ–
            persist_interval: è‡ªåŠ¨æŒä¹…åŒ–é—´éš”ï¼ˆç§’ï¼‰
        """
        self.max_size = max_size
        self.default_ttl = default_ttl
        self.cache: OrderedDict[str, Tuple[Any, datetime]] = OrderedDict()
        self.lock = asyncio.Lock()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.hits = 0
        self.misses = 0
        self.total_requests = 0
        
        # æŒä¹…åŒ–ç›¸å…³é…ç½®
        self.persist_file = persist_file
        self.persist_interval = persist_interval
        self.last_persist_time = datetime.now()
        
        # ç¼“å­˜ç­–ç•¥é…ç½® - é’ˆå¯¹ä¸åŒç±»å‹è¯·æ±‚çš„TTLè¦†ç›–
        self.ttl_overrides: Dict[str, int] = {
            "simple_query": 3600,  # ç®€å•æŸ¥è¯¢ç¼“å­˜1å°æ—¶
            "complex_query": 1800,  # å¤æ‚æŸ¥è¯¢ç¼“å­˜30åˆ†é’Ÿ
            "creative_query": 600,  # åˆ›é€ æ€§æŸ¥è¯¢ç¼“å­˜10åˆ†é’Ÿ
            "group_chat": 1800,  # ç¾¤èŠæ¶ˆæ¯ç¼“å­˜30åˆ†é’Ÿ
            "private_chat": 3600,  # ç§èŠæ¶ˆæ¯ç¼“å­˜1å°æ—¶
            "mention_response": 1200,  # è¢«@å›å¤ç¼“å­˜20åˆ†é’Ÿ
            "generic_response": 300,  # é€šç”¨å“åº”ç¼“å­˜5åˆ†é’Ÿ
            # æ–°å¢ç»„ä»¶ç‰¹å®šçš„ç¼“å­˜ç­–ç•¥
            "context_filter": 3600,  # ContextFilterç»“æœç¼“å­˜1å°æ—¶ï¼ˆç¡®å®šæ€§å†³ç­–ï¼‰
            "vision_router": 1800,  # VisionRouterç»“æœç¼“å­˜30åˆ†é’Ÿï¼ˆè§†è§‰åˆ¤æ–­ï¼‰
            "psychology_analysis": 1200,  # Psychologyåˆ†æç»“æœç¼“å­˜20åˆ†é’Ÿï¼ˆæƒ…ç»ªåˆ†æï¼‰
            "memory_extraction": 3600  # è®°å¿†æå–ç»“æœç¼“å­˜1å°æ—¶ï¼ˆç”¨æˆ·ä¿¡æ¯æå–ï¼‰
        }
        
        # å¦‚æœé…ç½®äº†æŒä¹…åŒ–æ–‡ä»¶ï¼Œå°è¯•ä»ç£ç›˜åŠ è½½
        if self.persist_file:
            try:
                self._load_from_disk()
            except Exception as e:
                logger.error(f"ä»ç£ç›˜åŠ è½½ç¼“å­˜å¤±è´¥: {str(e)}")
    
    def _load_from_disk(self):
        """ä»ç£ç›˜åŠ è½½ç¼“å­˜æ•°æ®ï¼Œåªä¿ç•™æœªè¿‡æœŸçš„æ¡ç›®"""
        # å®ç°ä»£ç ...
    
    def _generate_key(self, messages: List[BaseMessage], model: str, temperature: float, query_type: str = "default") -> str:
        """
        æ ¹æ®è¾“å…¥æ¶ˆæ¯ç”Ÿæˆå”¯ä¸€çš„ç¼“å­˜é”®
        - ä½¿ç”¨msgpackåºåˆ—åŒ–æ¶ˆæ¯æ•°æ®ï¼Œæé«˜æ€§èƒ½
        - è€ƒè™‘æ¶ˆæ¯ç±»å‹ã€å†…å®¹ã€æ¨¡å‹ã€æ¸©åº¦å‚æ•°å’ŒæŸ¥è¯¢ç±»å‹
        """
        # ç®€åŒ–æ¶ˆæ¯è½¬æ¢ï¼Œåªä¿ç•™å¿…è¦ä¿¡æ¯
        message_data = []
        for msg in messages:
            msg_data = {
                "type": msg.__class__.__name__,  # æ¶ˆæ¯ç±»å‹
                "content": msg.content,  # æ¶ˆæ¯å†…å®¹
                "additional_kwargs": msg.additional_kwargs,  # é™„åŠ å‚æ•°
            }
            message_data.append(msg_data)
        
        cache_key_data = {
            "messages": message_data,
            "model": model,
            "temperature": temperature,
            "query_type": query_type
        }
        
        cache_key_bytes = msgpack.packb(cache_key_data, use_bin_type=True)
        return hashlib.sha256(cache_key_bytes).hexdigest()
    
    async def get(self, messages: List[BaseMessage], model: str, temperature: float, query_type: str = "default") -> Optional[Any]:
        """
        ä»ç¼“å­˜ä¸­è·å–LLMè°ƒç”¨ç»“æœ
        - ä½¿ç”¨LRUç­–ç•¥ï¼šè·å–æ—¶å°†æ¡ç›®ç§»åˆ°ç¼“å­˜æœ«å°¾
        - è‡ªåŠ¨æ£€æŸ¥æ¡ç›®æ˜¯å¦è¿‡æœŸ
        """
        cache_key = self._generate_key(messages, model, temperature, query_type)
        
        async with self.lock:
            self.total_requests += 1
            
            if cache_key in self.cache:
                value, expire_time = self.cache.pop(cache_key)  # ç§»é™¤æ¡ç›®
                if datetime.now() < expire_time:
                    self.cache[cache_key] = (value, expire_time)  # é‡æ–°æ·»åŠ åˆ°æœ«å°¾ï¼Œå®ç°LRU
                    self.hits += 1
                    return value
            
            self.misses += 1
            return None
    
    async def set(self, messages: List[BaseMessage], model: str, temperature: float, value: Any, ttl: Optional[int] = None, query_type: str = "default") -> None:
        """
        å°†LLMè°ƒç”¨ç»“æœå­˜å…¥ç¼“å­˜
        - è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„TTLï¼šä¼˜å…ˆä½¿ç”¨æŒ‡å®šTTLï¼Œå¦åˆ™æ ¹æ®query_typeé€‰æ‹©ï¼Œæœ€åä½¿ç”¨é»˜è®¤TTL
        - å¯¹åˆ›é€ æ€§å†…å®¹ï¼ˆé«˜temperatureï¼‰ä½¿ç”¨è¾ƒçŸ­çš„TTL
        - è‡ªåŠ¨æ¸…ç†è¶…å‡ºæœ€å¤§å¤§å°çš„æ—§æ¡ç›®
        - æ”¯æŒç¼“å­˜æŒä¹…åŒ–
        """
        # é€‰æ‹©åˆé€‚çš„TTL
        if ttl is None:
            ttl = self.ttl_overrides.get(query_type, self.default_ttl)
            
            # å¯¹äºåˆ›é€ æ€§å†…å®¹ï¼Œå³ä½¿æ²¡æœ‰æŒ‡å®šquery_typeï¼Œä¹Ÿä½¿ç”¨è¾ƒçŸ­çš„TTL
            if temperature > 0.8:
                ttl = min(ttl, 600)  # æœ€å¤šç¼“å­˜10åˆ†é’Ÿ
            elif temperature > 0.5:
                ttl = min(ttl, 1800)  # æœ€å¤šç¼“å­˜30åˆ†é’Ÿ
        
        cache_key = self._generate_key(messages, model, temperature, query_type)
        expire_time = datetime.now() + timedelta(seconds=ttl)
        
        async with self.lock:
            # å¦‚æœæ¡ç›®å·²å­˜åœ¨ï¼Œå…ˆç§»é™¤ï¼ˆä¼šè‡ªåŠ¨ç§»åˆ°æœ«å°¾ï¼‰
            if cache_key in self.cache:
                del self.cache[cache_key]
            
            # æ£€æŸ¥ç¼“å­˜å¤§å°ï¼Œå¦‚æœè¶…è¿‡æœ€å¤§å€¼åˆ™æ¸…ç†æœ€æ—§çš„æ¡ç›®
            if len(self.cache) >= self.max_size:
                self.cache.popitem(last=False)  # ç§»é™¤æœ€æ—§çš„æ¡ç›®
            
            self.cache[cache_key] = (value, expire_time)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨æŒä¹…åŒ–
        if self.persist_file:
            time_since_last_persist = (datetime.now() - self.last_persist_time).total_seconds()
            if time_since_last_persist >= self.persist_interval:
                self._save_to_disk()
    
    def _save_to_disk(self):
        """å°†ç¼“å­˜æ•°æ®ä¿å­˜åˆ°ç£ç›˜ï¼Œå¤„ç†å¯¹è±¡åºåˆ—åŒ–"""
        # å®ç°ä»£ç ...

class LLMRequestQueue:
    """
    LLMè¯·æ±‚é˜Ÿåˆ—ç³»ç»Ÿ
    ç”¨äºç®¡ç†LLMè°ƒç”¨è¯·æ±‚ï¼Œæ§åˆ¶å¹¶å‘æ•°ï¼Œé˜²æ­¢è¯·æ±‚å †ç§¯å’Œè¶…æ—¶
    æ”¯æŒè¯·æ±‚åˆå¹¶ï¼Œé¿å…é‡å¤è¯·æ±‚
    """
    
    def __init__(self, max_concurrent: int = 15, timeout: int = 60):
        """
        åˆå§‹åŒ–è¯·æ±‚é˜Ÿåˆ—
        
        Args:
            max_concurrent: æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.max_concurrent = max_concurrent
        self.timeout = timeout
        self.queue: Deque = deque()
        self.current_concurrent = 0
        self.lock = asyncio.Lock()
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.pending_requests: Dict[str, List[asyncio.Future]] = {}  # å­˜å‚¨æ­£åœ¨å¤„ç†çš„è¯·æ±‚
        
        # è¯·æ±‚åˆå¹¶ä¼˜åŒ–
        self.merge_window = 0.5  # è¯·æ±‚åˆå¹¶çª—å£ï¼ˆç§’ï¼‰
        self.last_request_time: Dict[str, float] = {}  # è®°å½•æ¯ä¸ªè¯·æ±‚é”®çš„æœ€åè¯·æ±‚æ—¶é—´
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.total_requests = 0
        self.success_requests = 0
        self.failed_requests = 0
        self.merged_requests = 0  # é€šè¿‡è¯·æ±‚åˆå¹¶èŠ‚çœçš„è¯·æ±‚æ•°
        self.total_processing_time = 0.0
        self.request_times = []  # æœ€è¿‘è¯·æ±‚çš„å“åº”æ—¶é—´åˆ—è¡¨
    
    def _generate_request_key(self, llm: Any, messages: List[BaseMessage], temperature: float) -> str:
        """ç”Ÿæˆè¯·æ±‚çš„å”¯ä¸€æ ‡è¯†ï¼Œç”¨äºè¯·æ±‚åˆå¹¶"""
        # è·å–æ¨¡å‹åç§°
        model = getattr(llm, "model", "unknown")
        
        # ä½¿ç”¨ä¸LLMCacheç›¸åŒçš„é”®ç”Ÿæˆé€»è¾‘
        llm_cache_instance = LLMCache()
        return llm_cache_instance._generate_key(messages, model, temperature)
    
    async def add_request(self, llm: Any, messages: List[BaseMessage], temperature: float = 0.7) -> Any:
        """
        æ·»åŠ LLMè¯·æ±‚åˆ°é˜Ÿåˆ—å¹¶ç­‰å¾…ç»“æœ
        - æ”¯æŒè¯·æ±‚åˆå¹¶ï¼šç›¸åŒçš„è¯·æ±‚åªå¤„ç†ä¸€æ¬¡ï¼Œç»“æœå…±äº«
        - æ§åˆ¶å¹¶å‘æ•°ï¼Œé˜²æ­¢è¯·æ±‚å †ç§¯
        - è®¾ç½®è¯·æ±‚è¶…æ—¶
        """
        # ç”Ÿæˆè¯·æ±‚çš„å”¯ä¸€æ ‡è¯†
        request_key = self._generate_request_key(llm, messages, temperature)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸åŒçš„è¯·æ±‚æ­£åœ¨å¤„ç†
        async with self.lock:
            if request_key in self.pending_requests:
                # åˆ›å»ºæ–°çš„futureå¹¶åŠ å…¥ç­‰å¾…åˆ—è¡¨
                future = asyncio.Future()
                self.pending_requests[request_key].append(future)
                self.total_requests += 1
                self.merged_requests += 1  # è¿™æ˜¯ä¸€ä¸ªè¢«åˆå¹¶çš„è¯·æ±‚
                
                # ç­‰å¾…ç»“æœ
                try:
                    return await future
                except Exception as e:
                    # ç§»é™¤futureä»¥é˜²æ­¢å†…å­˜æ³„æ¼
                    self.pending_requests[request_key].remove(future)
                    raise
            
            # åˆ›å»ºæ–°çš„è¯·æ±‚åˆ—è¡¨
            self.pending_requests[request_key] = []
            self.total_requests += 1
        
        # å¤„ç†è¯·æ±‚
        async with self.semaphore:
            start_time = datetime.now()
            try:
                # ä½¿ç”¨asyncio.wait_forè®¾ç½®è¯·æ±‚è¶…æ—¶
                result = await asyncio.wait_for(
                    llm.ainvoke(messages),
                    timeout=self.timeout
                )
                
                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                self.success_requests += 1
                self.total_processing_time += (datetime.now() - start_time).total_seconds()
                
                # é€šçŸ¥æ‰€æœ‰ç­‰å¾…çš„è¯·æ±‚
                async with self.lock:
                    if request_key in self.pending_requests:
                        # æ›´æ–°åˆå¹¶è¯·æ±‚ç»Ÿè®¡
                        self.merged_requests += len(self.pending_requests[request_key])
                        
                        for future in self.pending_requests[request_key]:
                            if not future.done():
                                future.set_result(result)
                        # æ¸…ç†è¯·æ±‚
                        del self.pending_requests[request_key]
                
                return result
            except Exception as e:
                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                self.failed_requests += 1
                
                # é€šçŸ¥æ‰€æœ‰ç­‰å¾…çš„è¯·æ±‚å‘ç”Ÿé”™è¯¯
                async with self.lock:
                    if request_key in self.pending_requests:
                        # æ›´æ–°åˆå¹¶è¯·æ±‚ç»Ÿè®¡
                        self.merged_requests += len(self.pending_requests[request_key])
                        
                        for future in self.pending_requests[request_key]:
                            if not future.done():
                                future.set_exception(e)
                        # æ¸…ç†è¯·æ±‚
                        del self.pending_requests[request_key]
                
                raise

# å…¨å±€ç¼“å­˜å®ä¾‹
llm_cache = LLMCache(
    max_size=1000,  # ç¼“å­˜1000æ¡LLMè°ƒç”¨ç»“æœ
    default_ttl=7200,  # é»˜è®¤ç¼“å­˜2å°æ—¶
    persist_file=os.path.join(cache_dir, "llm_cache.msgpack"),  # ç¼“å­˜æŒä¹…åŒ–æ–‡ä»¶
    persist_interval=300  # æ¯5åˆ†é’Ÿè‡ªåŠ¨æŒä¹…åŒ–ä¸€æ¬¡
)

user_cache = LLMCache(
    max_size=2000,  # ç¼“å­˜2000ä¸ªç”¨æˆ·ä¿¡æ¯
    default_ttl=86400,  # ç¼“å­˜1å¤©
    persist_file=os.path.join(cache_dir, "user_cache.msgpack")
)

context_cache = LLMCache(
    max_size=2000,  # ç¼“å­˜2000ä¸ªä¸Šä¸‹æ–‡ä¿¡æ¯
    default_ttl=1800,  # ç¼“å­˜30åˆ†é’Ÿ
    persist_file=os.path.join(cache_dir, "context_cache.msgpack")
)

tool_cache = LLMCache(
    max_size=4000,  # ç¼“å­˜4000ä¸ªå·¥å…·è°ƒç”¨ç»“æœ
    default_ttl=3600,  # ç¼“å­˜1å°æ—¶
    persist_file=os.path.join(cache_dir, "tool_cache.msgpack")
)

# å…¨å±€è¯·æ±‚é˜Ÿåˆ—å®ä¾‹
llm_queue = LLMRequestQueue(max_concurrent=15, timeout=60)  # æœ€å¤§15ä¸ªå¹¶å‘è¯·æ±‚ï¼Œè¶…æ—¶60ç§’

async def cached_llm_invoke(llm: Any, messages: List[BaseMessage], temperature: float = 0.7, max_retries: int = 2, query_type: str = "default", conversation_type: str = "private") -> Any:
    """
    å¸¦ç¼“å­˜å’Œé”™è¯¯å¤„ç†çš„LLMè°ƒç”¨å‡½æ•°
    - è‡ªåŠ¨åˆ¤æ–­æŸ¥è¯¢ç±»å‹ï¼Œä¼˜åŒ–ç¼“å­˜ç­–ç•¥
    - æ”¯æŒç¼“å­˜å‘½ä¸­ç›´æ¥è¿”å›
    - ç¼“å­˜æœªå‘½ä¸­æ—¶é€šè¿‡è¯·æ±‚é˜Ÿåˆ—è°ƒç”¨LLM
    - å®ç°æŒ‡æ•°é€€é¿é‡è¯•æœºåˆ¶
    """
    # è‡ªåŠ¨åˆ¤æ–­æŸ¥è¯¢ç±»å‹
    auto_query_type = query_type
    if auto_query_type == "default":
        # æ£€æŸ¥æ˜¯å¦ä¸ºç¾¤èŠè¢«@çš„æƒ…å†µ
        last_msg = messages[-1] if messages else None
        if isinstance(last_msg, HumanMessage):
            content = str(last_msg.content)
            # æ£€æŸ¥æ˜¯å¦åŒ…å«@æ ‡è®°
            if "@" in content or "CQ:at" in content:
                auto_query_type = "mention_response"
            # ç®€å•åˆ¤æ–­æ¶ˆæ¯å¤æ‚åº¦
            elif len(content) < 50:
                auto_query_type = "simple_query"
            elif len(content) > 200:
                auto_query_type = "complex_query"
            else:
                auto_query_type = "generic_response"
        
        # æ ¹æ®å¯¹è¯ç±»å‹è°ƒæ•´æŸ¥è¯¢ç±»å‹
        if conversation_type == "group":
            auto_query_type = f"group_{auto_query_type}"
        else:
            auto_query_type = f"private_{auto_query_type}"
    
    # è·å–æ¨¡å‹åç§°
    model = getattr(llm, "model", "unknown")
    
    # å°è¯•ä»ç¼“å­˜è·å–
    cached_result = await llm_cache.get(messages, model, temperature, auto_query_type)
    if cached_result:
        return cached_result
    
    # ç¼“å­˜æœªå‘½ä¸­ï¼Œå°è¯•è°ƒç”¨LLM
    retry_count = 0
    last_exception = None
    
    while retry_count <= max_retries:
        try:
            # é€šè¿‡è¯·æ±‚é˜Ÿåˆ—è°ƒç”¨LLM
            result = await llm_queue.add_request(llm, messages, temperature)
            
            # å°†ç»“æœå­˜å…¥ç¼“å­˜
            await llm_cache.set(messages, model, temperature, result, query_type=auto_query_type)
            
            return result
        except asyncio.TimeoutError as e:
            last_exception = e
            retry_count += 1
        except (ConnectionError, BrokenPipeError, OSError) as e:
            last_exception = e
            retry_count += 1
        except Exception as e:
            # å…¶ä»–å¼‚å¸¸ï¼Œä¸é‡è¯•
            raise
        
        # é‡è¯•å‰ç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œé¿å…ç«‹å³é‡è¯•
        if retry_count <= max_retries:
            # ä½¿ç”¨æŒ‡æ•°é€€é¿ç®—æ³•
            wait_time = 2 ** retry_count  # 1, 2, 4ç§’
            await asyncio.sleep(wait_time)
    
    # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
    raise last_exception
```
- **åŠŸèƒ½**: æä¾›LLMè°ƒç”¨çš„ç¼“å­˜æœºåˆ¶å’Œè¯·æ±‚é˜Ÿåˆ—ç®¡ç†ï¼Œä¼˜åŒ–æ€§èƒ½å’Œèµ„æºä½¿ç”¨
- **è®¾è®¡æ€è·¯**: 
  - **ç¼“å­˜ç³»ç»Ÿ**: 
    - ä½¿ç”¨LRUç¼“å­˜ç­–ç•¥ï¼Œæ ¹æ®è¯·æ±‚ç±»å‹è‡ªåŠ¨è°ƒæ•´TTLï¼ˆç”Ÿå­˜æ—¶é—´ï¼‰
    - æ”¯æŒç¼“å­˜æŒä¹…åŒ–ï¼Œå‡å°‘é‡å¯åçš„ç¼“å­˜ä¸¢å¤±
    - å¯¹ä¸åŒç±»å‹çš„è¯·æ±‚ï¼ˆç®€å•æŸ¥è¯¢ã€å¤æ‚æŸ¥è¯¢ã€åˆ›é€ æ€§å†…å®¹ç­‰ï¼‰ä½¿ç”¨ä¸åŒçš„ç¼“å­˜ç­–ç•¥
    - é’ˆå¯¹é«˜temperatureçš„åˆ›é€ æ€§å†…å®¹ä½¿ç”¨è¾ƒçŸ­çš„TTL
    - æä¾›å¤šç§ä¸“ç”¨ç¼“å­˜å®ä¾‹ï¼ˆLLMè°ƒç”¨ã€ç”¨æˆ·ä¿¡æ¯ã€ä¸Šä¸‹æ–‡ã€å·¥å…·è°ƒç”¨ã€åµŒå…¥å‘é‡ï¼‰
  
  - **è¯·æ±‚é˜Ÿåˆ—**: 
    - å®ç°è¯·æ±‚åˆå¹¶ï¼Œç›¸åŒè¯·æ±‚åªå¤„ç†ä¸€æ¬¡ï¼Œç»“æœå…±äº«
    - æ§åˆ¶å¹¶å‘æ•°ï¼Œé˜²æ­¢è¯·æ±‚å †ç§¯
    - è®¾ç½®è¯·æ±‚è¶…æ—¶ï¼Œé¿å…é•¿æ—¶é—´é˜»å¡
    - æä¾›è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆè¯·æ±‚æ•°ã€æˆåŠŸç‡ã€åˆå¹¶ç‡ã€å“åº”æ—¶é—´ç­‰ï¼‰
  
  - **ç»Ÿä¸€æ¥å£**: 
    - æä¾›`cached_llm_invoke`å‡½æ•°ï¼Œé›†æˆç¼“å­˜å’Œé˜Ÿåˆ—åŠŸèƒ½
    - è‡ªåŠ¨åˆ¤æ–­æŸ¥è¯¢ç±»å‹ï¼Œä¼˜åŒ–ç¼“å­˜ç­–ç•¥
    - å®ç°æŒ‡æ•°é€€é¿é‡è¯•æœºåˆ¶ï¼Œæé«˜ç³»ç»Ÿç¨³å®šæ€§
- **å½±å“èŒƒå›´**: 
  - æ•´ä¸ªé¡¹ç›®çš„æ€§èƒ½ï¼Œå‡å°‘LLMè°ƒç”¨æ¬¡æ•°ï¼Œé™ä½æˆæœ¬
  - ç³»ç»Ÿçš„ç¨³å®šæ€§ï¼Œé˜²æ­¢è¯·æ±‚å †ç§¯å’Œè¶…æ—¶
  - ç”¨æˆ·ä½“éªŒï¼Œå‡å°‘å“åº”æ—¶é—´
  - èµ„æºä½¿ç”¨æ•ˆç‡ï¼Œä¼˜åŒ–å¹¶å‘å¤„ç†

# åµŒå…¥å‘é‡ç¼“å­˜æ”¯æŒ
åµŒå…¥å‘é‡ç¼“å­˜æ˜¯cache.pyçš„é‡è¦æ‰©å±•åŠŸèƒ½ï¼Œä¸“é—¨ç”¨äºç¼“å­˜æ–‡æœ¬çš„åµŒå…¥å‘é‡ï¼Œå‡å°‘é‡å¤è®¡ç®—ï¼š

```python
# åµŒå…¥å‘é‡ç¼“å­˜
embedding_cache = LLMCache(
    max_size=5000, 
    default_ttl=86400,  # ç¼“å­˜5000ä¸ªåµŒå…¥å‘é‡ï¼Œé»˜è®¤è¿‡æœŸæ—¶é—´1å¤©
    persist_file=os.path.join(cache_dir, "embedding_cache.msgpack")
)

async def cached_embedding_get(text: str, model: str) -> Optional[List[float]]:
    """ä»ç¼“å­˜è·å–æ–‡æœ¬çš„åµŒå…¥å‘é‡"""
    # å®ç°ä»£ç ...

async def cached_embedding_set(text: str, model: str, embedding: List[float], ttl: Optional[int] = None) -> None:
    """å°†æ–‡æœ¬çš„åµŒå…¥å‘é‡å­˜å…¥ç¼“å­˜"""
    # å®ç°ä»£ç ...
```
- **åŠŸèƒ½**: ç¼“å­˜æ–‡æœ¬çš„åµŒå…¥å‘é‡ï¼Œå‡å°‘é‡å¤è®¡ç®—
- **è®¾è®¡æ€è·¯**: å¤ç”¨LLMCacheçš„å®ç°ï¼Œä¸“é—¨ç”¨äºå­˜å‚¨å’Œæ£€ç´¢åµŒå…¥å‘é‡
- **å½±å“èŒƒå›´**: æ‰€æœ‰ä½¿ç”¨åµŒå…¥å‘é‡çš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬è®°å¿†æ£€ç´¢ã€ç›¸ä¼¼åº¦è®¡ç®—ç­‰

#### app/utils/qq_utils.py
```python
def parse_onebot_array_msg(message_data: list | dict) -> Tuple[str, List[str], Optional[str]]:
    """
    è§£æOneBot v11æ¶ˆæ¯æ•°ç»„ï¼Œå°†å¤æ‚çš„æ¶ˆæ¯ç»“æ„è½¬æ¢ä¸ºå¯è¯»æ–‡æœ¬
    
    Returns:
        (plain_text, image_urls, reply_message_id)
    """
    text_content: str = ""
    image_urls: List[str] = []
    reply_id: Optional[str] = None
    
    # å¤„ç†å­—ç¬¦ä¸²å½¢å¼çš„ç‰¹æ®Šæ¶ˆæ¯æ ‡è®°
    if isinstance(message_data, str):
        # å¤„ç†å¸¸è§çš„å­—ç¬¦ä¸²å½¢å¼çš„åˆå¹¶è½¬å‘æ¶ˆæ¯
        if "[forward]" in message_data or "[è½¬å‘æ¶ˆæ¯]" in message_data:
            return "[åˆå¹¶è½¬å‘æ¶ˆæ¯]", [], None
        # å¤„ç†æ™®é€šæ–‡æœ¬æ¶ˆæ¯
        # å°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–å›¾ç‰‡URL
        import re
        img_matches = re.findall(r'https?://[^\s]+\.(?:jpg|jpeg|png|gif|bmp|webp)', message_data)
        if img_matches:
            img_urls = [url.strip() for url in img_matches]
        return message_data, img_urls, None

    if not isinstance(message_data, list):
        return "", [], None

    for segment in message_data:
        if not isinstance(segment, dict):
            continue

        msg_type = segment.get("type")
        data = segment.get("data") or {}
        if not isinstance(data, dict):
            data = {}

        # ---------------------------
        # Text æ–‡æœ¬æ¶ˆæ¯
        # ---------------------------
        if msg_type == "text":
            text = str(data.get("text", ""))
            if "[è½¬å‘æ¶ˆæ¯]" in text:
                text_content += "[åˆå¹¶è½¬å‘æ¶ˆæ¯]"
            else:
                text_content += text
            continue

        # ---------------------------
        # Image å›¾ç‰‡æ¶ˆæ¯
        # ---------------------------
        if msg_type == "image":
            url = data.get("url")
            if isinstance(url, str) and url.strip():
                image_urls.append(url.strip())

            # å¦‚æœæ˜¯ä»mfaceè½¬æ¢æ¥çš„å›¾ç‰‡ï¼Œä¼˜å…ˆä½¿ç”¨è¡¨æƒ…æ ‡ç­¾
            if any(k in data for k in ("emoji_id", "emoji_package_id", "key")):
                summary = data.get("summary")
                label = None
                if isinstance(summary, str) and summary.strip():
                    label = summary.strip()
                elif data.get("emoji_id"):
                    label = f"emoji_id={data.get('emoji_id')}"
                else:
                    label = "mface"
                text_content += f" [å•†åŸè¡¨æƒ…:{label}] "
            else:
                text_content += " [å›¾ç‰‡] "
            continue

        # ---------------------------
        # QQ system face QQå†…ç½®è¡¨æƒ…
        # ---------------------------
        if msg_type == "face":
            face_id = str(data.get("id", ""))

            # å¤„ç†éª°å­/çŒœæ‹³ç­‰ç‰¹æ®Šè¡¨æƒ…
            if face_id in {"358", "359"} and data.get("resultId") is not None:
                if face_id == "358":
                    text_content += f" [éª°å­:{data.get('resultId')}] "
                else:
                    text_content += f" [çŒœæ‹³:{_format_rps_result(data.get('resultId'))}] "
                continue

            face_desc = _resolve_face_desc(face_id, raw=data.get("raw"))
            if face_desc:
                text_content += f" [è¡¨æƒ…:{face_desc}] "
            else:
                text_content += f" [Face:{face_id}] "
            continue

        # ---------------------------
        # Marketplace face å•†åŸè¡¨æƒ…
        # ---------------------------
        if msg_type == "mface":
            text_content += _format_mface(data)
            continue

        # ---------------------------
        # Dice / RPS / Poke éª°å­/çŒœæ‹³/æˆ³ä¸€æˆ³
        # ---------------------------
        if msg_type == "dice":
            text_content += f" [éª°å­:{data.get('result', '')}] "
            continue

        if msg_type == "rps":
            text_content += f" [çŒœæ‹³:{_format_rps_result(data.get('result'))}] "
            continue

        if msg_type == "poke":
            poke_type = data.get("type")
            poke_id = data.get("id")
            text_content += f" [æˆ³ä¸€æˆ³:type={poke_type}, id={poke_id}] "
            continue

        # ---------------------------
        # Mentions / reply @æåŠ/å›å¤
        # ---------------------------
        if msg_type == "at":
            qq = data.get("qq")
            text_content += f"[Mention:{qq}]"
            continue

        if msg_type == "reply":
            reply_id = str(data.get("id")) if data.get("id") is not None else None
            continue

        # ---------------------------
        # Other common message types å…¶ä»–å¸¸è§æ¶ˆæ¯ç±»å‹
        # ---------------------------
        if msg_type == "record":
            text_content += " [è¯­éŸ³æ¶ˆæ¯] "
            continue

        if msg_type == "video":
            text_content += " [è§†é¢‘æ¶ˆæ¯] "
            continue

        if msg_type == "file":
            name = data.get("name") or data.get("file") or "file"
            text_content += f" [æ–‡ä»¶:{name}] "
            continue

        if msg_type == "json":
            text_content += " [å¡ç‰‡æ¶ˆæ¯/å°ç¨‹åº] "
            continue

        if msg_type == "xml":
            text_content += " [XMLæ¶ˆæ¯] "
            continue

        # ---------------------------
        # åˆå¹¶è½¬å‘æ¶ˆæ¯
        # ---------------------------
        if msg_type == "forward":
            # è·å–è½¬å‘æ¶ˆæ¯IDï¼ˆç”¨äºé€šè¿‡APIè·å–å®é™…å†…å®¹ï¼‰
            forward_id = data.get("id") or data.get("forward_id")
            
            # æå–åˆå¹¶è½¬å‘çš„æ¶ˆæ¯å†…å®¹
            forward_content = data.get("content", "")
            
            if forward_content:
                try:
                    # è§£æåˆå¹¶è½¬å‘å†…å®¹ï¼ˆå¯èƒ½æ˜¯JSONå­—ç¬¦ä¸²æˆ–å¯¹è±¡ï¼‰
                    if isinstance(forward_content, str):
                        import json
                        forward_data = json.loads(forward_content)
                    else:
                        forward_data = forward_content
                    
                    # é€’å½’è§£æè½¬å‘çš„æ¶ˆæ¯
                    if "messages" in forward_data:
                        # éå†è½¬å‘çš„æ¯æ¡æ¶ˆæ¯
                        for forward_msg in forward_data["messages"]:
                            if isinstance(forward_msg, dict):
                                # è§£æå•æ¡è½¬å‘æ¶ˆæ¯
                                sender_name = forward_msg.get("sender", {}).get("name", "æœªçŸ¥ç”¨æˆ·")
                                forward_text, forward_images, _ = parse_onebot_array_msg(forward_msg.get("message", []))
                                
                                if forward_text:
                                    text_content += f"\nã€{sender_name}ã€‘: {forward_text}"
                                # æ£€æŸ¥æ–‡æœ¬ä¸­æ˜¯å¦å·²ç»åŒ…å«å›¾ç‰‡æ ‡è®°ï¼Œé¿å…é‡å¤
                                if forward_images and "[å›¾ç‰‡]" not in forward_text:
                                    text_content += f" [{len(forward_images)}å¼ å›¾ç‰‡]"
                    elif isinstance(forward_data, list):
                        # ç›´æ¥å¤„ç†æ¶ˆæ¯åˆ—è¡¨
                        forward_text, forward_images, _ = parse_onebot_array_msg(forward_data)
                        if forward_text:
                            text_content += f"\nã€è½¬å‘æ¶ˆæ¯ã€‘: {forward_text}"
                        # æ£€æŸ¥æ–‡æœ¬ä¸­æ˜¯å¦å·²ç»åŒ…å«å›¾ç‰‡æ ‡è®°ï¼Œé¿å…é‡å¤
                        if forward_images and "[å›¾ç‰‡]" not in forward_text:
                            text_content += f" [{len(forward_images)}å¼ å›¾ç‰‡]"
                    else:
                        # å¦‚æœå†…å®¹å­˜åœ¨ä½†æ ¼å¼ä¸æ”¯æŒï¼Œæ·»åŠ è½¬å‘IDä¿¡æ¯ä»¥ä¾¿åç»­å¤„ç†
                        if forward_id:
                            text_content += f" [åˆå¹¶è½¬å‘æ¶ˆæ¯(ID:{forward_id})]"
                        else:
                            text_content += " [åˆå¹¶è½¬å‘æ¶ˆæ¯]"
                except Exception as e:
                    # å¦‚æœè§£æå¤±è´¥ï¼Œæ˜¾ç¤ºå ä½ç¬¦
                    if forward_id:
                        text_content += f" [åˆå¹¶è½¬å‘æ¶ˆæ¯(ID:{forward_id})]"
                    else:
                        text_content += " [åˆå¹¶è½¬å‘æ¶ˆæ¯]"
            else:
                # å¦‚æœæ²¡æœ‰å†…å®¹ä½†æœ‰è½¬å‘IDï¼Œæ·»åŠ IDä¿¡æ¯
                if forward_id:
                    text_content += f" [åˆå¹¶è½¬å‘æ¶ˆæ¯(ID:{forward_id})]"
                else:
                    text_content += " [åˆå¹¶è½¬å‘æ¶ˆæ¯]"
            continue

        # ---------------------------
        # Fallback: å¤„ç†æœªçŸ¥æ¶ˆæ¯ç±»å‹
        # ---------------------------
        if msg_type:
            text_content += f" [{msg_type}] "

    return text_content.strip(), image_urls, reply_id
```

```python
# Legacy mapping (classic CQ/CoolQ-style) for the early QQ built-in faces.
QQ_FACE_MAPPING_LEGACY: Dict[str, str] = {
    "0": "æƒŠè®¶",
    "1": "æ’‡å˜´",
    "2": "è‰²",
    "3": "å‘å‘†",
    "4": "å¾—æ„",
    # ...æ›´å¤šä¼ ç»Ÿè¡¨æƒ…æ˜ å°„
}

# "Official" system emoji mapping (EmojiType=1) from QQ Bot OpenAPI docs.
QQ_FACE_MAPPING_OFFICIAL: Dict[str, str] = {
    # Basic
    "4": "å¾—æ„",
    "5": "æµæ³ª",
    "8": "ç¡",
    "9": "å¤§å“­",
    "10": "å°´å°¬",
    # ...æ›´å¤šå®˜æ–¹è¡¨æƒ…æ˜ å°„
}

# Known special face IDs used by some OneBot/CQ implementations.
SPECIAL_FACE_IDS: Dict[str, str] = {
    "358": "éª°å­",
    "359": "çŒœæ‹³",
}


def _resolve_face_desc(face_id: str, raw: Any = None) -> Optional[str]:
    """
    è§£æè¡¨æƒ…IDä¸ºäººç±»å¯è¯»çš„æè¿°
    - æ”¯æŒå¤šç§è¡¨æƒ…æ˜ å°„è¡¨ï¼ˆå®˜æ–¹ã€ä¼ ç»Ÿã€ç”¨æˆ·è‡ªå®šä¹‰ï¼‰
    - æ”¯æŒä»åŸå§‹æ¶ˆæ¯ä¸­æå–è¡¨æƒ…æè¿°
    """
    # 0) Specials (dice/rps) ç‰¹æ®Šè¡¨æƒ…
    if face_id in SPECIAL_FACE_IDS:
        return SPECIAL_FACE_IDS[face_id]

    # 1) Raw payload (most reliable) ä»åŸå§‹æ¶ˆæ¯ä¸­æå–è¡¨æƒ…æè¿°
    raw_desc = _extract_face_desc_from_raw(raw)
    if raw_desc:
        return raw_desc

    # 2) User mapping (highest priority among tables) ç”¨æˆ·è‡ªå®šä¹‰æ˜ å°„
    if face_id in QQ_FACE_MAPPING_USER:
        return QQ_FACE_MAPPING_USER.get(face_id)

    mode = QQ_FACE_MAP_MODE
    if mode not in {"official", "legacy", "auto"}:
        mode = "official"

    # 3) Mapping tables æ ¹æ®æ¨¡å¼é€‰æ‹©æ˜ å°„è¡¨
    if mode == "legacy":
        return QQ_FACE_MAPPING_LEGACY.get(face_id) or QQ_FACE_MAPPING_OFFICIAL.get(face_id)
    if mode == "auto":
        # Try official first (latest desktop QQ), then legacy.
        return QQ_FACE_MAPPING_OFFICIAL.get(face_id) or QQ_FACE_MAPPING_LEGACY.get(face_id)
    # default: official é»˜è®¤ä½¿ç”¨å®˜æ–¹æ˜ å°„è¡¨
    return QQ_FACE_MAPPING_OFFICIAL.get(face_id) or QQ_FACE_MAPPING_LEGACY.get(face_id)


def _format_mface(data: dict) -> str:
    """æ ¼å¼åŒ–QQå•†åŸè¡¨æƒ…ä¸ºæ–‡æœ¬"""
    summary = data.get("summary")
    emoji_id = data.get("emoji_id")
    pkg_id = data.get("emoji_package_id")

    label = None
    if isinstance(summary, str) and summary.strip():
        label = summary.strip()
    elif emoji_id:
        label = f"emoji_id={emoji_id}"
    else:
        label = "mface"

    # Keep package id if present (helps disambiguate) å¦‚æœæœ‰åŒ…IDï¼Œä¿ç•™ä»¥å¸®åŠ©åŒºåˆ†
    if pkg_id:
        return f" [å•†åŸè¡¨æƒ…:{label}; pkg={pkg_id}] "
    return f" [å•†åŸè¡¨æƒ…:{label}] "


def _format_rps_result(result: Any) -> str:
    """çŒœæ‹³ç»“æœæ˜ å°„: 1=çŸ³å¤´, 2=å‰ªåˆ€, 3=å¸ƒ"""
    try:
        r = int(str(result))
    except Exception:
        return str(result)

    return {1: "çŸ³å¤´", 2: "å‰ªåˆ€", 3: "å¸ƒ"}.get(r, str(result))
```
- **åŠŸèƒ½**: è§£æOneBot v11æ¶ˆæ¯æ ¼å¼ï¼Œå°†å¤æ‚çš„æ¶ˆæ¯ç»“æ„è½¬æ¢ä¸ºå¯è¯»æ–‡æœ¬ï¼Œå¤„ç†QQå®˜æ–¹è¡¨æƒ…åŒ…å’Œè‡ªå®šä¹‰è¡¨æƒ…
- **è®¾è®¡æ€è·¯**: 
  - **æ¶ˆæ¯ç±»å‹æ”¯æŒ**: æ”¯æŒæ–‡æœ¬ã€å›¾ç‰‡ã€è¡¨æƒ…ã€å•†åŸè¡¨æƒ…ã€éª°å­ã€çŒœæ‹³ã€æˆ³ä¸€æˆ³ã€@æåŠã€å›å¤ã€è¯­éŸ³ã€è§†é¢‘ã€æ–‡ä»¶ã€å¡ç‰‡æ¶ˆæ¯ã€å°ç¨‹åºã€XMLæ¶ˆæ¯ã€åˆå¹¶è½¬å‘æ¶ˆæ¯ç­‰å¤šç§æ¶ˆæ¯ç±»å‹
  
  - **è¡¨æƒ…æ˜ å°„ç³»ç»Ÿ**: 
    - å†…ç½®å®˜æ–¹å’Œä¼ ç»Ÿä¸¤ç§è¡¨æƒ…æ˜ å°„è¡¨
    - æ”¯æŒç”¨æˆ·è‡ªå®šä¹‰è¡¨æƒ…æ˜ å°„ï¼ˆé€šè¿‡ç¯å¢ƒå˜é‡é…ç½®ï¼‰
    - æ”¯æŒä»åŸå§‹æ¶ˆæ¯ä¸­æå–è¡¨æƒ…æè¿°
    - è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„è¡¨æƒ…æ˜ å°„æ¨¡å¼
  
  - **æ¶ˆæ¯è§£æç­–ç•¥**: 
    - ä¼˜å…ˆå¤„ç†å­—ç¬¦ä¸²å½¢å¼çš„ç‰¹æ®Šæ¶ˆæ¯æ ‡è®°
    - é€’å½’è§£æå¤æ‚çš„æ¶ˆæ¯ç»“æ„ï¼ˆå¦‚åˆå¹¶è½¬å‘æ¶ˆæ¯ï¼‰
    - å¯¹æœªçŸ¥æ¶ˆæ¯ç±»å‹ä¿ç•™å ä½ç¬¦ï¼Œç¡®ä¿æ¶ˆæ¯å†…å®¹ä¸ä¸¢å¤±
    - æä¾›é²æ£’çš„æ¶ˆæ¯è§£æï¼Œé¿å…å› æ¶ˆæ¯æ ¼å¼é—®é¢˜å¯¼è‡´ç¨‹åºå´©æºƒ
  
  - **å…¼å®¹æ€§è®¾è®¡**: 
    - å…¼å®¹ä¸åŒOneBotå®ç°ï¼ˆæ”¯æŒlegacyå’Œofficialä¸¤ç§è¡¨æƒ…æ˜ å°„æ¨¡å¼ï¼‰
    - å¤„ç†å„ç§å¯èƒ½çš„æ¶ˆæ¯æ ¼å¼å˜ä½“
    - æ”¯æŒä»å­—ç¬¦ä¸²ä¸­æå–å›¾ç‰‡URL
  
  - **æ‰©å±•æœºåˆ¶**: 
    - æ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡é…ç½®è¡¨æƒ…æ˜ å°„æ¨¡å¼
    - æ”¯æŒç”¨æˆ·æä¾›è‡ªå®šä¹‰è¡¨æƒ…æ˜ å°„æ–‡ä»¶
- **å½±å“èŒƒå›´**: 
  - æ™ºèƒ½ä½“å¯¹QQæ¶ˆæ¯çš„ç†è§£èƒ½åŠ›ï¼šç›´æ¥å½±å“æ™ºèƒ½ä½“èƒ½å¦æ­£ç¡®ç†è§£ç”¨æˆ·å‘é€çš„å„ç§ç±»å‹æ¶ˆæ¯
  - è¡¨æƒ…åŒ…çš„å¤„ç†å’Œå“åº”è´¨é‡ï¼šå½±å“æ™ºèƒ½ä½“å¯¹è¡¨æƒ…åŒ…çš„è¯†åˆ«å’Œå›åº”
  - ä¸ä¸åŒOneBotå®¢æˆ·ç«¯çš„å…¼å®¹æ€§ï¼šç¡®ä¿æ™ºèƒ½ä½“èƒ½ä¸å„ç§OneBotå®ç°ï¼ˆå¦‚go-cqhttpã€NapCatQQç­‰ï¼‰æ­£å¸¸å·¥ä½œ
  - ç”¨æˆ·ä½“éªŒï¼šç›´æ¥å½±å“æ™ºèƒ½ä½“å¯¹ç”¨æˆ·æ¶ˆæ¯çš„ç†è§£å’Œå›åº”è´¨é‡

# è¡¨æƒ…æ˜ å°„ç³»ç»Ÿçš„é…ç½®
qq_utils.pyæä¾›äº†çµæ´»çš„è¡¨æƒ…æ˜ å°„é…ç½®é€‰é¡¹ï¼š

```python
# ä»ç¯å¢ƒå˜é‡è¯»å–è¡¨æƒ…æ˜ å°„æ¨¡å¼
QQ_FACE_MAP_MODE = os.getenv("QQ_FACE_MAP_MODE", "official").strip().lower()

# å¯é€‰çš„ç”¨æˆ·æä¾›çš„æ˜ å°„æ–‡ä»¶
QQ_FACE_MAPPING_USER: Dict[str, str] = {}
_user_map_path = os.getenv("QQ_FACE_MAPPING_FILE")
if _user_map_path:
    try:
        with open(_user_map_path, "r", encoding="utf-8") as f:
            _obj = json.load(f)
        if isinstance(_obj, dict):
            QQ_FACE_MAPPING_USER = {str(k): str(v) for k, v in _obj.items() if v is not None}
    except Exception:
        QQ_FACE_MAPPING_USER = {}
```
- **åŠŸèƒ½**: æä¾›çµæ´»çš„è¡¨æƒ…æ˜ å°„é…ç½®é€‰é¡¹
- **è®¾è®¡æ€è·¯**: å…è®¸ç”¨æˆ·æ ¹æ®ä¸åŒçš„OneBotå®ç°å’Œéœ€æ±‚é…ç½®è¡¨æƒ…æ˜ å°„
- **å½±å“èŒƒå›´**: è¡¨æƒ…çš„è§£æå’Œæ˜¾ç¤ºæ–¹å¼ï¼Œå½±å“ç”¨æˆ·ä½“éªŒ

## 4. å¼€å‘æŒ‡å—

### 4.1 ç¯å¢ƒæ­å»º

1. **å®‰è£… Python**: ç¡®ä¿å®‰è£… Python 3.11 æˆ–ä»¥ä¸Šç‰ˆæœ¬
2. **åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ**: `python -m venv venv`
3. **æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ**: 
   - Windows: `venv\Scripts\activate`
   - Linux/Mac: `source venv/bin/activate`
4. **å®‰è£…ä¾èµ–**: `pip install -r requirements.txt`
5. **é…ç½®ç¯å¢ƒå˜é‡**: å¤åˆ¶ `.env.example` ä¸º `.env`ï¼Œå¹¶å¡«å…¥ API å¯†é’¥

### 4.2 è¿è¡Œé¡¹ç›®

1. **å¯åŠ¨ OneBot å®¢æˆ·ç«¯**: ç¡®ä¿ OneBot v11 å®¢æˆ·ç«¯å·²é…ç½®å¹¶è¿è¡Œï¼Œåå‘ WebSocket åœ°å€è®¾ç½®ä¸º `ws://127.0.0.1:6199/ws`
2. **å¯åŠ¨ AliceBot**: `python qq_server.py`
3. **éªŒè¯è¿è¡ŒçŠ¶æ€**: æŸ¥çœ‹æ§åˆ¶å°è¾“å‡ºï¼Œç¡®è®¤æœåŠ¡æ­£å¸¸å¯åŠ¨

### 4.3 å¼€å‘æµç¨‹

1. **ç†è§£éœ€æ±‚**: æ˜ç¡®è¦ä¿®æ”¹æˆ–æ·»åŠ çš„åŠŸèƒ½
2. **åˆ†æç°æœ‰ä»£ç **: äº†è§£ç›¸å…³æ¨¡å—çš„ç»“æ„å’Œé€»è¾‘
3. **ä¿®æ”¹ä»£ç **: 
   - éµå¾ªç°æœ‰ä»£ç é£æ ¼
   - ç¡®ä¿ç±»å‹å®‰å…¨
   - æ·»åŠ å¿…è¦çš„æ³¨é‡Š
4. **æµ‹è¯•**: è¿è¡Œé¡¹ç›®ï¼Œæµ‹è¯•ä¿®æ”¹åçš„åŠŸèƒ½
5. **è°ƒè¯•**: å¦‚é‡é—®é¢˜ï¼Œä½¿ç”¨ LangSmith è¿›è¡Œè°ƒè¯•

### 4.4 å¸¸è§ä¿®æ”¹åœºæ™¯

#### ä¿®æ”¹æ™ºèƒ½ä½“äººè®¾

1. ç¼–è¾‘ `app/core/prompts.py` ä¸­çš„æç¤ºè¯
2. ä¿®æ”¹ `app/core/persona/` ç›®å½•ä¸‹çš„äººè®¾æ–‡ä»¶
3. é‡å¯é¡¹ç›®ä½¿ä¿®æ”¹ç”Ÿæ•ˆ

#### æ·»åŠ æ–°å·¥å…·

1. åœ¨ `app/tools/` ç›®å½•ä¸‹åˆ›å»ºæ–°çš„å·¥å…·æ–‡ä»¶
2. ç»§æ‰¿ `BaseTool` ç±»ï¼Œå®ç° `_arun` æ–¹æ³•
3. åœ¨ `app/tools/__init__.py` ä¸­æ³¨å†Œæ–°å·¥å…·
4. é‡å¯é¡¹ç›®ä½¿å·¥å…·ç”Ÿæ•ˆ

#### ä¿®æ”¹å·¥ä½œæµç¨‹

1. ç¼–è¾‘ `app/graph/graph_builder.py`
2. æ·»åŠ æ–°èŠ‚ç‚¹æˆ–ä¿®æ”¹èŠ‚ç‚¹é—´çš„è¿æ¥å…³ç³»
3. é‡å¯é¡¹ç›®ä½¿ä¿®æ”¹ç”Ÿæ•ˆ

### 4.5 è°ƒè¯•æŠ€å·§

1. **LangSmith è°ƒè¯•**: å¯ç”¨ LangSmith è·Ÿè¸ªï¼ŒæŸ¥çœ‹æ™ºèƒ½ä½“çš„å®Œæ•´å·¥ä½œæµç¨‹
2. **æ—¥å¿—è°ƒè¯•**: æŸ¥çœ‹æ§åˆ¶å°è¾“å‡ºï¼Œäº†è§£å„èŠ‚ç‚¹çš„æ‰§è¡Œæƒ…å†µ
3. **çŠ¶æ€æ£€æŸ¥**: åœ¨èŠ‚ç‚¹ä¸­æ·»åŠ æ‰“å°è¯­å¥ï¼Œæ£€æŸ¥çŠ¶æ€å˜åŒ–
4. **åˆ†æ®µæµ‹è¯•**: å•ç‹¬æµ‹è¯•æŸä¸ªèŠ‚ç‚¹çš„åŠŸèƒ½ï¼Œç¡®ä¿å…¶æ­£å¸¸å·¥ä½œ

## 5. ç»´æŠ¤æŒ‡å—

### 5.1 å®šæœŸç»´æŠ¤

1. **æ¸…ç†è®°å¿†**: å®šæœŸæ¸…ç†æ—§çš„æˆ–æ— ç”¨çš„è®°å¿†
2. **æ›´æ–°æ¨¡å‹**: æ ¹æ®éœ€è¦æ›´æ–°è¯­è¨€æ¨¡å‹ï¼Œä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½
3. **å¤‡ä»½æ•°æ®**: å®šæœŸå¤‡ä»½å‘é‡æ•°æ®åº“å’Œå†å²è®°å½•

### 5.2 å¸¸è§é—®é¢˜æ’æŸ¥

| é—®é¢˜ç°è±¡ | å¯èƒ½åŸå›  | è§£å†³æ–¹æ¡ˆ |
|---------|---------|---------|
| æ™ºèƒ½ä½“ä¸å›å¤ | ä¸Šä¸‹æ–‡è¿‡æ»¤å™¨è®¤ä¸ºä¸éœ€è¦å›å¤ | æ£€æŸ¥ `context_filter.py` ä¸­çš„é€»è¾‘ï¼Œè°ƒæ•´å›å¤é˜ˆå€¼ |
| å›å¤è´¨é‡å·® | æ¨¡å‹é…ç½®ä¸å½“æˆ–æç¤ºè¯é—®é¢˜ | è°ƒæ•´æ¨¡å‹å‚æ•°æˆ–ä¿®æ”¹æç¤ºè¯ |
| è®°å¿†ä¸å‡†ç¡® | è®°å¿†ä¿å­˜é€»è¾‘é—®é¢˜ | æ£€æŸ¥ `memory_saver.py` ä¸­çš„ä»£ç ï¼Œç¡®ä¿è®°å¿†æ­£ç¡®ä¿å­˜ |
| å·¥å…·è°ƒç”¨å¤±è´¥ | API å¯†é’¥é—®é¢˜æˆ–ç½‘ç»œé—®é¢˜ | æ£€æŸ¥ API å¯†é’¥é…ç½®ï¼Œç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸ |

### 5.3 æ€§èƒ½ä¼˜åŒ–

1. **æ¨¡å‹ä¼˜åŒ–**: æ ¹æ®ç¡¬ä»¶æ¡ä»¶é€‰æ‹©åˆé€‚çš„æ¨¡å‹å¤§å°
2. **è®°å¿†ä¼˜åŒ–**: è°ƒæ•´è®°å¿†æ£€ç´¢çš„æ•°é‡å’Œè´¨é‡ï¼Œå¹³è¡¡æ€§èƒ½å’Œå‡†ç¡®æ€§
3. **å¹¶è¡Œå¤„ç†**: å……åˆ†åˆ©ç”¨å¹¶è¡Œå¤„ç†å™¨èŠ‚ç‚¹ï¼Œæé«˜å“åº”é€Ÿåº¦
4. **ç¼“å­˜ä¼˜åŒ–**: åˆç†ä½¿ç”¨ç¼“å­˜ï¼Œå‡å°‘é‡å¤è®¡ç®—

## 6. æ‰©å±•å»ºè®®

1. **æ”¯æŒæ›´å¤šé€šä¿¡å¹³å°**: é™¤ QQ å¤–ï¼Œå¯æ‰©å±•æ”¯æŒå¾®ä¿¡ã€Discord ç­‰å¹³å°
2. **å¢å¼ºå¤šæ¨¡æ€èƒ½åŠ›**: æ”¯æŒè¯­éŸ³è¾“å…¥è¾“å‡ºã€è§†é¢‘ç†è§£ç­‰
3. **æ·»åŠ æ›´å¤šå·¥å…·**: æ ¹æ®éœ€æ±‚æ·»åŠ æ–°çš„å·¥å…·ï¼Œå¦‚ç¿»è¯‘ã€æ—¥ç¨‹ç®¡ç†ç­‰
4. **å¢å¼ºæƒ…æ„Ÿç³»ç»Ÿ**: æ”¹è¿›æƒ…æ„Ÿæ¨¡å‹ï¼Œä½¿æƒ…ç»ªå˜åŒ–æ›´åŠ è‡ªç„¶
5. **æ·»åŠ è§’è‰²ç³»ç»Ÿ**: æ”¯æŒåˆ‡æ¢ä¸åŒäººè®¾å’Œè§’è‰²

## 7. æ€»ç»“

AliceBot æ˜¯ä¸€ä¸ªåŠŸèƒ½ä¸°å¯Œã€æ¶æ„æ¸…æ™°çš„æ™ºèƒ½ä½“é¡¹ç›®ï¼ŒåŸºäº LangGraph æ„å»ºäº†å®Œæ•´çš„æ‹ŸäººåŒ–å¿ƒæ™ºæ¨¡å‹ã€‚é€šè¿‡æœ¬æŠ€æœ¯å¼€å‘è¯´æ˜ä¹¦ï¼Œå¸Œæœ›èƒ½å¸®åŠ©å¼€å‘è€…ç†è§£é¡¹ç›®æ¶æ„ã€åŠŸèƒ½æ¨¡å—å’Œå¼€å‘æµç¨‹ï¼Œä»è€Œèƒ½å¤Ÿè¿›è¡Œå¼€å‘ã€ä¿®æ”¹å’Œç»´æŠ¤å·¥ä½œã€‚

é¡¹ç›®é‡‡ç”¨äº†æ¨¡å—åŒ–è®¾è®¡ï¼Œå„ä¸ªæ¨¡å—ä¹‹é—´èŒè´£æ˜ç¡®ï¼Œä¾¿äºæ‰©å±•å’Œä¿®æ”¹ã€‚å¼€å‘è€…å¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹æ™ºèƒ½ä½“çš„äººè®¾ã€å·¥ä½œæµç¨‹ã€å·¥å…·é›†ç­‰ï¼Œæ‰“é€ ä¸ªæ€§åŒ–çš„æ™ºèƒ½ä½“ã€‚

éšç€å¤§è¯­è¨€æ¨¡å‹å’Œæ™ºèƒ½ä½“æŠ€æœ¯çš„ä¸æ–­å‘å±•ï¼ŒAliceBot ä¹Ÿå°†æŒç»­æ¼”è¿›ï¼Œæä¾›æ›´è‡ªç„¶ã€æ›´æ™ºèƒ½çš„äº¤äº’ä½“éªŒã€‚