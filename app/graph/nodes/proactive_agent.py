import json
import time
from datetime import datetime
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from app.core.state import AgentState
from app.core.config import config
from app.core.global_store import global_store
from app.memory.relation_db import relation_db
from app.core.prompts import SOCIAL_VOLITION_PROMPT

# å»ºè®®ä½¿ç”¨é€»è¾‘èƒ½åŠ›è¾ƒå¼ºçš„æ¨¡å‹ (å¦‚ GPT-4o, Qwen-72B)
llm = ChatOpenAI(
    model=config.MODEL_NAME,
    temperature=0.8,  # ç¨å¾®é«˜ä¸€ç‚¹çš„æ¸©åº¦ï¼Œè®©ä¸»åŠ¨å‘è¨€æ›´æœ‰çµæ€§
    api_key=config.SILICONFLOW_API_KEY,
    base_url=config.SILICONFLOW_BASE_URL
)


def _get_time_period(dt: datetime) -> str:
    h = dt.hour
    if 0 <= h < 5: return "æ·±å¤œ/å‡Œæ™¨"
    if 5 <= h < 9: return "æ—©æ™¨"
    if 9 <= h < 12: return "ä¸Šåˆ"
    if 12 <= h < 14: return "ä¸­åˆ"
    if 14 <= h < 18: return "ä¸‹åˆ"
    if 18 <= h < 23: return "æ™šä¸Š"
    return "æ·±å¤œ"


async def proactive_node(state: AgentState):
    """
    ä¸»åŠ¨ç¤¾äº¤å¼•æ“ (Social Volition Engine) - è§†è§‰å¢å¼ºç‰ˆ
    ç»¼åˆåˆ¤æ–­å›¾ç‰‡æ€§è´¨(å®å›¾/è¡¨æƒ…åŒ…)ã€æœ€è¿‘æ–‡æœ¬æ¶ˆæ¯ã€æ²‰é»˜æ—¶é•¿å’Œå¥½æ„Ÿåº¦ã€‚
    """
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{ts}] --- [Proactive] Analyzing Social Context... ---")

    # 1. è·å–åŸºç¡€ä¸Šä¸‹æ–‡
    user_id = state.get("sender_qq", "unknown")
    user_display_name = state.get("sender_name", "User")

    # 2. è®¡ç®—æ²‰é»˜æ—¶é•¿
    last_ts = state.get("last_interaction_ts", time.time())
    now_ts = time.time()
    silence_seconds = now_ts - last_ts

    if silence_seconds < 60:
        silence_str = "åˆšåˆš (ç”¨æˆ·å¯èƒ½è¿˜åœ¨è¾“å…¥ä¸­æˆ–åˆšå‘å®Œæ¶ˆæ¯)"
    elif silence_seconds < 3600:
        silence_str = f"{int(silence_seconds // 60)}åˆ†é’Ÿå‰"
    else:
        silence_str = f"{int(silence_seconds // 3600)}å°æ—¶å‰"

    # 3. æå–æœ€è¿‘çš„ä¸€æ¡æ–‡æœ¬æ¶ˆæ¯
    msgs = state.get("messages", [])
    last_text_content = "æ— æœ€è¿‘æ–‡æœ¬æ¶ˆæ¯"

    # å€’åºæŸ¥æ‰¾æœ€è¿‘ä¸€æ¡ HumanMessage
    for m in reversed(msgs):
        if isinstance(m, HumanMessage):
            content = m.content
            # å¤„ç†å¤šæ¨¡æ€åˆ—è¡¨çš„æƒ…å†µ
            if isinstance(content, list):
                content = next((x['text'] for x in content if x['type'] == 'text'), "[å›¾ç‰‡/æ— æ–‡æœ¬]")
            last_text_content = content
            break

    # 4. è§†è§‰ä¿¡æ¯ (åŸºäº Perception èŠ‚ç‚¹çš„åˆ†ç±»ç»“æœ)
    # image_data ä»…åœ¨ visual_type='photo' æ—¶ç”± perception èŠ‚ç‚¹å¡«å……ï¼Œè¡¨æƒ…åŒ…æ—¶ä¸å¡«å……ä»¥èŠ‚çœå†…å­˜
    image_data = state.get("current_image_artifact")
    visual_type = state.get("visual_type", "none")  # 'photo', 'sticker', 'icon', 'none'

    vision_desc = "æ— å›¾ç‰‡"
    if visual_type == "photo":
        vision_desc = "ã€ç”¨æˆ·å‘é€äº†ä¸€å¼ å«æœ‰å…·ä½“ä¿¡æ¯çš„å›¾ç‰‡/æˆªå›¾ï¼Œè¯·ç»“åˆå›¾ç‰‡å†…å®¹åˆ†æã€‘"
    elif visual_type == "sticker":
        vision_desc = "ã€ç”¨æˆ·å‘é€äº†ä¸€ä¸ªè¡¨æƒ…åŒ…/Stickerï¼Œé€šå¸¸ç”¨äºè¡¨è¾¾æƒ…ç»ªæˆ–ç©ç¬‘ã€‘"

    # 5. æ·±åº¦å…³ç³»æ•°æ®
    profile = relation_db.get_user_profile(user_id)
    rel = profile.relationship

    # 6. å½“å‰æƒ…ç»ªä¸ç¯å¢ƒ
    emotion = global_store.get_emotion_snapshot()
    now_dt = datetime.now()

    # 7. æœ€è¿‘è¯é¢˜æ‘˜è¦
    summary = state.get("conversation_summary", "æ— æœ€è¿‘å¯¹è¯è®°å½•")

    # --- æ„é€  System Prompt ---
    # è¿™é‡Œé€šè¿‡ Prompt æ³¨å…¥æ›´å¤šå³æ—¶ä¿¡æ¯
    prompt = SOCIAL_VOLITION_PROMPT.format(
        current_time=now_dt.strftime("%H:%M"),
        time_period=_get_time_period(now_dt),
        silence_duration=silence_str,
        mood=emotion.primary_emotion,
        stamina=emotion.stamina,
        user_name=user_display_name,
        intimacy=rel.intimacy,
        relation_tags=", ".join(rel.tags) if rel.tags else "æ— ",
        relation_notes=rel.notes or "æ— ",
        vision_desc=vision_desc,
        conversation_summary=summary[-400:] if summary else "æ— "
    )

    input_msgs = [SystemMessage(content=prompt)]

    # --- æ ¸å¿ƒä¿®æ”¹ï¼šæ ¹æ® visual_type æ„å»ºä¸åŒçš„è¾“å…¥ ---

    # åœºæ™¯ A: æœ‰æ„ä¹‰çš„å›¾ç‰‡ (Photo) -> å‘é€ Base64 ç»™ LLM
    if visual_type == "photo" and image_data:
        print("[{ts}] ğŸ” [Proactive] Injecting IMAGE payload for analysis.")
        input_msgs.append(HumanMessage(content=[
            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}},
            {"type": "text",
             "text": f"ç”¨æˆ·åˆšå‘äº†è¿™å¼ å›¾ã€‚ä¸Šä¸€å¥æ–‡æœ¬æ˜¯: '{last_text_content}'ã€‚è¯·åˆ¤æ–­å›¾ç‰‡å†…å®¹æ˜¯å¦é‡è¦ï¼Ÿæˆ‘è¯¥å¦‚ä½•è¯„è®ºï¼Ÿ"}
        ]))

    # åœºæ™¯ B: è¡¨æƒ…åŒ… (Sticker) -> æ‹¦æˆª Base64ï¼Œä»…å‘é€æ–‡æœ¬æç¤º
    elif visual_type == "sticker":
        print("[{ts}] ğŸ­ [Proactive] Handling STICKER (Skipping visual payload).")
        # å‘Šè¯‰ LLM è¿™æ˜¯ä¸ªè¡¨æƒ…åŒ…ï¼Œä¸éœ€è¦æ·±åº¦åˆ†æï¼Œåªéœ€è¦ç¤¾äº¤å›åº”
        sticker_prompt = (
            f"[ç³»ç»Ÿé€šçŸ¥] ç”¨æˆ·å‘é€äº†ä¸€ä¸ªè¡¨æƒ…åŒ… (Sticker)ã€‚\n"
            f"ä¸Šä¸€å¥æ–‡æœ¬æ˜¯: '{last_text_content}'ã€‚\n"
            f"æ— éœ€åˆ†æå›¾ç‰‡å†…å®¹ï¼ˆæœªä¸Šä¼ ï¼‰ã€‚è¯·æ ¹æ®å½“å‰äº²å¯†åº¦ ({rel.intimacy}) å†³å®šæ˜¯å›å¤ä¸€ä¸ªè¡¨æƒ…ã€ç®€çŸ­åæ§½è¿˜æ˜¯ä¿æŒæ²‰é»˜ã€‚"
        )
        input_msgs.append(HumanMessage(content=sticker_prompt))

    # åœºæ™¯ C: æ— å›¾ (çº¯æ–‡æœ¬æˆ–é™é»˜)
    else:
        if silence_seconds < 120:
            # C1: åˆšåˆšèŠè¿‡å¤© -> åˆ¤æ–­æ˜¯å¦è¿½è¯„/æ¥è¯
            user_input_prompt = (
                f"User just said: '{last_text_content}'. "
                f"Context Filter might have ignored it. "
                f"Based on our intimacy ({rel.intimacy}) and the text content, "
                f"should I voluntarily add a comment or follow up? (e.g., comfort, roast, or ask detail)"
            )
        else:
            # C2: æ²‰é»˜å¾ˆä¹… -> åˆ¤æ–­æ˜¯å¦ç ´å†°
            user_input_prompt = (
                f"User has been silent for {silence_str}. "
                f"Last known message was: '{last_text_content}'. "
                f"Should I initiate a NEW conversation based on the time of day or our relationship?"
            )
        input_msgs.append(HumanMessage(content=user_input_prompt))

    try:
        response = await llm.ainvoke(input_msgs)
        content = response.content.strip()

        # JSON æ¸…æ´—
        if "```json" in content:
            content = content.replace("```json", "").replace("```", "")

        # æœ‰äº›æ¨¡å‹å¯èƒ½ä¼šè¾“å‡º Markdown æ ¼å¼ï¼Œå†åŠ ä¸€å±‚æ¸…æ´—
        content = content.strip('`')

        try:
            decision = json.loads(content)
        except:
            print(f"[{ts}] âš ï¸ [Proactive] JSON Parse fail: {content[:30]}...")
            # è¿™é‡Œçš„ fallback ç­–ç•¥å¯ä»¥æ ¹æ®éœ€æ±‚è°ƒæ•´ï¼Œé»˜è®¤ä¿æŒæ²‰é»˜æ¯”è¾ƒå®‰å…¨
            return {"next_step": "silent"}

        intent = decision.get("intent", "silent")
        reply_content = decision.get("content", "")
        reason = decision.get("reason", "")

        print(f"[{ts}] ğŸ¤– [Proactive Decision] {intent.upper()} | Reason: {reason}")

        if intent == "silent" or not reply_content:
            return {"next_step": "silent"}

        # å†³å®šè¯´è¯ -> æ¶ˆè€—ä½“åŠ›
        global_store.update_emotion(0, 0, stamina_delta=-3.0)

        ai_msg = AIMessage(content=reply_content)

        # è¿”å›æ›´æ–°åçš„çŠ¶æ€
        # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨ msgs (ä» state è·å–çš„åˆ—è¡¨) + æ–°æ¶ˆæ¯
        # å…·ä½“æ˜¯è¿”å›å®Œæ•´åˆ—è¡¨è¿˜æ˜¯å¢é‡åˆ—è¡¨å–å†³äºä½ çš„ Graph Reducer å®šä¹‰ï¼Œè¿™é‡Œä¿æŒåŸé€»è¾‘é£æ ¼è¿”å›å®Œæ•´åˆ—è¡¨
        return {
            "messages": msgs + [ai_msg],
            "next_step": "speak",
            "internal_monologue": f"[Social Volition] Intent: {intent}, Reason: {reason}"
        }

    except Exception as e:
        print(f"[{ts}] âŒ [Proactive Error] {e}")
        return {"next_step": "silent"}
