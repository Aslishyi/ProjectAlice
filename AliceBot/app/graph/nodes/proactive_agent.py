import json
import time
import logging
import random
from datetime import datetime
from typing import List, Any, Dict
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from app.core.state import AgentState
from app.core.config import config
from app.core.global_store import global_store
from app.memory.relation_db import relation_db
from app.core.prompts import ALICE_CORE_PERSONA, SOCIAL_VOLITION_PROMPT
from app.utils.cache import cached_llm_invoke
from app.memory.vector_store import vector_db as vector_store

# é…ç½®æ—¥å¿—
logger = logging.getLogger("ProactiveAgent")

# ä¸»åŠ¨äº¤äº’é…ç½®
PROACTIVE_CONFIG = {
    # æ´»è·ƒæ—¶é—´çª—å£ï¼ˆå°æ—¶ï¼‰
    "active_time_windows": [
        (9, 12),    # ä¸Šåˆ
        (14, 17),   # ä¸‹åˆ
        (19, 22)    # æ™šä¸Š
    ],
    # æœ€å°æ²‰é»˜æ—¶é•¿ï¼ˆå°æ—¶ï¼‰
    "min_silence_hours": 1,
    # æœ€å¤§æ²‰é»˜æ—¶é•¿ï¼ˆå°æ—¶ï¼‰
    "max_silence_hours": 24,
    # åŸºç¡€è§¦å‘æ¦‚ç‡
    "base_chance": 0.3,
    # ç”¨æˆ·åé¦ˆå½±å“å› å­
    "feedback_factor": 0.2,
    # ä¸ªæ€§åŒ–è¯é¢˜æƒé‡
    "topic_relevance_weight": 0.7,
    # äººè®¾ä¸€è‡´æ€§è¿‡æ»¤é˜ˆå€¼
    "persona_consistency_threshold": 0.8
}

# å»ºè®®ä½¿ç”¨é€»è¾‘èƒ½åŠ›è¾ƒå¼ºçš„æ¨¡å‹
llm = ChatOpenAI(
    model=config.MODEL_NAME,
    temperature=0.6,  # é™ä½æ¸©åº¦ï¼Œè®©ä¸»åŠ¨å‘è¨€æ›´ç¬¦åˆäººè®¾ï¼Œé¿å…è¿‡äºæ´»æ³¼
    api_key=config.MODEL_API_KEY,
    base_url=config.MODEL_URL
)

class ProactiveInteractionManager:
    def __init__(self):
        self.logger = logger
        self.feedback_store = {}
        
    def is_in_active_time_window(self) -> bool:
        """æ£€æŸ¥å½“å‰æ—¶é—´æ˜¯å¦åœ¨æ´»è·ƒçª—å£å†…"""
        current_hour = datetime.now().hour
        for start, end in PROACTIVE_CONFIG["active_time_windows"]:
            if start <= current_hour < end:
                return True
        return False
    
    def should_initiate_interaction(self, user_id: str, last_interaction_time: float, user_feedback_score: float, intimacy: int, familiarity: int, trust: int, interest_match: int, stamina: float, interaction_patterns: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å‘èµ·ä¸»åŠ¨äº¤äº’"""
        # 1. æ£€æŸ¥å½“å‰æ—¶é—´æ˜¯å¦åœ¨æ´»è·ƒçª—å£å†…
        if not self.is_in_active_time_window():
            self.logger.debug("ä¸åœ¨æ´»è·ƒæ—¶é—´çª—å£å†…ï¼Œè·³è¿‡ä¸»åŠ¨äº¤äº’")
            return False
        
        # 2. æ£€æŸ¥ä½“åŠ›å€¼
        if stamina < 20:
            self.logger.debug(f"ä½“åŠ›å€¼è¿‡ä½ ({stamina:.1f})ï¼Œè·³è¿‡ä¸»åŠ¨äº¤äº’")
            return False
        
        # 3. è®¡ç®—æ²‰é»˜æ—¶é•¿
        silence_hours = (time.time() - last_interaction_time) / 3600
        
        # 4. æ£€æŸ¥æ²‰é»˜æ—¶é•¿æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…
        if silence_hours < PROACTIVE_CONFIG["min_silence_hours"] or silence_hours > PROACTIVE_CONFIG["max_silence_hours"]:
            self.logger.debug(f"æ²‰é»˜æ—¶é•¿ ({silence_hours:.1f}å°æ—¶) ä¸åœ¨åˆç†èŒƒå›´ï¼Œè·³è¿‡ä¸»åŠ¨äº¤äº’")
            return False
        
        # 5. è·å–ç”¨æˆ·äº¤äº’æ¨¡å¼åå¥½
        preferred_response_time = interaction_patterns.get("preferred_response_time", None)
        current_hour = datetime.now().hour
        
        # æ£€æŸ¥æ˜¯å¦åœ¨ç”¨æˆ·åå¥½çš„å›å¤æ—¶é—´æ®µå†…
        if preferred_response_time:
            # å‡è®¾preferred_response_timeæ ¼å¼ä¸º [start_hour, end_hour]
            if not (preferred_response_time[0] <= current_hour < preferred_response_time[1]):
                self.logger.debug(f"å½“å‰æ—¶é—´ä¸åœ¨ç”¨æˆ·åå¥½çš„å›å¤æ—¶é—´æ®µå†…ï¼Œè·³è¿‡ä¸»åŠ¨äº¤äº’")
                return False
        
        # 6. è®¡ç®—è§¦å‘æ¦‚ç‡
        base_probability = PROACTIVE_CONFIG["base_chance"]
        
        # åŸºäºå…³ç³»äº²å¯†åº¦çš„è°ƒæ•´
        intimacy_factor = 0.5 + (intimacy / 100)  # 0.5-1.5
        
        # åŸºäºç†Ÿæ‚‰åº¦çš„è°ƒæ•´
        familiarity_factor = 0.8 + (familiarity / 500)  # 0.8-1.0
        
        # åŸºäºä¿¡ä»»åº¦çš„è°ƒæ•´
        trust_factor = 0.8 + (trust / 500)  # 0.8-1.0
        
        # åŸºäºå…´è¶£åŒ¹é…åº¦çš„è°ƒæ•´
        interest_factor = 0.5 + (interest_match / 100)  # 0.5-1.5
        
        # åŸºäºæ²‰é»˜æ—¶é•¿çš„æ¦‚ç‡è°ƒæ•´ï¼ˆæ›´æ™ºèƒ½çš„æ›²çº¿ï¼‰
        if silence_hours < 6:
            # çŸ­æ—¶é—´æ²‰é»˜ï¼šæ¦‚ç‡éšæ—¶é—´çº¿æ€§å¢åŠ ï¼Œä½†å—äº²å¯†åº¦å½±å“
            silence_factor = min(1.5, (silence_hours / PROACTIVE_CONFIG["min_silence_hours"]) * intimacy_factor)
        elif silence_hours < 12:
            # ä¸­ç­‰æ—¶é—´æ²‰é»˜ï¼šä¿æŒè¾ƒé«˜æ¦‚ç‡
            silence_factor = 1.2 * intimacy_factor
        else:
            # é•¿æ—¶é—´æ²‰é»˜ï¼šæ¦‚ç‡é€æ¸é™ä½ï¼Œä½†å—ç†Ÿæ‚‰åº¦å’Œä¿¡ä»»åº¦å½±å“
            silence_factor = max(0.5, (1 - (silence_hours - 12) / 24) * (familiarity_factor + trust_factor) / 2)
        
        # ç”¨æˆ·åé¦ˆè°ƒæ•´ï¼Œæƒé‡æ›´é«˜
        feedback_factor = 1 + (user_feedback_score * PROACTIVE_CONFIG["feedback_factor"] * 1.5)
        
        # ç»¼åˆæ‰€æœ‰å› å­
        final_probability = base_probability * silence_factor * feedback_factor * interest_factor
        
        # æ ¹æ®å…³ç³»é˜¶æ®µè°ƒæ•´æœ€ç»ˆæ¦‚ç‡
        if intimacy < 30:
            # ä½äº²å¯†åº¦ç”¨æˆ·ï¼šé™ä½è§¦å‘æ¦‚ç‡
            final_probability *= 0.7
        elif intimacy > 70:
            # é«˜äº²å¯†åº¦ç”¨æˆ·ï¼šé€‚å½“æé«˜è§¦å‘æ¦‚ç‡
            final_probability *= 1.2
        
        # é™åˆ¶æ¦‚ç‡èŒƒå›´
        final_probability = max(0.03, min(0.85, final_probability))
        
        # 7. éšæœºåˆ¤æ–­æ˜¯å¦è§¦å‘
        if random.random() < final_probability:
            self.logger.debug(f"è§¦å‘ä¸»åŠ¨äº¤äº’ï¼Œæ¦‚ç‡: {final_probability:.2f}")
            return True
        
        return False
    
    def _check_topic_relevance(self, topic: str, favorite_topics: List[str], avoid_topics: List[str]) -> bool:
        """æ£€æŸ¥è¯é¢˜ç›¸å…³æ€§å’Œæ˜¯å¦ä¸ºé¿å…è¯é¢˜"""
        # 1. æ£€æŸ¥æ˜¯å¦ä¸ºé¿å…è¯é¢˜
        if avoid_topics:
            for avoid_topic in avoid_topics:
                if avoid_topic in topic:
                    return False
        
        # 2. æ£€æŸ¥æ˜¯å¦ä¸å…´è¶£è¯é¢˜ç›¸å…³
        if favorite_topics:
            for fav_topic in favorite_topics:
                if fav_topic in topic:
                    return True
        
        # 3. é»˜è®¤è¿”å›Trueï¼ˆå…è®¸ä½¿ç”¨ï¼‰
        return True
    
    def _score_topic_relevance(self, topic: str, favorite_topics: List[str], memory_topics: List[str]) -> float:
        """ä¸ºè¯é¢˜æ‰“åˆ†ï¼Œè¯„ä¼°å…¶ç›¸å…³æ€§"""
        score = 0.5  # åŸºç¡€åˆ†æ•°
        
        # ä¸å…´è¶£è¯é¢˜åŒ¹é…åº¦
        if favorite_topics:
            for fav_topic in favorite_topics:
                if fav_topic in topic:
                    score += 0.3
        
        # ä¸è®°å¿†ç‚¹åŒ¹é…åº¦
        if memory_topics:
            for mem_topic in memory_topics:
                if mem_topic in topic:
                    score += 0.2
        
        return min(1.0, score)
    
    async def get_personalized_topics(self, user_id: str, limit: int = 5) -> List[str]:
        """è·å–ä¸ªæ€§åŒ–è¯é¢˜åˆ—è¡¨"""
        try:
            # è·å–ç”¨æˆ·å…³ç³»æ•°æ®
            profile = await relation_db.get_user_profile(user_id)
            rel = profile.relationship
            
            # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æ„Ÿå…´è¶£çš„è¯é¢˜
            favorite_topics = rel.favorite_topics.copy()
            avoid_topics = rel.avoid_topics.copy()
            
            # è·å–ç”¨æˆ·è®°å¿†ç‚¹
            memory_points = rel.memory_points
            memory_topics = []
            
            # è§£æè®°å¿†ç‚¹ï¼Œè¿‡æ»¤å‡ºå…´è¶£çˆ±å¥½å’Œæ—¥å¸¸è¯é¢˜ç›¸å…³çš„å†…å®¹
            for mp in memory_points:
                if isinstance(mp, str):
                    parts = mp.split(":")
                    if len(parts) >= 3:
                        category, content, weight = parts[0], ":".join(parts[1:-1]), float(parts[-1])
                        # åªä¿ç•™é«˜æƒé‡çš„è®°å¿†ç‚¹
                        if weight > 0.5 and category in ["å…´è¶£çˆ±å¥½", "å…±åŒç»å†", "æ—¥å¸¸è¯é¢˜"]:
                            memory_topics.append((content.strip(), weight))
            
            # å¯¹è®°å¿†ç‚¹æŒ‰æƒé‡æ’åº
            memory_topics.sort(key=lambda x: x[1], reverse=True)
            memory_topic_texts = [topic for topic, weight in memory_topics]
            
            # ä»å‘é‡å­˜å‚¨ä¸­è·å–ç›¸å…³è®°å¿†ç‚¹ï¼Œä½¿ç”¨ç”¨æˆ·çš„å…´è¶£ä½œä¸ºæŸ¥è¯¢
            vector_query = " ".join(favorite_topics[:3]) if favorite_topics else "æ—¥å¸¸è¯é¢˜"
            vector_memories = await vector_store.search(
                query=vector_query,
                k=10,
                categories=["å…´è¶£çˆ±å¥½", "å…±åŒç»å†", "æ—¥å¸¸è¯é¢˜"]
            )
            
            vector_topics = []
            if vector_memories:
                for memory in vector_memories:
                    if memory.content and len(memory.content) > 5:
                        vector_topics.append(memory.content)
            
            # åˆå¹¶æ‰€æœ‰è¯é¢˜æºå¹¶æ‰“åˆ†
            all_topic_candidates = []
            
            # 1. ä¼˜å…ˆæ·»åŠ ç”¨æˆ·æ„Ÿå…´è¶£çš„è¯é¢˜
            for topic in favorite_topics:
                if topic and self._check_topic_relevance(topic, favorite_topics, avoid_topics):
                    relevance_score = self._score_topic_relevance(topic, favorite_topics, memory_topic_texts)
                    all_topic_candidates.append((topic, relevance_score, "favorite"))
            
            # 2. æ·»åŠ è®°å¿†ç‚¹è¯é¢˜
            for topic in memory_topic_texts:
                if topic and self._check_topic_relevance(topic, favorite_topics, avoid_topics):
                    relevance_score = self._score_topic_relevance(topic, favorite_topics, memory_topic_texts)
                    all_topic_candidates.append((topic, relevance_score, "memory"))
            
            # 3. æ·»åŠ å‘é‡å­˜å‚¨è¯é¢˜
            for topic in vector_topics:
                if topic and self._check_topic_relevance(topic, favorite_topics, avoid_topics):
                    relevance_score = self._score_topic_relevance(topic, favorite_topics, memory_topic_texts)
                    all_topic_candidates.append((topic, relevance_score, "vector"))
            
            # 4. å¦‚æœè¯é¢˜ä¸å¤Ÿï¼Œä½¿ç”¨é»˜è®¤è¯é¢˜ï¼ˆç»è¿‡é¿å…è¯é¢˜è¿‡æ»¤ï¼‰
            default_topics = [
                "æœ€è¿‘æœ‰æ²¡æœ‰è¯»åˆ°ä»€ä¹ˆæœ‰æ„æ€çš„ä¹¦ï¼Ÿ",
                "é™„è¿‘æ–°å¼€äº†å®¶å’–å•¡é¦†ï¼Œç¯å¢ƒæŒºå®‰é™çš„...",
                "æ—§ä¹¦åº—æ‰“æŠ˜ï¼Œä½ æœ‰æƒ³å»çœ‹çœ‹å—ï¼Ÿ",
                "ä»Šå¤©å¤©æ°”ä¸é”™ï¼Œé€‚åˆå‡ºé—¨æ•£æ­¥å‘¢",
                "æœ€è¿‘æ€»æ˜¯ç¡ä¸å¤Ÿï¼Œä½ ä¹Ÿè¿™æ ·å—ï¼Ÿ",
                "å¬è¯´æœ‰éƒ¨è€ç”µå½±é‡æ˜ äº†ï¼Œå¥½åƒè¿˜ä¸é”™",
                "æ˜¨å¤©åœ¨å’–å•¡é¦†çœ‹åˆ°ä¸€åªå¾ˆå¯çˆ±çš„çŒ«",
                "æœ€è¿‘åœ¨å¬ä¸€äº›è€æ­Œï¼Œçªç„¶è§‰å¾—ä»¥å‰çš„æ­Œæ›´æœ‰å‘³é“",
                "ä½ å¹³æ—¶å–œæ¬¢å»å“ªäº›å®‰é™çš„åœ°æ–¹ï¼Ÿ",
                "ä»Šå¤©å°è¯•åšäº†æ‰‹å†²å’–å•¡ï¼Œè™½ç„¶å‘³é“ä¸€èˆ¬..."
            ]
            
            # è¿‡æ»¤é»˜è®¤è¯é¢˜ï¼Œé¿å…ä½¿ç”¨ç”¨æˆ·ä¸å–œæ¬¢çš„è¯é¢˜
            filtered_defaults = []
            for topic in default_topics:
                if self._check_topic_relevance(topic, favorite_topics, avoid_topics):
                    relevance_score = self._score_topic_relevance(topic, favorite_topics, memory_topic_texts)
                    filtered_defaults.append((topic, relevance_score, "default"))
            
            # æ·»åŠ é»˜è®¤è¯é¢˜å€™é€‰
            all_topic_candidates.extend(filtered_defaults)
            
            # å»é‡
            seen_topics = set()
            unique_candidates = []
            for topic, score, source in all_topic_candidates:
                if topic not in seen_topics:
                    seen_topics.add(topic)
                    unique_candidates.append((topic, score, source))
            
            # æŒ‰ç›¸å…³æ€§åˆ†æ•°æ’åº
            unique_candidates.sort(key=lambda x: x[1], reverse=True)
            
            # é€‰æ‹©å‰limitä¸ªè¯é¢˜
            result_topics = [topic for topic, score, source in unique_candidates[:limit]]
            
            # ç¡®ä¿å¤šæ ·æ€§ï¼šæœ€å¤šå…è®¸2ä¸ªç›¸åŒæ¥æºçš„è¯é¢˜
            source_count = {}
            diverse_topics = []
            for topic, score, source in unique_candidates:
                if source_count.get(source, 0) < 2:
                    diverse_topics.append(topic)
                    source_count[source] = source_count.get(source, 0) + 1
                    if len(diverse_topics) >= limit:
                        break
            
            # å¦‚æœå¤šæ ·æ€§è¯é¢˜ä¸è¶³ï¼Œä½¿ç”¨åŸå§‹æ’åºçš„è¯é¢˜è¡¥å……
            if len(diverse_topics) < limit:
                for topic in result_topics:
                    if topic not in diverse_topics:
                        diverse_topics.append(topic)
                        if len(diverse_topics) >= limit:
                            break
            
            return diverse_topics[:limit]
        except Exception as e:
            self.logger.error(f"è·å–ä¸ªæ€§åŒ–è¯é¢˜å¤±è´¥: {e}")
            return []
    
    def update_user_feedback(self, user_id: str, feedback_type: str):
        """æ›´æ–°ç”¨æˆ·åé¦ˆï¼ˆpositive/negativeï¼‰"""
        if user_id not in self.feedback_store:
            self.feedback_store[user_id] = {"positive": 0, "negative": 0, "last_updated": time.time()}
        
        # æ›´æ–°åé¦ˆè®¡æ•°
        if feedback_type == "positive":
            self.feedback_store[user_id]["positive"] += 1
        elif feedback_type == "negative":
            self.feedback_store[user_id]["negative"] += 1
        
        self.feedback_store[user_id]["last_updated"] = time.time()
    
    def get_user_feedback_score(self, user_id: str) -> float:
        """è·å–ç”¨æˆ·åé¦ˆåˆ†æ•°ï¼ˆ-1åˆ°1ä¹‹é—´ï¼‰"""
        if user_id not in self.feedback_store:
            return 0.0
        
        feedback = self.feedback_store[user_id]
        total = feedback["positive"] + feedback["negative"]
        if total == 0:
            return 0.0
        
        # è®¡ç®—åé¦ˆåˆ†æ•°ï¼ˆpositive - negativeï¼‰/ total
        score = (feedback["positive"] - feedback["negative"]) / total
        return score

# åˆå§‹åŒ–ä¸»åŠ¨äº¤äº’ç®¡ç†å™¨
interaction_manager = ProactiveInteractionManager()

def _filter_unnatural_responses(content: str) -> str:
    """è¿‡æ»¤ä¸ç¬¦åˆAliceäººè®¾çš„ä¸è‡ªç„¶å›åº”"""
    # Aliceçš„æ ¸å¿ƒæ€§æ ¼ï¼šäº‘æ·¡é£è½»ã€æ³¢æ¾œä¸æƒŠã€ä¸åˆ»æ„ã€ä¸è®¨å¥½
    
    # 1. ç§»é™¤è¿‡äºæ­£å¼çš„è¡¨è¾¾
    formal_phrases = [
        "å¾ˆé«˜å…´è®¤è¯†ä½ ", "ä¹æ„æ•ˆåŠ³", "æ ¹æ®æˆ‘çš„çŸ¥è¯†", "æˆ‘è®¤ä¸º", "æˆ‘è§‰å¾—",
        "ä½ å¥½", "åœ¨å—", "è¯·é—®", "æ„Ÿè°¢", "è°¢è°¢", "å¯¹ä¸èµ·", "æŠ±æ­‰",
        "è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„", "éšæ—¶ä¸ºä½ æœåŠ¡", "æˆ‘æ¥å¸®ä½ ",
        "æˆ‘æ˜ç™½äº†", "æˆ‘ç†è§£", "ä½ è¯´å¾—å¯¹", "ç¡®å®å¦‚æ­¤"
    ]
    
    filtered_content = content
    for phrase in formal_phrases:
        if phrase in filtered_content:
            filtered_content = filtered_content.replace(phrase, "")
    
    # 2. ç§»é™¤è¿‡äºäº²å¯†çš„è¡¨è¾¾
    intimate_phrases = [
        "äº²çˆ±çš„", "å®è´", "è€å…¬", "è€å©†", "å“¥å“¥", "å§å§", "å¼Ÿå¼Ÿ", "å¦¹å¦¹",
        "æˆ‘çˆ±ä½ ", "æˆ‘æƒ³ä½ ", "æ€å¿µä½ ", "å–œæ¬¢ä½ ", "æŠ±æŠ±", "äº²äº²",
        "æƒ³ä½ å•¦", "çˆ±ä½ ", "æˆ‘çš„", "ä¸“å±", "å”¯ä¸€"
    ]
    
    for phrase in intimate_phrases:
        if phrase in filtered_content:
            filtered_content = filtered_content.replace(phrase, "")
    
    # 3. ç§»é™¤åˆ»æ„å¼•å¯¼å¯¹è¯çš„è¡¨è¾¾
    guiding_phrases = [
        "é‚£ä½ å‘¢", "ä½ è§‰å¾—å‘¢", "æœ‰ä»€ä¹ˆæƒ³æ³•", "åˆ†äº«ç»™æˆ‘å¬å¬",
        "æœ‰ä»€ä¹ˆæ„Ÿå—", "è§‰å¾—æ€ä¹ˆæ ·", "éšæ—¶æ¥æ‰¾æˆ‘èŠèŠå“¦",
        "å¯¹å§", "æ˜¯ä¸æ˜¯", "å¯¹å—", "å¥½ä¸å¥½", "å¯ä»¥å—",
        "æ€ä¹ˆæ ·", "å‘¢",  # æ³¨æ„ï¼šåªç§»é™¤ä½œä¸ºç–‘é—®è¯çš„"å‘¢"ï¼Œä¿ç•™ä½œä¸ºè¯­æ°”è¯çš„"å‘¢"
    ]
    
    for phrase in guiding_phrases:
        if filtered_content.endswith(phrase):
            filtered_content = filtered_content[:-len(phrase)]
        elif f"{phrase}" in filtered_content:
            filtered_content = filtered_content.replace(f" {phrase}", "")
    
    # 4. ç§»é™¤æ„Ÿå¹å·å’Œé—®å·ï¼ˆAliceå¾ˆå°‘ç”¨å¼ºçƒˆçš„æ ‡ç‚¹ï¼‰
    filtered_content = filtered_content.replace("!", "...")
    filtered_content = filtered_content.replace("?", "...")
    
    # 5. ç§»é™¤è¿‡é•¿çš„å¥å­ï¼ˆä¿æŒç®€çŸ­ï¼‰
    sentences = filtered_content.split("ã€‚")
    short_sentences = []
    for sentence in sentences:
        sentence = sentence.strip()
        if sentence and len(sentence) < 25:  # æ›´ä¸¥æ ¼çš„é•¿åº¦é™åˆ¶
            short_sentences.append(sentence)
    
    filtered_content = "ã€‚".join(short_sentences)
    
    # 6. ç¡®ä¿å†…å®¹ç¬¦åˆAliceçš„è¯´è¯é£æ ¼
    filtered_content = filtered_content.strip()
    if not filtered_content:
        return ""
    
    # 7. æ·»åŠ é€‚å½“çš„è¯­æ°”è¯ï¼ˆç¬¦åˆäº‘æ·¡é£è½»çš„é£æ ¼ï¼‰
    valid_endings = ["...", "å‘¢", "å‘€", "å“¦", "å—¯", ""]
    if not any(filtered_content.endswith(ending) for ending in valid_endings):
        filtered_content += random.choice(["...", "å“¦", ""])
    
    # 8. ç¡®ä¿å¥å­ç®€çŸ­ï¼ˆæœ€å¤š25å­—ï¼‰
    if len(filtered_content) > 25:
        filtered_content = filtered_content[:25] + "..."
    
    return filtered_content

def _ensure_alice_persona(content: str, intimacy: int) -> str:
    """ç¡®ä¿å†…å®¹ç¬¦åˆAliceçš„äººè®¾"""
    # Aliceçš„æ ¸å¿ƒç‰¹ç‚¹ï¼šç®€çŸ­ã€äº‘æ·¡é£è½»ã€é¿å…éº»çƒ¦ã€ä¸åˆ»æ„
    
    # 1. åˆæ­¥è¿‡æ»¤
    filtered_content = _filter_unnatural_responses(content)
    if not filtered_content:
        return ""
    
    # 2. ä¿æŒå¥å­æ•°é‡é™åˆ¶ï¼ˆæœ€å¤šä¸¤å¥è¯ï¼‰
    lines = filtered_content.split("ã€‚")
    filtered_lines = []
    
    for line in lines:
        line = line.strip()
        if line:
            filtered_lines.append(line)
    
    if not filtered_lines:
        return ""
    
    # æœ€å¤šä¸¤å¥è¯
    result = "ã€‚".join(filtered_lines[:2])
    
    # 3. æ ¹æ®äº²å¯†åº¦è°ƒæ•´è¯­æ°”ï¼ˆæ›´ç»†è…»çš„è°ƒæ•´ï¼‰
    if intimacy > 85:
        # æé«˜äº²å¯†åº¦ï¼šå¯ä»¥ç¨å¾®éšæ„ä¸€ç‚¹ï¼Œä½†ä»ç„¶ä¿æŒäº‘æ·¡é£è½»
        result = result.replace("...", "~").replace("å“¦", "å“¦~")
        # å¯ä»¥æ·»åŠ ä¸€äº›è½»å¾®çš„äº²æ˜µè¯­æ°”è¯
        if not any(result.endswith(ending) for ending in ["~", "å“¦~", "å‘¢"]):
            result += "~"
    elif intimacy > 70:
        # é«˜äº²å¯†åº¦ï¼šä¿æŒè‡ªç„¶ï¼Œç•¥å¾®éšæ„
        result = result.replace("...", "~").replace("å“¦", "å“¦~")
    elif intimacy < 35:
        # ä½äº²å¯†åº¦ï¼šä¿æŒè·ç¦»æ„Ÿï¼Œæ›´å†·æ·¡
        result = result.replace("~", "...").replace("å‘€", "å“¦").replace("å“¦~", "å“¦")
        # ç§»é™¤è¿‡äºæ´»æ³¼çš„è¯­æ°”è¯
        result = result.replace("å“ˆ", "").replace("å˜¿", "")
    elif intimacy < 20:
        # æä½äº²å¯†åº¦ï¼šéå¸¸å†·æ·¡ï¼Œå°½é‡ç®€çŸ­
        result = result.replace("~", "...").replace("å‘€", "").replace("å“¦~", "")
        # åªä¿ç•™æœ€æ ¸å¿ƒçš„å†…å®¹
        if len(result) > 15:
            result = result[:15] + "..."
    
    # 4. æœ€ç»ˆè¿‡æ»¤ï¼Œç¡®ä¿ç¬¦åˆAliceçš„æ ¸å¿ƒé£æ ¼
    final_content = _filter_unnatural_responses(result)
    
    # 5. ç¡®ä¿å†…å®¹ä¸æ˜¯åˆ»æ„çš„æé—®æˆ–å¼•å¯¼
    if any(final_content.endswith(ending) for ending in ["...?", "?", "å‘¢", "å—", "å§"]):
        # è½¬æ¢ä¸ºé™ˆè¿°å¥
        final_content = final_content[:-1] + "..."
    
    # 6. æ·»åŠ ä¸€äº›Aliceç‰¹æœ‰çš„è¯´è¯ä¹ æƒ¯ï¼ˆå¶å°”çš„é”™åˆ«å­—æˆ–çœç•¥ï¼‰
    alice_mannerisms = [
        lambda x: x.replace("ä»€ä¹ˆ", "å•¥"),
        lambda x: x.replace("æ€ä¹ˆ", "å’‹"),
        lambda x: x.replace("æ²¡æœ‰", "æ²¡"),
        lambda x: x.replace("æ˜¯ä¸æ˜¯", "æ˜¯ä¸"),
        lambda x: x  # ä¸ä¿®æ”¹
    ]
    
    # éšæœºåº”ç”¨ä¸€ä¸ªè¯´è¯ä¹ æƒ¯ï¼ˆ30%æ¦‚ç‡ï¼‰
    if random.random() < 0.3:
        final_content = random.choice(alice_mannerisms)(final_content)
    
    return final_content

async def _generate_proactive_content(user_id: str, topics: List[str], intimacy: int, current_time: str, silence_duration: str, stamina: float, chat_type: str, user_name: str, familiarity: int, trust: int, interest_match: int, communication_style: str) -> str:
    """ç”Ÿæˆç¬¦åˆäººè®¾çš„ä¸»åŠ¨äº¤äº’å†…å®¹"""
    if not topics:
        return ""
    
    try:
        # éšæœºé€‰æ‹©ä¸€ä¸ªè¯é¢˜ï¼Œä½†åŸºäºè¯é¢˜çš„ç›¸å…³æ€§å’Œå¤šæ ·æ€§
        selected_topic = random.choice(topics)
        
        # è·å–ç”¨æˆ·å…³ç³»æ•°æ®ï¼Œç”¨äºæ„å»ºæ›´ä¸ªæ€§åŒ–çš„prompt
        profile = await relation_db.get_user_profile(user_id)
        rel = profile.relationship
        
        # ç”Ÿæˆå½“å‰æƒ…ç»ªçŠ¶æ€ï¼ŒåŸºäºç”¨æˆ·çš„æƒ…æ„Ÿè¶‹åŠ¿
        sentiment_trends = rel.sentiment_trends
        current_mood = "å¹³é™"
        
        # åˆ†ææœ€è¿‘çš„æƒ…æ„Ÿè¶‹åŠ¿
        if sentiment_trends:
            # è·å–æœ€è¿‘5æ¡æƒ…æ„Ÿè®°å½•
            recent_sentiments = sentiment_trends[-5:]
            # è®¡ç®—ç§¯æ/æ¶ˆææƒ…æ„Ÿçš„æ¯”ä¾‹
            positive_count = sum(1 for trend in recent_sentiments if trend.get("sentiment") in ["å¼€å¿ƒ", "æ„‰å¿«", "å…´é«˜é‡‡çƒˆ"])
            negative_count = sum(1 for trend in recent_sentiments if trend.get("sentiment") in ["ä½è½", "æ²®ä¸§", "çƒ¦èº"])
            
            if positive_count > negative_count:
                current_mood = "æ„‰å¿«"
            elif negative_count > positive_count:
                current_mood = "ä½è½"
        
        # å¡«å……SOCIAL_VOLITION_PROMPTæ‰€éœ€çš„å‚æ•°
        prompt = SOCIAL_VOLITION_PROMPT.format(
            alice_core_persona=ALICE_CORE_PERSONA,
            current_time=current_time,
            time_period="ä¸Šåˆ" if 9 <= int(current_time.split(":")[0]) < 12 else "ä¸‹åˆ" if 12 <= int(current_time.split(":")[0]) < 18 else "æ™šä¸Š",
            silence_duration=silence_duration,
            mood=current_mood,
            stamina=stamina,
            chat_type=chat_type,
            user_name=user_name,
            intimacy=intimacy,
            familiarity=familiarity,
            trust=trust,
            interest_match=interest_match,
            relation_tags=", ".join(rel.tags) if rel.tags else "",
            relation_notes=rel.notes if rel.notes else "",
            vision_desc="æ— ",  # ä¸»åŠ¨å‘èµ·æ—¶é€šå¸¸æ²¡æœ‰å›¾ç‰‡
            personalized_info=f"æ„Ÿå…´è¶£çš„è¯é¢˜: {selected_topic}ï¼Œç”¨æˆ·æ²Ÿé€šé£æ ¼: {communication_style}",
            conversation_summary=f"æœ€è¿‘çš„è¯é¢˜: {selected_topic}"
        )
        
        # ä½¿ç”¨åŠ¨æ€äººè®¾ç®¡ç†ç³»ç»Ÿæ„å»ºæ›´ä¸°å¯Œçš„prompt
        from app.core.prompts import build_prompt_with_persona
        contextual_prompt = await build_prompt_with_persona(
            core_persona=prompt,
            context=f"å½“å‰æ­£åœ¨ä¸{user_name}è¿›è¡Œä¸»åŠ¨äº¤äº’ï¼Œè¯é¢˜æ˜¯{selected_topic}",
            scene=chat_type,
            emotion=current_mood,
            relation=f"å¥½æ„Ÿåº¦{intimacy}/100",
            max_extended_items=3,
            max_contextual_items=2
        )
        
        # æ ¹æ®æ²Ÿé€šé£æ ¼è°ƒæ•´temperature
        temperature = 0.5
        if communication_style == "playful":
            temperature = 0.7
        elif communication_style == "formal":
            temperature = 0.3
        
        response = await cached_llm_invoke(
            llm, 
            [SystemMessage(content=contextual_prompt)],
            temperature=temperature,
            query_type="proactive_content",
            conversation_type=chat_type
        )
        
        content = response.content.strip()
        if content:
            try:
                # è§£æJSONå“åº”
                import json
                result = json.loads(content)
                proactive_content = result.get("content", "")
                if proactive_content:
                    # ç¡®ä¿å†…å®¹ç¬¦åˆAliceäººè®¾
                    return _ensure_alice_persona(proactive_content, intimacy)
            except json.JSONDecodeError:
                # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨å†…å®¹
                return _ensure_alice_persona(content, intimacy)
        
        return ""
    except Exception as e:
        logger.error(f"ç”Ÿæˆä¸»åŠ¨å†…å®¹å¤±è´¥: {e}")
        return ""

async def proactive_node(state: AgentState):
    """ä¸»åŠ¨äº¤äº’èŠ‚ç‚¹ - è‡ªç„¶è§¦å‘ç‰ˆæœ¬"""
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    logger.info(f"[{ts}] --- [Proactive] Checking interaction opportunity... ---")
    
    # 1. è·å–åŸºæœ¬ä¸Šä¸‹æ–‡
    try:
        user_id = state.get("sender_qq", "unknown")
        user_display_name = state.get("sender_name", "User")
        is_group = state.get("is_group", False)
        session_id = state.get("session_id", "unknown")
        msgs = state.get("messages", [])
        
        if not user_id or user_id == "unknown":
            logger.warning(f"[{ts}] ç¼ºå°‘ç”¨æˆ·IDï¼Œè·³è¿‡ä¸»åŠ¨äº¤äº’")
            return {"next_step": "silent"}
    except Exception as e:
        logger.error(f"[{ts}] è·å–ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
        return {"next_step": "silent"}
    
    # 2. è·å–ç”¨æˆ·å…³ç³»æ•°æ®
    try:
        profile = await relation_db.get_user_profile(user_id)
        rel = profile.relationship
        intimacy = rel.intimacy
        familiarity = rel.familiarity
        trust = rel.trust
        interest_match = rel.interest_match
        
        # 3. æ£€æŸ¥å…³ç³»é˜¶æ®µ - ä½äº²å¯†åº¦ç”¨æˆ·å‡å°‘ä¸»åŠ¨äº¤äº’
        if intimacy < 20 and random.random() > 0.3:
            logger.debug(f"[{ts}] ç”¨æˆ·äº²å¯†åº¦è¾ƒä½ ({intimacy})ï¼Œå‡å°‘ä¸»åŠ¨äº¤äº’")
            return {"next_step": "silent"}
        
        # 4. è·å–ä¸Šæ¬¡äº¤äº’æ—¶é—´
        last_interaction_time = getattr(rel, "last_interaction_time", time.time() - 3600 * 2)
        
        # 5. è·å–ç”¨æˆ·åé¦ˆåˆ†æ•°
        feedback_score = interaction_manager.get_user_feedback_score(user_id)
        
        # 6. è·å–ä½“åŠ›å€¼
        stamina = getattr(rel, "stamina", 80.0)  # ä½¿ç”¨é»˜è®¤å€¼80.0å¦‚æœæ²¡æœ‰
        
        # 7. åˆ¤æ–­æ˜¯å¦åº”è¯¥å‘èµ·ä¸»åŠ¨äº¤äº’
        if not interaction_manager.should_initiate_interaction(
            user_id, 
            last_interaction_time, 
            feedback_score, 
            intimacy, 
            familiarity, 
            trust, 
            interest_match, 
            stamina, 
            rel.interaction_patterns
        ):
            return {"next_step": "silent"}
            
        # 8. è·å–ä¸ªæ€§åŒ–è¯é¢˜
        topics = await interaction_manager.get_personalized_topics(user_id)
        
        # 9. ç”Ÿæˆä¸»åŠ¨å†…å®¹
        # å‡†å¤‡SOCIAL_VOLITION_PROMPTæ‰€éœ€çš„å‚æ•°
        current_time = datetime.now().strftime("%H:%M")
        # è®¡ç®—æ²‰é»˜æ—¶é•¿ï¼ˆå°æ—¶ï¼‰
        silence_hours = (time.time() - last_interaction_time) / 3600
        silence_duration = f"{silence_hours:.1f}å°æ—¶"
        chat_type = "group" if is_group else "private"
        user_name = user_display_name
        
        content = await _generate_proactive_content(
            user_id, topics, intimacy, current_time, silence_duration, stamina, 
            chat_type, user_name, familiarity, trust, interest_match, rel.communication_style
        )
        
        if not content or len(content.strip()) < 5:
            logger.debug(f"[{ts}] ç”Ÿæˆçš„å†…å®¹ä¸ç¬¦åˆè¦æ±‚ï¼Œè·³è¿‡ä¸»åŠ¨äº¤äº’")
            return {"next_step": "silent"}
            
        # 9. æ„å»ºAIæ¶ˆæ¯
        ai_msg = AIMessage(content=content)
        
        # 10. æ›´æ–°æœ€åäº¤äº’æ—¶é—´
        rel.last_interaction_time = time.time()
        relation_db.update_relationship(user_id, user_id, rel)
        
        # 11. æ¶ˆè€—ä½“åŠ›
        stamina_cost = -1.5 if is_group else -2.0  # å‡å°‘ä½“åŠ›æ¶ˆè€—ï¼Œé¿å…é¢‘ç¹è§¦å‘
        global_store.update_emotion(0, 0, stamina_delta=stamina_cost)
        
        logger.info(f"[{ts}] ğŸ¤– [Proactive] INITIATE_TOPIC | Content: {content}")
        
        return {
            "messages": msgs + [ai_msg],
            "next_step": "speak",
            "internal_monologue": f"[Social Volition] Intent: initiate_topic, Reason: åŸºäºç”¨æˆ·æ²‰é»˜æ—¶é•¿å’Œå…³ç³»äº²å¯†åº¦çš„è‡ªç„¶è§¦å‘, ChatType: {'Group' if is_group else 'Private'}"
        }
        
    except Exception as e:
        logger.error(f"[{ts}] ä¸»åŠ¨äº¤äº’å¤±è´¥: {e}")
        return {"next_step": "silent"}

# é¢å¤–çš„å·¥å…·å‡½æ•°ï¼Œç”¨äºå¤–éƒ¨æ¨¡å—è°ƒç”¨
def update_proactive_feedback(user_id: str, is_positive: bool):
    """æ›´æ–°ä¸»åŠ¨äº¤äº’çš„ç”¨æˆ·åé¦ˆ"""
    feedback_type = "positive" if is_positive else "negative"
    interaction_manager.update_user_feedback(user_id, feedback_type)
    logger.info(f"Updated proactive feedback for {user_id}: {feedback_type}")
