# === Pythonä»£ç æ–‡ä»¶: context_filter.py ===

import json
import re
import time
import logging
from datetime import datetime

# é…ç½®æ—¥å¿—
logger = logging.getLogger("ContextFilter")

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage
from app.core.state import AgentState
from app.core.config import config


# ==============================================================================
# æ”¹è¿›ç‚¹ 1: é²æ£’çš„ JSON æ¸…æ´—ä¸è§£æå‡½æ•° (é˜²å¾¡ API è„æ•°æ®æ³¨å…¥)
# ==============================================================================
def _clean_and_parse_json(text: str) -> dict:
    """
    ä¸“é—¨æ¸…æ´— [system hint] è„æ•°æ®å¹¶è§£æ JSON
    """
    if not text: return None

    # 1. æš´åŠ›æ¸…æ´— API æ³¨å…¥çš„ç³»ç»Ÿæç¤º
    # ç§»é™¤ç±»ä¼¼ [system hint: ...] çš„å†…å®¹
    text = re.sub(r"\[system hint:.*?\]", "", text, flags=re.IGNORECASE)
    text = text.strip()

    # 2. æå– Markdown ä»£ç å—ä¸­çš„ JSON
    match = re.search(r"```(?:json)?\s*(\{.*?\})\s*```", text, re.DOTALL)
    if match:
        json_str = match.group(1)
    else:
        # å°è¯•ç›´æ¥å¯»æ‰¾å¤§æ‹¬å·
        start = text.find("{")
        end = text.rfind("}")
        if start != -1 and end != -1:
            json_str = text[start: end + 1]
        else:
            json_str = text

    # 3. å°è¯•è§£æ
    try:
        return json.loads(json_str)
    except json.JSONDecodeError:
        try:
            # å°è¯•ä¿®å¤å¸¸è§çš„å°¾éšé€—å·é”™è¯¯
            return json.loads(re.sub(r",\s*}", "}", json_str))
        except:
            return None


# ==============================================================================
# æ”¹è¿›ç‚¹ 2: Prompt ä¼˜åŒ– (é˜²æ­¢å›¾ç‰‡/è¡¨æƒ…åŒ…åœ¨ Filter é˜¶æ®µè¢«é”™è¯¯æ‹¦æˆª)
# ==============================================================================
FILTER_PROMPT = """
You are the "Attention Filter" for an AI Assistant named Alice.
Your task is to analyze the latest message and decide if Alice should reply.

ã€Current Modeã€‘
**{chat_mode}**

ã€Conversation Context (Last 3 messages)ã€‘
{context_history}

ã€Message Detailsã€‘
- Sender: {user_name} (QQ: {user_qq})
- Is Mentioned (@Alice): {is_mentioned}
- Has Image Attached: {has_image}

ã€Decision Logicã€‘

### STEP 1: UNIVERSAL BLOCKERS (Check these FIRST for BOTH Private & Group)
**Return FALSE (Do NOT Reply)** if ANY of these apply:
1.  **Conversation Closure**: The user explicitly ends the topic (e.g., "Ok", "Thanks", "Got it", "Good night", "Bye", "å¥½çš„", "æ”¶åˆ°", "è°¢äº†", "ç¡äº†").
2.  **Meaningless Phatic**: The user sends ONLY generic emojis or simple reactions (e.g., "Haha", "666") with NO new info. 
    *   **EXCEPTION:** If `Has Image Attached` is TRUE, do **NOT** block it here. Pass it through for visual analysis.
3.  **Sentence Fragmentation**: The user is sending a split sentence. Wait for the full thought.
4.  **Double Sending**: Multiple messages in <1s. Only process the final one.
5.  **Topic Exhaustion**: Alice gave a final answer, and the user's reply adds nothing new.

### STEP 2: MODE-SPECIFIC RULES (If NO Blockers found)

#### SCENARIO A: PRIVATE CHAT (1-on-1)
**DEFAULT DECISION: TRUE (Reply)**.
If the message is NOT blocked by Step 1, Alice should reply to maintain the conversation flow.

#### SCENARIO B: GROUP CHAT
**DEFAULT DECISION: FALSE (Do NOT reply)**.
Alice should stay quiet to avoid spamming. **Return TRUE** ONLY if:
1.  **Explicit Mention**: `Is Mentioned` is true.
2.  **Name Reference**: The message content explicitly mentions "Alice" (e.g., "Aliceï¼Œä½ ä»Šå¤©ä¸‹åˆåšäº†ä»€ä¹ˆå‘€ï¼Ÿ").
3.  **Explicit Question**: The user asks a clear question Alice is uniquely qualified to answer.
4.  **Active Engagement**: The user is replying *directly* to Alice's previous statement.

### Output Format
Return a JSON object with a "reasoning" field and a "should_reply" boolean.
{{"reasoning": "Private chat. Message is 'Ok', which hits Universal Blocker #1 (Closure).", "should_reply": false}}
"""

llm = ChatOpenAI(
    model=config.SMALL_MODEL,  # å»ºè®®ç»Ÿä¸€ä½¿ç”¨ config.MODEL_NAME æˆ–ç¡®è®¤ config.MIMO_MODEL å­˜åœ¨
    temperature=0.0,
    api_key=config.SMALL_MODEL_API_KEY,  # å»ºè®®ç»Ÿä¸€é…ç½®
    base_url=config.SMALL_MODEL_URL
)


def _extract_last_message_content(msgs: list) -> str:
    """
    ä»æ¶ˆæ¯åˆ—è¡¨ä¸­æå–æœ€åä¸€æ¡æ¶ˆæ¯çš„æ–‡æœ¬å†…å®¹
    """
    if not msgs:
        return ""
    
    last_msg = msgs[-1]
    if isinstance(last_msg.content, list):
        return next((x['text'] for x in last_msg.content if x.get('type') == 'text'), "")
    else:
        return str(last_msg.content).strip()


def _check_has_image(state: AgentState, last_content: str) -> bool:
    """
    æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦åŒ…å«å›¾ç‰‡
    """
    image_urls = state.get("image_urls", [])
    return bool(image_urls or "[å›¾ç‰‡]" in last_content)


def _build_context_history(msgs: list) -> str:
    """
    æ„å»ºä¸Šä¸‹æ–‡å†å²å­—ç¬¦ä¸²
    """
    recent_msgs = msgs[-3:]
    history_str = ""
    
    for i, m in enumerate(recent_msgs):
        role = "AI(Alice)" if isinstance(m, (SystemMessage, dict)) or m.type == "ai" else "User"
        content = m.content
        
        if isinstance(content, list):
            text_part = next((x['text'] for x in content if x.get('type') == 'text'), "")
            if not text_part:
                text_part = "[Image/RichMedia]"
            content = text_part

        # æˆªæ–­è¿‡é•¿æ¶ˆæ¯é˜²æ­¢ Prompt çˆ†ç‚¸
        content_str = str(content)
        if len(content_str) > 100:
            content_str = content_str[:100] + "..."

        prefix = ">> [LATEST MSG] " if i == len(recent_msgs) - 1 else ""
        history_str += f"{prefix}[{role}]: {content_str}\n"
    
    return history_str


def _apply_heuristic_pre_filter(state: AgentState, last_content: str, has_img: bool) -> dict or None:
    """
    åº”ç”¨å¯å‘å¼é¢„è¿‡æ»¤è§„åˆ™
    """
    is_group = state.get("is_group", False)
    current_ts = time.time()
    
    # å¦‚æœæ²¡æœ‰å›¾ç‰‡ï¼Œä¸”æ–‡æœ¬é•¿åº¦æçŸ­ä¸”éé—®å¥
    if not has_img and len(last_content) < 2 and last_content not in ["?", "ï¼Ÿ", "hi", "Hi"]:
        # ç§èŠæ—¶ï¼Œå¦‚æœå¤ªçŸ­å¯èƒ½ä¹Ÿéœ€è¦å›ï¼ˆæ¯”å¦‚"?"ï¼‰ï¼Œè¿™é‡Œä¸»è¦é’ˆå¯¹ç¾¤èŠå™ªéŸ³
        if is_group:
            return {
                "should_reply": False,
                "filter_reason": "Message too short/Noise (Heuristic)",
                "last_interaction_ts": current_ts
            }
    
    return None


async def context_filter_node(state: AgentState):
    current_ts = time.time()
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    is_group = state.get("is_group", False)
    is_mentioned = state.get("is_mentioned", False)

    # 1. å¼ºè§„åˆ™ï¼šæ— è®ºç¾¤èŠç§èŠï¼Œè¢«è‰¾ç‰¹å¿…é¡»å› (æœ€é«˜ä¼˜å…ˆçº§)
    if is_mentioned:
        return {
            "should_reply": True,
            "filter_reason": "Directly mentioned (Hard Rule)",
            "last_interaction_ts": current_ts
        }

    msgs = state.get("messages", [])
    if not msgs:
        return {"should_reply": False, "filter_reason": "No messages"}

    # æå–æœ€åä¸€æ¡æ¶ˆæ¯çš„å†…å®¹
    last_content = _extract_last_message_content(msgs)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡
    has_img = _check_has_image(state, last_content)
    
    # 2. åº”ç”¨å¯å‘å¼é¢„è¿‡æ»¤
    pre_filter_result = _apply_heuristic_pre_filter(state, last_content, has_img)
    if pre_filter_result:
        return pre_filter_result

    # 3. æ„å»ºä¸Šä¸‹æ–‡å†å²
    history_str = _build_context_history(msgs)
    chat_mode = "GROUP CHAT" if is_group else "PRIVATE CHAT (1-on-1)"

    try:
        # 4. å¡«å……å¹¶è°ƒç”¨LLM
        prompt = FILTER_PROMPT.format(
            chat_mode=chat_mode,
            context_history=history_str,
            user_name=state.get("sender_name", "User"),
            user_qq=state.get("sender_qq", "Unknown"),
            is_mentioned=str(is_mentioned),
            has_image=str(has_img)
        )

        resp = await llm.ainvoke([SystemMessage(content=prompt)])
        # å¤„ç†respå¯èƒ½æ˜¯å­—ç¬¦ä¸²çš„æƒ…å†µ
        if isinstance(resp, str):
            raw_content = resp.strip()
        else:
            raw_content = resp.content.strip()

        # 5. ä½¿ç”¨å¢å¼ºçš„è§£æå™¨è§£æç»“æœ
        data = _clean_and_parse_json(raw_content)

        if data:
            should = data.get("should_reply", False)
            reason = data.get("reasoning", data.get("reason", "No reason"))

            log_icon = "âœ…" if should else "ğŸ›‘"
            mode_icon = "ğŸ‘¥" if is_group else "ğŸ‘¤"
            logger.info(f"[{ts}]{log_icon} [Filter] [{mode_icon}] Reply? {should} | Reason: {reason[:100]}")

            return {
                "should_reply": should,
                "filter_reason": reason,
                "last_interaction_ts": current_ts
            }
        else:
            logger.warning(f"[{ts}]âš ï¸ [Filter Warning] JSON Parse Failed. Raw: {raw_content[:50]}...")
            # å…œåº•ï¼šç§èŠå›ï¼Œç¾¤èŠä¸å›
            return {
                "should_reply": not is_group,
                "filter_reason": "Parse fail (Fallback)",
                "last_interaction_ts": current_ts
            }

    except Exception as e:
        logger.error(f"[{ts}]âŒ [Filter Error] {e}. Fallback used.")
        return {
            "should_reply": not is_group,
            "filter_reason": f"Error fallback: {str(e)}",
            "last_interaction_ts": current_ts
        }
