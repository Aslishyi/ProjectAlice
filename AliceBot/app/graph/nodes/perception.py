import base64
import httpx
import io
import re  # <--- æ–°å¢
import logging
from PIL import Image
from langchain_core.messages import HumanMessage, SystemMessage
from app.core.state import AgentState
from app.core.config import config
from app.plugins.emoji_plugin.emoji_manager import get_emoji_manager
from app.utils.cache import cached_llm_invoke
from langchain_openai import ChatOpenAI

# åˆå§‹åŒ–LLMå®ä¾‹
llm = ChatOpenAI(
    model=config.MODEL_NAME,
    temperature=0.3,  # ä½¿ç”¨è¾ƒä½çš„temperatureä»¥è·å¾—æ›´ç¨³å®šçš„åˆ†ç±»ç»“æœ
    api_key=config.MODEL_API_KEY,
    base_url=config.MODEL_URL
)

# é…ç½®æ—¥å¿—
logger = logging.getLogger("Perception")

# ç”¨äºåœ¨å†…å­˜ä¸­ä¸´æ—¶ç¼“å­˜å·²å¤„ç†çš„å›¾ç‰‡å°ºå¯¸ä¿¡æ¯ï¼Œé¿å…é‡å¤ä¸‹è½½
_IMG_CACHE = {}


async def _analyze_emoji_with_llm(base64_data: str) -> dict:
    """
    ä½¿ç”¨å¤§æ¨¡å‹åˆ†æè¡¨æƒ…åŒ…ï¼Œç”Ÿæˆæƒ…ç»ªæ ‡ç­¾ã€æè¿°å’Œåˆ†ç±»
    
    Args:
        base64_data: å›¾ç‰‡çš„base64ç¼–ç æ•°æ®
        
    Returns:
        dict: åŒ…å«æƒ…ç»ªæ ‡ç­¾ã€æè¿°å’Œåˆ†ç±»çš„å­—å…¸
    """
    try:
        logger.info(f"ğŸ¨ [Perception] å¼€å§‹åˆ†æè¡¨æƒ…åŒ…")
        
        # æ„é€ ç³»ç»Ÿæç¤ºè¯ - ä¼˜åŒ–ç‰ˆ
        system_prompt = ("ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¡¨æƒ…åŒ…åˆ†æä¸“å®¶ï¼Œå…·æœ‰ä¸°å¯Œçš„ç½‘ç»œæ–‡åŒ–çŸ¥è¯†å’Œæƒ…æ„Ÿåˆ†æèƒ½åŠ›ã€‚\n" 
                        "è¯·ä»”ç»†è§‚å¯Ÿå›¾ç‰‡å†…å®¹ï¼Œä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢åˆ†æè¡¨æƒ…åŒ…ï¼š\n" 
                        "\n" 
                        "1. æƒ…ç»ªæ ‡ç­¾ï¼š\n" 
                        "   - ç²¾ç¡®è¯†åˆ«è¡¨æƒ…åŒ…ä¼ è¾¾çš„æ ¸å¿ƒæƒ…ç»ªï¼Œä½¿ç”¨ä¸­æ–‡å…³é”®è¯\n" 
                        "   - æ¯ä¸ªæ ‡ç­¾å¿…é¡»ä¸å›¾ç‰‡å†…å®¹ç›´æ¥ç›¸å…³ï¼Œé¿å…æ³›æ³›è€Œè°ˆ\n" 
                        "   - æœ€å¤šç”Ÿæˆ5ä¸ªæ ‡ç­¾ï¼ŒæŒ‰æƒ…ç»ªå¼ºåº¦æ’åº\n" 
                        "   - ç¤ºä¾‹ï¼šå¼€å¿ƒã€å¹½é»˜ã€å¯çˆ±ã€å…´å¥‹ã€æç¬‘ï¼›æ‚²ä¼¤ã€å§”å±ˆã€éš¾è¿‡ã€ç—›è‹¦ã€å¤±æœ›\n" 
                        "   - é¿å…çŸ›ç›¾çš„æƒ…ç»ªæ ‡ç­¾ï¼Œç¡®ä¿æƒ…ç»ªä¸€è‡´æ€§\n" 
                        "\n" 
                        "2. æè¿°ï¼š\n" 
                        "   - ç®€æ´æ˜äº†åœ°æè¿°è¡¨æƒ…åŒ…çš„è§†è§‰å†…å®¹å’Œæ ¸å¿ƒå…ƒç´ \n" 
                        "   - åŒ…æ‹¬ä¸»è¦è§’è‰²ã€åŠ¨ä½œã€è¡¨æƒ…å’Œæ–‡å­—ï¼ˆå¦‚æœ‰ï¼‰\n" 
                        "   - ä¸è¶…è¿‡50å­—ï¼Œçªå‡ºå…³é”®ä¿¡æ¯\n" 
                        "\n" 
                        "3. åˆ†ç±»ï¼š\n" 
                        "   - ä»ä»¥ä¸‹åˆ†ç±»ä¸­é€‰æ‹©**å”¯ä¸€**æœ€åˆé€‚çš„é€‰é¡¹ï¼š\n" 
                        "     * è¡¨æƒ…ç¬¦å·ï¼šç®€å•çš„è¡¨æƒ…ç¬¦å·æˆ–emojiç»„åˆ\n" 
                        "     * äººç‰©å½¢è±¡ï¼šåŒ…å«äººç‰©è§’è‰²çš„è¡¨æƒ…åŒ…\n" 
                        "     * åŠ¨ç‰©æ¤ç‰©ï¼šä»¥åŠ¨ç‰©æˆ–æ¤ç‰©ä¸ºä¸»é¢˜çš„è¡¨æƒ…åŒ…\n" 
                        "     * åœºæ™¯ç”Ÿæ´»ï¼šè¡¨ç°ç”Ÿæ´»åœºæ™¯æˆ–æ—¥å¸¸æ´»åŠ¨çš„è¡¨æƒ…åŒ…\n" 
                        "     * æ–‡å­—æ¢—å›¾ï¼šåŒ…å«å¤§é‡æ–‡å­—æˆ–æ–‡å­—æ¸¸æˆçš„è¡¨æƒ…åŒ…\n" 
                        "     * å…¶ä»–ï¼šæ— æ³•å½’ç±»åˆ°ä¸Šè¿°ç±»åˆ«çš„è¡¨æƒ…åŒ…\n" 
                        "\n" 
                        "è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–å†…å®¹ã€è§£é‡Šæˆ–è¯´æ˜ï¼š\n" 
                        "{\"emotions\": [\"æƒ…ç»ªæ ‡ç­¾1\", \"æƒ…ç»ªæ ‡ç­¾2\"], \"description\": \"æè¿°å†…å®¹\", \"category\": \"åˆ†ç±»åç§°\"}")
        
        # æ„é€ ç”¨æˆ·æ¶ˆæ¯ï¼Œä½¿ç”¨æ­£ç¡®çš„å¤šæ¨¡æ€æ ¼å¼
        content = [
            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_data}"}},
            {"type": "text", "text": "è¯·æ ¹æ®æä¾›çš„è¡¨æƒ…åŒ…å›¾ç‰‡ï¼Œç”Ÿæˆæƒ…ç»ªæ ‡ç­¾ã€æè¿°å’Œåˆ†ç±»ä¿¡æ¯ã€‚"}
        ]
        
        # æ„é€ æ¶ˆæ¯åˆ—è¡¨
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=content)
        ]
        
        # è°ƒç”¨LLM
        response = await cached_llm_invoke(
            llm, 
            messages, 
            temperature=0.2,  # æ›´ä½çš„æ¸©åº¦ä»¥è·å¾—æ›´ç²¾ç¡®ã€ç¨³å®šçš„åˆ†æç»“æœ
            query_type="emoji_analysis"
        )
        
        # å¤„ç†å“åº”
        if isinstance(response, str):
            content = response.strip()
        else:
            content = response.content.strip()
        
        logger.info(f"ğŸ¨ [Perception] LLMåŸå§‹å“åº”: {content[:150]}...")
        
        # è§£æJSONå“åº”ï¼Œä½¿ç”¨æ›´å¥å£®çš„æ–¹å¼
        import json
        import re
        
        # æå–Markdown JSON
        match = re.search(r"```(?:json)?\s*(\{.*?\})\s*```", content, re.DOTALL)
        if match:
            content = match.group(1)
        else:
            # å°è¯•æ‰¾åˆ°JSONçš„å¼€å§‹å’Œç»“æŸä½ç½®
            start = content.find("{")
            end = content.rfind("}")
            if start != -1 and end != -1:
                content = content[start: end + 1]
        
        try:
            result = json.loads(content)
            
            # éªŒè¯å¹¶æ¸…ç†ç»“æœ
            valid_result = {}
            
            # éªŒè¯æƒ…ç»ªæ ‡ç­¾
            allowed_categories = ["è¡¨æƒ…ç¬¦å·", "äººç‰©å½¢è±¡", "åŠ¨ç‰©æ¤ç‰©", "åœºæ™¯ç”Ÿæ´»", "æ–‡å­—æ¢—å›¾", "å…¶ä»–"]
            
            # å¤„ç†æƒ…ç»ªæ ‡ç­¾
            emotions = result.get("emotions", [])
            if isinstance(emotions, list) and emotions:
                # è¿‡æ»¤ç©ºæ ‡ç­¾å¹¶ç¡®ä¿æ˜¯å­—ç¬¦ä¸²ç±»å‹
                valid_emotions = [str(e).strip() for e in emotions if e and isinstance(e, (str, int, float))]
                # é™åˆ¶æœ€å¤š5ä¸ªæ ‡ç­¾
                valid_result["emotions"] = valid_emotions[:5]
            else:
                valid_result["emotions"] = ["æœªçŸ¥"]
            
            # å¤„ç†æè¿°
            description = result.get("description", "")
            if isinstance(description, str) and description.strip():
                valid_result["description"] = description.strip()[:50]  # é™åˆ¶50å­—
            else:
                valid_result["description"] = ""
            
            # å¤„ç†åˆ†ç±»
            category = result.get("category", "å…¶ä»–")
            if isinstance(category, str) and category in allowed_categories:
                valid_result["category"] = category
            else:
                valid_result["category"] = "å…¶ä»–"
            
            logger.info(f"ğŸ¨ [Perception] LLMåˆ†æç»“æœ (å·²éªŒè¯): {valid_result}")
            return valid_result
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ [Perception] JSONè§£æå¤±è´¥: {e}, å¤„ç†åçš„å†…å®¹: {content[:100]}...")
            # å¤±è´¥æ—¶è¿”å›é»˜è®¤å€¼
            return {
                "emotions": ["æœªçŸ¥"],
                "description": "",
                "category": "å…¶ä»–"
            }
            
    except Exception as e:
        logger.error(f"âŒ [Perception] LLMåˆ†æè¡¨æƒ…åŒ…å¤±è´¥: {e}")
        # å¤±è´¥æ—¶è¿”å›é»˜è®¤å€¼
        return {
            "emotions": ["æœªçŸ¥"],
            "description": "",
            "category": "å…¶ä»–"
        }



def _compress_image(image: Image.Image, max_dimension: int = 1536, quality: int = 85) -> str:
    """å›¾ç‰‡å‹ç¼©é€»è¾‘ (ä¿æŒä¸å˜)"""
    if image.mode in ("RGBA", "P"):
        image = image.convert("RGB")
    width, height = image.size
    max_side = max(width, height)
    if max_side > max_dimension:
        scale_ratio = max_dimension / max_side
        image = image.resize((int(width * scale_ratio), int(height * scale_ratio)), Image.Resampling.LANCZOS)
    output_buffer = io.BytesIO()
    image.save(output_buffer, format="JPEG", quality=quality)
    return base64.b64encode(output_buffer.getvalue()).decode('utf-8')



def _find_image_urls(state: AgentState) -> list:
    """
    æŸ¥æ‰¾å›¾ç‰‡URLsï¼Œä¼˜å…ˆä½¿ç”¨å½“å‰å›¾ç‰‡ï¼Œå¦åˆ™å›æº¯å†å²æ¶ˆæ¯
    """
    image_urls = state.get("image_urls", [])
    if image_urls:
        return image_urls
    
    # å†å²å›æº¯
    msgs = state.get("messages", [])
    for m in reversed(msgs):
        if isinstance(m, HumanMessage):
            hist_urls = m.additional_kwargs.get("image_urls", [])
            if hist_urls:
                return hist_urls
    
    return []



def _classify_image(image: Image.Image, file_size_kb: float) -> str:
    """
    å¯¹å›¾ç‰‡è¿›è¡Œåˆ†ç±»ï¼šstickerã€icon æˆ– photo
    
    ä¼˜åŒ–åçš„åˆ†ç±»ç®—æ³•ï¼š
    1. åŸºäºå°ºå¯¸ã€æ¯”ä¾‹ã€é€æ˜åº¦ã€æ–‡ä»¶å¤§å°ç­‰å¤šç»´åº¦ç‰¹å¾
    2. æ›´ä¸¥æ ¼åŒºåˆ†è¡¨æƒ…åŒ…å’Œæ™®é€šå›¾ç‰‡
    3. æé«˜åˆ†ç±»å‡†ç¡®ç‡ï¼Œå‡å°‘è¯¯åˆ¤
    """
    width, height = image.size
    ratio = width / height if height > 0 else 0
    is_square_ish = 0.5 < ratio < 1.6
    has_transparency = image.mode in ('RGBA', 'LA') or ('transparency' in image.info)
    
    # å°å›¾æ ‡åˆ¤æ–­
    if width < 50 or height < 50:
        logger.info(f"ğŸ‘ï¸ -> Classified as ICON ({width}x{height}, {file_size_kb:.1f}KB)")
        return "icon"
    
    # è¡¨æƒ…åŒ…ç‰¹å¾åˆ¤æ–­
    # 1. å°ºå¯¸é€‚ä¸­ï¼šé€šå¸¸åœ¨100-1024åƒç´ ä¹‹é—´
    # 2. æ¥è¿‘æ­£æ–¹å½¢æ¯”ä¾‹
    # 3. å¯èƒ½æœ‰é€æ˜èƒŒæ™¯
    # 4. æ–‡ä»¶å¤§å°è¾ƒå°ï¼ˆé€šå¸¸å°äº1MBï¼‰
    is_small_to_medium = 100 <= width <= 1024 and 100 <= height <= 1024
    is_small_file = file_size_kb < 1024  # å°äº1MB
    has_sticker_characteristics = (is_square_ish and (has_transparency or is_small_file or is_small_to_medium))
    
    # æ™®é€šå›¾ç‰‡ç‰¹å¾åˆ¤æ–­
    # 1. å¤§å°ºå¯¸
    # 2. æ¯”ä¾‹å¤šæ ·ï¼ˆéæ­£æ–¹å½¢ï¼‰
    # 3. é€šå¸¸æ²¡æœ‰é€æ˜èƒŒæ™¯
    # 4. æ–‡ä»¶å¤§å°è¾ƒå¤§
    is_large = width > 1024 or height > 1024
    is_non_square = ratio <= 0.7 or ratio >= 1.4
    is_large_file = file_size_kb >= 1024
    has_photo_characteristics = (is_large or is_non_square or is_large_file) and not has_transparency
    
    # ç»¼åˆåˆ¤æ–­
    if has_photo_characteristics:
        logger.info(f"ğŸ‘ï¸ -> Classified as PHOTO ({width}x{height}, {file_size_kb:.1f}KB, ratio: {ratio:.2f})")
        return "photo"
    elif has_sticker_characteristics:
        logger.info(f"ğŸ‘ï¸ -> Classified as STICKER ({width}x{height}, {file_size_kb:.1f}KB, ratio: {ratio:.2f})")
        return "sticker"
    else:
        logger.info(f"ğŸ‘ï¸ -> Else Classified as PHOTO ({width}x{height}, {file_size_kb:.1f}KB, ratio: {ratio:.2f})")
        return "photo"



async def _download_and_process_image(target_url: str) -> tuple:
    """
    ä¸‹è½½å¹¶å¤„ç†å›¾ç‰‡
    """
    logger.info(f"ğŸ‘ï¸ [Perception] Downloading: {target_url[:50]}...")
    
    try:
        async with httpx.AsyncClient() as client:
            resp = await client.get(target_url, timeout=(3.0, 10.0))
            
            if resp.status_code == 200:
                try:
                    img_bytes = resp.content
                    image = Image.open(io.BytesIO(img_bytes))
                    width, height = image.size
                    file_size_kb = len(img_bytes) / 1024
                    
                    visual_type = _classify_image(image, file_size_kb)
                    
                    # åªå¯¹ç…§ç‰‡è¿›è¡Œå‹ç¼©
                    final_image_data = _compress_image(image) if visual_type == "photo" else None
                    
                    # æ›´æ–°ç¼“å­˜
                    _IMG_CACHE[target_url] = (visual_type, width, height, file_size_kb)
                    
                    return visual_type, final_image_data
                    
                except Exception as img_err:
                    logger.warning(f"âš ï¸ [Perception] Image processing error: {img_err}")
                    _IMG_CACHE[target_url] = ("failed", 0, 0, 0)
                    return "error", None
            else:
                logger.warning(f"âš ï¸ [Perception] Download Failed: HTTP {resp.status_code}.")
                _IMG_CACHE[target_url] = ("failed", 0, 0, 0)
                return "failed", None
                
    except httpx.TimeoutException:
        logger.warning("âš ï¸ [Perception] Download TIMEOUT. Skipping.")
        _IMG_CACHE[target_url] = ("failed", 0, 0, 0)
        return "timeout", None
    except Exception as e:
        logger.warning(f"âš ï¸ [Perception] Network error: {e}")
        return "error", None



async def perception_node(state: AgentState) -> dict:
    """
    æ„ŸçŸ¥èŠ‚ç‚¹ï¼šå¢åŠ ç¼“å­˜ä¸è¶…æ—¶ä¼˜åŒ–ï¼Œæ”¯æŒæ™ºèƒ½å¤„ç†å¤šå¼ å›¾ç‰‡
    """
    # æŸ¥æ‰¾å›¾ç‰‡URLs
    image_urls = _find_image_urls(state)
    if not image_urls:
        return {"visual_type": "none", "current_image_artifact": None}
    
    # è¿‡æ»¤éæ³•URL
    valid_image_urls = [url for url in image_urls if url.startswith("http")]
    if not valid_image_urls:
        return {"visual_type": "none", "current_image_artifact": None}
    
    # æ™ºèƒ½é€‰æ‹©éœ€è¦å¤„ç†çš„å›¾ç‰‡
    processed_images = []
    photos = []
    stickers = []
    
    # é¦–å…ˆå¯¹æ‰€æœ‰å›¾ç‰‡è¿›è¡Œåˆæ­¥åˆ†ç±»ï¼ˆä½¿ç”¨ç¼“å­˜æˆ–å¿«é€Ÿåˆ†ç±»ï¼‰
    for url in valid_image_urls:
        if url in _IMG_CACHE:
            cached_type, w, h, size = _IMG_CACHE[url]
            if cached_type == "photo":
                photos.append((url, cached_type))
            elif cached_type == "sticker":
                stickers.append((url, cached_type))
        else:
            # å¯¹äºæœªç¼“å­˜çš„å›¾ç‰‡ï¼Œå…ˆå¿«é€Ÿä¸‹è½½å¹¶åˆ†ç±»
            visual_type, _ = await _download_and_process_image(url)
            if visual_type == "photo":
                photos.append((url, visual_type))
            elif visual_type == "sticker":
                stickers.append((url, visual_type))
    
    # å†³å®šå¤„ç†å“ªäº›å›¾ç‰‡
    # 1. ä¼˜å…ˆå¤„ç†æ‰€æœ‰ç…§ç‰‡ç±»å‹çš„å›¾ç‰‡ï¼ˆé€šå¸¸åŒ…å«é‡è¦ä¿¡æ¯ï¼‰
    # 2. å¯¹äºè¡¨æƒ…åŒ…ï¼Œæœ€å¤šå¤„ç†2å¼ ä»£è¡¨æ€§çš„
    # 3. æ€»å¤„ç†å›¾ç‰‡æ•°ä¸è¶…è¿‡5å¼ ï¼Œé¿å…æ€§èƒ½é—®é¢˜
    target_images = []
    
    # æ·»åŠ æ‰€æœ‰ç…§ç‰‡
    for photo_url, _ in photos:
        target_images.append(photo_url)
    
    # æ·»åŠ æœ€å¤š2å¼ è¡¨æƒ…åŒ…
    for sticker_url, _ in stickers[:2]:
        target_images.append(sticker_url)
    
    # é™åˆ¶æ€»æ•°é‡
    target_images = target_images[:5]
    
    # å¤„ç†é€‰ä¸­çš„å›¾ç‰‡
    processed_image_data = []
    main_visual_type = "none"
    main_image_artifact = None
    all_image_artifacts = []
    
    for i, target_url in enumerate(target_images):
        # ç¼“å­˜æ£€æŸ¥
        if target_url in _IMG_CACHE:
            cached_type, w, h, size = _IMG_CACHE[target_url]
            logger.info(f"âš¡ [Perception] Cache Hit: {cached_type} ({w}x{h}) - Image {i+1}/{len(target_images)}")
            if cached_type == "photo":
                # ä¸‹è½½å¹¶å¤„ç†ç…§ç‰‡ï¼Œè·å–å®Œæ•´çš„image_artifact
                _, final_image_data = await _download_and_process_image(target_url)
                all_image_artifacts.append({
                    "type": cached_type,
                    "data": final_image_data
                })
                if not main_image_artifact:
                    main_image_artifact = final_image_data
                    main_visual_type = cached_type
            elif cached_type == "sticker":
                if not main_visual_type:
                    main_visual_type = cached_type
        else:
            # ä¸‹è½½å¹¶å¤„ç†å›¾ç‰‡
            visual_type, final_image_data = await _download_and_process_image(target_url)
            
            if visual_type == "photo":
                all_image_artifacts.append({
                    "type": visual_type,
                    "data": final_image_data
                })
                if not main_image_artifact:
                    main_image_artifact = final_image_data
                    main_visual_type = visual_type
            elif visual_type == "sticker" and not main_visual_type:
                main_visual_type = visual_type
        
        # è®°å½•å¤„ç†çš„å›¾ç‰‡
        processed_images.append({
            "url": target_url,
            "type": visual_type if 'visual_type' in locals() else _IMG_CACHE.get(target_url, ("unknown",))[0]
        })
    
    # è®°å½•å¤„ç†ä¿¡æ¯
    logger.info(f"ğŸ“¸ [Perception] Processed {len(processed_images)}/{len(valid_image_urls)} images")
    
    # æ„é€ è¿”å›
    updates = {
        "visual_type": main_visual_type,
        "current_image_artifact": main_image_artifact,
        "all_image_artifacts": all_image_artifacts,  # åŒ…å«æ‰€æœ‰å¤„ç†è¿‡çš„å›¾ç‰‡æ•°æ®
        "processed_images": processed_images  # è®°å½•æ‰€æœ‰å¤„ç†è¿‡çš„å›¾ç‰‡ä¿¡æ¯
    }
    
    return updates
