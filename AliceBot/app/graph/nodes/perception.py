import base64
import httpx
import io
import re  # <--- æ–°å¢
import logging
from PIL import Image
from langchain_core.messages import HumanMessage, SystemMessage
from app.core.state import AgentState
from app.core.config import config
from app.plugins.emoji_plugin.emoji_manager import get_emoji_manager
from app.utils.cache import cached_llm_invoke
from langchain_openai import ChatOpenAI
from typing import List, Optional, Dict, Tuple, Any

# åˆå§‹åŒ–LLMå®ä¾‹
llm = ChatOpenAI(
    model=config.MODEL_NAME,
    temperature=0.3,  # ä½¿ç”¨è¾ƒä½çš„temperatureä»¥è·å¾—æ›´ç¨³å®šçš„åˆ†ç±»ç»“æœ
    api_key=config.MODEL_API_KEY,
    base_url=config.MODEL_URL
)

# é…ç½®æ—¥å¿—
logger = logging.getLogger("Perception")

# ç”¨äºåœ¨å†…å­˜ä¸­ä¸´æ—¶ç¼“å­˜å·²å¤„ç†çš„å›¾ç‰‡å°ºå¯¸ä¿¡æ¯ï¼Œé¿å…é‡å¤ä¸‹è½½
_IMG_CACHE = {}


async def _process_image_with_llm(base64_data: str) -> tuple[bool, dict]:
    """
    ä½¿ç”¨å¤§æ¨¡å‹åŒæ—¶å®Œæˆå›¾ç‰‡æ˜¯å¦ä¸ºè¡¨æƒ…åŒ…çš„åˆ¤æ–­å’Œåˆ†æ
    
    Args:
        base64_data: å›¾ç‰‡çš„base64ç¼–ç æ•°æ®
        
    Returns:
        tuple[bool, dict]: (æ˜¯å¦ä¸ºè¡¨æƒ…åŒ…, åˆ†æç»“æœ)
        åˆ†æç»“æœåŒ…å«: emotions (æƒ…ç»ªæ ‡ç­¾), description (æè¿°), category (åˆ†ç±»)
    """
    try:
        logger.info(f"ğŸ¨ [Perception] å¼€å§‹ä½¿ç”¨å¤§æ¨¡å‹åˆ¤æ–­å’Œåˆ†æå›¾ç‰‡")
        
        # æ„é€ ç³»ç»Ÿæç¤ºè¯ - æ•´åˆåˆ¤æ–­å’Œåˆ†æåŠŸèƒ½
        system_prompt = ("ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¡¨æƒ…åŒ…åˆ†æä¸“å®¶ï¼Œå…·æœ‰ä¸°å¯Œçš„ç½‘ç»œæ–‡åŒ–çŸ¥è¯†å’Œæƒ…æ„Ÿåˆ†æèƒ½åŠ›ã€‚\n" 
                        "è¯·ä»”ç»†è§‚å¯Ÿå›¾ç‰‡å†…å®¹ï¼Œå®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š\n" 
                        "\n" 
                        "1. é¦–å…ˆåˆ¤æ–­è¿™å¼ å›¾ç‰‡æ˜¯å¦ä¸ºè¡¨æƒ…åŒ…ï¼ˆstickerï¼‰\n" 
                        "   - è¡¨æƒ…åŒ…çš„å®šä¹‰ï¼š\n" 
                        "     * é€šå¸¸æ˜¯å…·æœ‰å¤¸å¼ è¡¨æƒ…ã€åŠ¨ä½œæˆ–æ–‡å­—çš„å›¾ç‰‡\n" 
                        "     * ç”¨äºåœ¨èŠå¤©ä¸­è¡¨è¾¾æƒ…æ„Ÿæˆ–è°ƒä¾ƒ\n" 
                        "     * é€šå¸¸å…·æœ‰å¡é€šé£æ ¼æˆ–ç»è¿‡ç‰¹æ®Šå¤„ç†\n" 
                        "     * å°ºå¯¸é€šå¸¸è¾ƒå°ï¼Œæ¯”ä¾‹æ¥è¿‘æ­£æ–¹å½¢\n" 
                        "   - æ™®é€šå›¾ç‰‡çš„å®šä¹‰ï¼š\n" 
                        "     * çœŸå®çš„ç…§ç‰‡ï¼ˆå¦‚é£æ™¯ã€äººç‰©ã€é£Ÿç‰©ç­‰ï¼‰\n" 
                        "     * æ²¡æœ‰æ˜æ˜¾çš„å¤¸å¼ è¡¨æƒ…æˆ–åŠ¨ä½œ\n" 
                        "     * é€šå¸¸ç”¨äºè®°å½•çœŸå®åœºæ™¯\n" 
                        "\n" 
                        "2. å¦‚æœæ˜¯è¡¨æƒ…åŒ…ï¼Œè¯·ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢åˆ†æï¼š\n" 
                        "   - æƒ…ç»ªæ ‡ç­¾ï¼šç²¾ç¡®è¯†åˆ«è¡¨æƒ…åŒ…ä¼ è¾¾çš„æ ¸å¿ƒæƒ…ç»ªï¼Œä½¿ç”¨ä¸­æ–‡å…³é”®è¯ï¼Œæœ€å¤š5ä¸ªï¼ŒæŒ‰æƒ…ç»ªå¼ºåº¦æ’åº\n" 
                        "   - æè¿°ï¼šç®€æ´æ˜äº†åœ°æè¿°è¡¨æƒ…åŒ…çš„è§†è§‰å†…å®¹å’Œæ ¸å¿ƒå…ƒç´ ï¼Œä¸è¶…è¿‡50å­—\n" 
                        "   - åˆ†ç±»ï¼šä»ä»¥ä¸‹é€‰é¡¹ä¸­é€‰æ‹©å”¯ä¸€æœ€åˆé€‚çš„ï¼šè¡¨æƒ…ç¬¦å·ã€äººç‰©å½¢è±¡ã€åŠ¨ç‰©æ¤ç‰©ã€åœºæ™¯ç”Ÿæ´»ã€æ–‡å­—æ¢—å›¾ã€å…¶ä»–\n" 
                        "\n" 
                        "è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–å†…å®¹ã€è§£é‡Šæˆ–è¯´æ˜ï¼š\n" 
                        "{\"is_emoji\": true/false, \"emotions\": [\"æƒ…ç»ªæ ‡ç­¾1\", \"æƒ…ç»ªæ ‡ç­¾2\"], \"description\": \"æè¿°å†…å®¹\", \"category\": \"åˆ†ç±»åç§°\"}")
        
        # æ„é€ ç”¨æˆ·æ¶ˆæ¯ï¼Œä½¿ç”¨æ­£ç¡®çš„å¤šæ¨¡æ€æ ¼å¼
        message_content: list[str | dict[str, Any]] = [
            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_data}"}},
            {"type": "text", "text": "è¯·åˆ¤æ–­è¿™å¼ å›¾ç‰‡æ˜¯å¦ä¸ºè¡¨æƒ…åŒ…ï¼Œå¦‚æœæ˜¯ï¼Œè¯·ç”Ÿæˆæƒ…ç»ªæ ‡ç­¾ã€æè¿°å’Œåˆ†ç±»ä¿¡æ¯ã€‚"}
        ]
        
        # æ„é€ æ¶ˆæ¯åˆ—è¡¨
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=message_content)
        ]
        
        # è°ƒç”¨LLM
        response = await cached_llm_invoke(
            llm, 
            messages, 
            temperature=0.2,  # é€‚ä¸­çš„æ¸©åº¦ä»¥è·å¾—ç²¾ç¡®ä¸”ä¸°å¯Œçš„åˆ†æç»“æœ
            query_type="image_classification_and_analysis"
        )
        
        # å¤„ç†å“åº”
        response_content: str
        if isinstance(response, str):
            response_content = response.strip()
        else:
            response_content = response.content.strip()
        
        logger.info(f"ğŸ¨ [Perception] LLMå“åº”: {response_content[:150]}...")
        
        # è§£æJSONå“åº”
        import json
        import re
        
        # æå–Markdown JSON
        match = re.search(r"```(?:json)?\s*(\{.*?\})\s*```", response_content, re.DOTALL)
        if match:
            json_content = match.group(1)
        else:
            # å°è¯•æ‰¾åˆ°JSONçš„å¼€å§‹å’Œç»“æŸä½ç½®
            start = response_content.find("{")
            end = response_content.rfind("}")
            if start != -1 and end != -1:
                json_content = response_content[start: end + 1]
            else:
                json_content = response_content
        
        try:
            result = json.loads(json_content)
            
            # éªŒè¯å¹¶æ¸…ç†ç»“æœ
            is_emoji = result.get("is_emoji", False)
            valid_result: dict[str, Any] = {}
            
            # å¦‚æœæ˜¯è¡¨æƒ…åŒ…ï¼ŒéªŒè¯æƒ…ç»ªæ ‡ç­¾ã€æè¿°å’Œåˆ†ç±»
            if is_emoji:
                allowed_categories = ["è¡¨æƒ…ç¬¦å·", "äººç‰©å½¢è±¡", "åŠ¨ç‰©æ¤ç‰©", "åœºæ™¯ç”Ÿæ´»", "æ–‡å­—æ¢—å›¾", "å…¶ä»–"]
                
                # å¤„ç†æƒ…ç»ªæ ‡ç­¾
                emotions = result.get("emotions", [])
                if isinstance(emotions, list) and emotions:
                    # è¿‡æ»¤ç©ºæ ‡ç­¾å¹¶ç¡®ä¿æ˜¯å­—ç¬¦ä¸²ç±»å‹
                    valid_emotions = [str(e).strip() for e in emotions if e and isinstance(e, (str, int, float))]
                    # é™åˆ¶æœ€å¤š5ä¸ªæ ‡ç­¾
                    valid_result["emotions"] = valid_emotions[:5]
                else:
                    valid_result["emotions"] = ["æœªçŸ¥"]
                
                # å¤„ç†æè¿°
                description = result.get("description", "")
                if isinstance(description, str) and description.strip():
                    valid_result["description"] = description.strip()[:50]  # é™åˆ¶50å­—
                else:
                    valid_result["description"] = ""
                
                # å¤„ç†åˆ†ç±»
                category = result.get("category", "å…¶ä»–")
                if isinstance(category, str) and category in allowed_categories:
                    valid_result["category"] = category
                else:
                    valid_result["category"] = "å…¶ä»–"
            
            logger.info(f"ğŸ¨ [Perception] LLMåˆ¤æ–­ç»“æœ: {'æ˜¯è¡¨æƒ…åŒ…' if is_emoji else 'ä¸æ˜¯è¡¨æƒ…åŒ…'}")
            if is_emoji:
                logger.info(f"ğŸ¨ [Perception] LLMåˆ†æç»“æœ (å·²éªŒè¯): {valid_result}")
            
            return is_emoji, valid_result
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ [Perception] JSONè§£æå¤±è´¥: {e}, å¤„ç†åçš„å†…å®¹: {json_content[:100]}...")
            # å¤±è´¥æ—¶è¿”å›é»˜è®¤å€¼
            return False, {
                "emotions": ["æœªçŸ¥"],
                "description": "",
                "category": "å…¶ä»–"
            }
            
    except Exception as e:
        logger.error(f"âŒ [Perception] LLMåˆ¤æ–­å’Œåˆ†æå›¾ç‰‡å¤±è´¥: {e}")
        # å¤±è´¥æ—¶è¿”å›é»˜è®¤å€¼
        return False, {
            "emotions": ["æœªçŸ¥"],
            "description": "",
            "category": "å…¶ä»–"
        }


# ä¿ç•™åŸæœ‰å‡½æ•°ä½œä¸ºå…¼å®¹å±‚
async def _is_emoji_with_llm(base64_data: str) -> bool:
    """
    ä½¿ç”¨å¤§æ¨¡å‹åˆ¤æ–­å›¾ç‰‡æ˜¯å¦ä¸ºè¡¨æƒ…åŒ…ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
    
    Args:
        base64_data: å›¾ç‰‡çš„base64ç¼–ç æ•°æ®
        
    Returns:
        bool: æ˜¯å¦ä¸ºè¡¨æƒ…åŒ…
    """
    is_emoji, _ = await _process_image_with_llm(base64_data)
    return is_emoji


async def _analyze_emoji_with_llm(base64_data: str) -> dict:
    """
    ä½¿ç”¨å¤§æ¨¡å‹åˆ†æè¡¨æƒ…åŒ…ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
    
    Args:
        base64_data: å›¾ç‰‡çš„base64ç¼–ç æ•°æ®
        
    Returns:
        dict: åŒ…å«æƒ…ç»ªæ ‡ç­¾ã€æè¿°å’Œåˆ†ç±»çš„å­—å…¸
    """
    _, analysis = await _process_image_with_llm(base64_data)
    return analysis



def _compress_image(image: Image.Image, max_dimension: int = 1536, quality: int = 85) -> str:
    """å›¾ç‰‡å‹ç¼©é€»è¾‘ (ä¿æŒä¸å˜)"""
    if image.mode in ("RGBA", "P"):
        image = image.convert("RGB")
    width, height = image.size
    max_side = max(width, height)
    if max_side > max_dimension:
        scale_ratio = max_dimension / max_side
        image = image.resize((int(width * scale_ratio), int(height * scale_ratio)), Image.Resampling.LANCZOS)
    output_buffer = io.BytesIO()
    image.save(output_buffer, format="JPEG", quality=quality)
    return base64.b64encode(output_buffer.getvalue()).decode('utf-8')



def _find_image_urls(state: AgentState) -> list:
    """
    æŸ¥æ‰¾å›¾ç‰‡URLsï¼Œä¼˜å…ˆä½¿ç”¨å½“å‰å›¾ç‰‡ï¼Œå¦åˆ™å›æº¯å†å²æ¶ˆæ¯
    """
    image_urls = state.get("image_urls", [])
    if image_urls:
        return image_urls
    
    # å†å²å›æº¯
    msgs = state.get("messages", [])
    for m in reversed(msgs):
        if isinstance(m, HumanMessage):
            hist_urls = m.additional_kwargs.get("image_urls", [])
            if hist_urls:
                return hist_urls
    
    return []



async def _classify_image(image: Image.Image, file_size_kb: float) -> str:
    """
    å¯¹å›¾ç‰‡è¿›è¡Œåˆ†ç±»ï¼šstickerã€icon æˆ– photo
    
    ä½¿ç”¨å¤§æ¨¡å‹APIè¿›è¡Œåˆ¤æ–­ï¼Œæé«˜åˆ†ç±»å‡†ç¡®ç‡
    """
    width, height = image.size
    ratio = width / height if height > 0 else 0
    
    # å°å›¾æ ‡åˆ¤æ–­ - ä»ç„¶ä½¿ç”¨æœ¬åœ°è§„åˆ™ï¼Œå› ä¸ºå°å›¾æ ‡æ˜æ˜¾ä¸æ˜¯è¡¨æƒ…åŒ…
    if width < 50 or height < 50:
        logger.info(f"ğŸ‘ï¸ -> Classified as ICON ({width}x{height}, {file_size_kb:.1f}KB)")
        return "icon"
    
    # å°†å›¾ç‰‡è½¬æ¢ä¸ºbase64ï¼Œç”¨äºå¤§æ¨¡å‹åˆ¤æ–­
    try:
        import io
        import base64
        
        # ä¿å­˜å›¾ç‰‡åˆ°å­—èŠ‚æµ
        buffer = io.BytesIO()
        image_format = image.format or "JPEG"
        if image.mode in ('RGBA', 'LA'):
            # å¯¹äºæœ‰é€æ˜é€šé“çš„å›¾ç‰‡ï¼Œä½¿ç”¨PNGæ ¼å¼
            image_format = "PNG"
        image.save(buffer, format=image_format)
        buffer.seek(0)
        
        # è½¬æ¢ä¸ºbase64
        base64_data = base64.b64encode(buffer.read()).decode('utf-8')
        
        # ä½¿ç”¨å¤§æ¨¡å‹åŒæ—¶è¿›è¡Œåˆ¤æ–­å’Œåˆ†æ
        is_emoji, _ = await _process_image_with_llm(base64_data)
        
        if is_emoji:
            logger.info(f"ğŸ‘ï¸ -> LLM Classified as STICKER ({width}x{height}, {file_size_kb:.1f}KB, ratio: {ratio:.2f})")
            return "sticker"
        else:
            logger.info(f"ğŸ‘ï¸ -> LLM Classified as PHOTO ({width}x{height}, {file_size_kb:.1f}KB, ratio: {ratio:.2f})")
            return "photo"
            
    except Exception as e:
        logger.error(f"âŒ å¤§æ¨¡å‹åˆ†ç±»å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°å¤‡ä»½è§„åˆ™: {e}")
        # å‡ºé”™æ—¶ä½¿ç”¨æœ¬åœ°å¤‡ä»½é€»è¾‘
        try:
            has_transparency = image.mode in ('RGBA', 'LA') or ('transparency' in image.info)
            is_square_ish = 0.5 < ratio < 1.6
            is_small_to_medium = 100 <= width <= 1024 and 100 <= height <= 1024
            is_small_file = file_size_kb < 1024  # å°äº1MB
            has_sticker_characteristics = (is_square_ish and (has_transparency or is_small_file or is_small_to_medium))
            
            if has_sticker_characteristics:
                logger.info(f"ğŸ‘ï¸ -> Backup Rule Classified as STICKER ({width}x{height}, {file_size_kb:.1f}KB, ratio: {ratio:.2f})")
                return "sticker"
            else:
                logger.info(f"ğŸ‘ï¸ -> Backup Rule Classified as PHOTO ({width}x{height}, {file_size_kb:.1f}KB, ratio: {ratio:.2f})")
                return "photo"
        except Exception as backup_e:
            logger.error(f"âŒ æœ¬åœ°å¤‡ä»½è§„åˆ™ä¹Ÿå¤±è´¥: {backup_e}")
            return "photo"



async def _download_and_process_image(target_url: str) -> tuple:
    """
    ä¸‹è½½å¹¶å¤„ç†å›¾ç‰‡
    """
    logger.info(f"ğŸ‘ï¸ [Perception] Downloading: {target_url[:50]}...")
    
    try:
        async with httpx.AsyncClient() as client:
            resp = await client.get(target_url, timeout=(3.0, 10.0))
            
            if resp.status_code == 200:
                try:
                    img_bytes = resp.content
                    image = Image.open(io.BytesIO(img_bytes))
                    width, height = image.size
                    file_size_kb = len(img_bytes) / 1024
                    
                    visual_type = await _classify_image(image, file_size_kb)
                    
                    # åªå¯¹ç…§ç‰‡è¿›è¡Œå‹ç¼©
                    final_image_data = _compress_image(image) if visual_type == "photo" else None
                    
                    # æ›´æ–°ç¼“å­˜
                    _IMG_CACHE[target_url] = (visual_type, width, height, file_size_kb)
                    
                    return visual_type, final_image_data
                    
                except Exception as img_err:
                    logger.warning(f"âš ï¸ [Perception] Image processing error: {img_err}")
                    _IMG_CACHE[target_url] = ("failed", 0, 0, 0)
                    return "error", None
            else:
                logger.warning(f"âš ï¸ [Perception] Download Failed: HTTP {resp.status_code}.")
                _IMG_CACHE[target_url] = ("failed", 0, 0, 0)
                return "failed", None
                
    except httpx.TimeoutException:
        logger.warning("âš ï¸ [Perception] Download TIMEOUT. Skipping.")
        _IMG_CACHE[target_url] = ("failed", 0, 0, 0)
        return "timeout", None
    except Exception as e:
        logger.warning(f"âš ï¸ [Perception] Network error: {e}")
        return "error", None



async def perception_node(state: AgentState) -> dict:
    """
    æ„ŸçŸ¥èŠ‚ç‚¹ï¼šå¢åŠ ç¼“å­˜ä¸è¶…æ—¶ä¼˜åŒ–ï¼Œæ”¯æŒæ™ºèƒ½å¤„ç†å¤šå¼ å›¾ç‰‡
    """
    # æŸ¥æ‰¾å›¾ç‰‡URLs
    image_urls = _find_image_urls(state)
    if not image_urls:
        return {"visual_type": "none", "current_image_artifact": None}
    
    # è¿‡æ»¤éæ³•URL
    valid_image_urls = [url for url in image_urls if url.startswith("http")]
    if not valid_image_urls:
        return {"visual_type": "none", "current_image_artifact": None}
    
    # æ™ºèƒ½é€‰æ‹©éœ€è¦å¤„ç†çš„å›¾ç‰‡
    processed_images = []
    photos = []
    stickers = []
    
    # é¦–å…ˆå¯¹æ‰€æœ‰å›¾ç‰‡è¿›è¡Œåˆæ­¥åˆ†ç±»ï¼ˆä½¿ç”¨ç¼“å­˜æˆ–å¿«é€Ÿåˆ†ç±»ï¼‰
    for url in valid_image_urls:
        if url in _IMG_CACHE:
            cached_type, w, h, size = _IMG_CACHE[url]
            if cached_type == "photo":
                photos.append((url, cached_type))
            elif cached_type == "sticker":
                stickers.append((url, cached_type))
        else:
            # å¯¹äºæœªç¼“å­˜çš„å›¾ç‰‡ï¼Œå…ˆå¿«é€Ÿä¸‹è½½å¹¶åˆ†ç±»
            visual_type, _ = await _download_and_process_image(url)
            if visual_type == "photo":
                photos.append((url, visual_type))
            elif visual_type == "sticker":
                stickers.append((url, visual_type))
    
    # å†³å®šå¤„ç†å“ªäº›å›¾ç‰‡
    # 1. ä¼˜å…ˆå¤„ç†æ‰€æœ‰ç…§ç‰‡ç±»å‹çš„å›¾ç‰‡ï¼ˆé€šå¸¸åŒ…å«é‡è¦ä¿¡æ¯ï¼‰
    # 2. å¯¹äºè¡¨æƒ…åŒ…ï¼Œæœ€å¤šå¤„ç†2å¼ ä»£è¡¨æ€§çš„
    # 3. æ€»å¤„ç†å›¾ç‰‡æ•°ä¸è¶…è¿‡5å¼ ï¼Œé¿å…æ€§èƒ½é—®é¢˜
    target_images = []
    
    # æ·»åŠ æ‰€æœ‰ç…§ç‰‡
    for photo_url, _ in photos:
        target_images.append(photo_url)
    
    # æ·»åŠ æœ€å¤š2å¼ è¡¨æƒ…åŒ…
    for sticker_url, _ in stickers[:2]:
        target_images.append(sticker_url)
    
    # é™åˆ¶æ€»æ•°é‡
    target_images = target_images[:5]
    
    # å¤„ç†é€‰ä¸­çš„å›¾ç‰‡
    processed_image_data: list[dict[str, Any]] = []
    main_visual_type = "none"
    main_image_artifact = None
    all_image_artifacts = []
    
    for i, target_url in enumerate(target_images):
        # ç¼“å­˜æ£€æŸ¥
        if target_url in _IMG_CACHE:
            cached_type, w, h, size = _IMG_CACHE[target_url]
            logger.info(f"âš¡ [Perception] Cache Hit: {cached_type} ({w}x{h}) - Image {i+1}/{len(target_images)}")
            if cached_type == "photo":
                # ä¸‹è½½å¹¶å¤„ç†ç…§ç‰‡ï¼Œè·å–å®Œæ•´çš„image_artifact
                _, final_image_data = await _download_and_process_image(target_url)
                all_image_artifacts.append({
                    "type": cached_type,
                    "data": final_image_data
                })
                if not main_image_artifact:
                    main_image_artifact = final_image_data
                    main_visual_type = cached_type
            elif cached_type == "sticker":
                if not main_visual_type:
                    main_visual_type = cached_type
        else:
            # ä¸‹è½½å¹¶å¤„ç†å›¾ç‰‡
            visual_type, final_image_data = await _download_and_process_image(target_url)
            
            if visual_type == "photo":
                all_image_artifacts.append({
                    "type": visual_type,
                    "data": final_image_data
                })
                if not main_image_artifact:
                    main_image_artifact = final_image_data
                    main_visual_type = visual_type
            elif visual_type == "sticker" and not main_visual_type:
                main_visual_type = visual_type
        
        # è®°å½•å¤„ç†çš„å›¾ç‰‡
        processed_images.append({
            "url": target_url,
            "type": visual_type if 'visual_type' in locals() else _IMG_CACHE.get(target_url, ("unknown",))[0]
        })
    
    # è®°å½•å¤„ç†ä¿¡æ¯
    logger.info(f"ğŸ“¸ [Perception] Processed {len(processed_images)}/{len(valid_image_urls)} images")
    
    # æ„é€ è¿”å›
    updates = {
        "visual_type": main_visual_type,
        "current_image_artifact": main_image_artifact,
        "all_image_artifacts": all_image_artifacts,  # åŒ…å«æ‰€æœ‰å¤„ç†è¿‡çš„å›¾ç‰‡æ•°æ®
        "processed_images": processed_images  # è®°å½•æ‰€æœ‰å¤„ç†è¿‡çš„å›¾ç‰‡ä¿¡æ¯
    }
    
    return updates
