import json
import re
import time
import random
import logging
from datetime import datetime
from langchain_openai import ChatOpenAI

# é…ç½®æ—¥å¿—
logger = logging.getLogger("UnifiedAgent")
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from app.core.state import AgentState
from app.core.config import config
from app.memory.vector_store import vector_db
from app.memory.relation_db import relation_db
from app.core.prompts import ALICE_CORE_PERSONA, AGENT_SYSTEM_PROMPT
from app.utils.cache import cached_llm_invoke, cached_user_info_get, cached_user_info_set

llm = ChatOpenAI(
    model=config.MODEL_NAME,
    temperature=0.7,
    api_key=config.MODEL_API_KEY,
    base_url=config.MODEL_URL
)


def robust_json_parse(text: str) -> dict:
    """
    å¢å¼ºå‹ JSON è§£æå™¨ - ä¸“é—¨ä¿®å¤ API æ³¨å…¥çš„è„æ•°æ®
    """
    if not text: return None

    # ğŸš€ [æ ¸å¿ƒä¿®å¤] ç§»é™¤ API å¼ºè¡Œæ³¨å…¥çš„ system hint åƒåœ¾ä¿¡æ¯
    text = re.sub(r"\[system hint:.*?\]", "", text, flags=re.IGNORECASE)
    text = text.strip()

    # æå– Markdown JSON
    match = re.search(r"```(?:json)?\s*(\{.*?\})\s*```", text, re.DOTALL)
    if match:
        text = match.group(1)
    else:
        start = text.find("{")
        end = text.rfind("}")
        if start != -1 and end != -1:
            text = text[start: end + 1]

    try:
        return json.loads(text)
    except json.JSONDecodeError:
        try:
            fixed_text = re.sub(r",\s*}", "}", text)
            return json.loads(fixed_text)
        except:
            return None


async def agent_node(state: AgentState):
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    logger.info(f"[{ts}]--- [Alice Core] Processing... ---")

    msgs = state.get("messages", [])
    image_data = state.get("current_image_artifact")
    visual_type = state.get("visual_type", "none")

    # æå–æœ€è¿‘ä¸€æ¡æ¶ˆæ¯æ–‡æœ¬
    last_human_content = ""
    if msgs:
        for m in reversed(msgs):
            if isinstance(m, HumanMessage):
                content = m.content
                if isinstance(content, list):
                    content = next((x['text'] for x in content if x['type'] == 'text'), "")
                last_human_content = str(content).strip()
                break

    # =========================================================================
    # ğŸ›¡ï¸ ç¬¬ä¸€é“é˜²çº¿ï¼šçŸ­è·¯æ‹¦æˆª (Short-Circuit)
    # =========================================================================
    if visual_type == "sticker":
        # ğŸš€ [æ ¸å¿ƒä¿®å¤ 1] å¢å¼ºæ¸…æ´—é€»è¾‘
        # 1. ç§»é™¤å¯èƒ½å­˜åœ¨çš„ [ç”¨æˆ·å]: å‰ç¼€ (éè´ªå©ªåŒ¹é…)
        # 2. ç§»é™¤ [å›¾ç‰‡], [è¡¨æƒ…] å ä½ç¬¦
        # 3. ç§»é™¤ç©ºæ ¼

        # ä¸´æ—¶å˜é‡ï¼Œå…ˆå»æ‰ç”¨æˆ·åå¼€å¤´
        # åŒ¹é…æ¨¡å¼ï¼šè¡Œé¦– + [ä»»æ„å­—ç¬¦] + å†’å· + å¯é€‰ç©ºæ ¼
        temp_text = re.sub(r"^\[.*?\]:\s*", "", last_human_content)

        clean_text = temp_text.replace("[å›¾ç‰‡]", "").replace("[è¡¨æƒ…]", "").replace(" ", "").strip()

        logger.debug(f"[{ts}]ğŸ•µï¸ [Debug] Sticker Check -> Raw: '{last_human_content}' | Removed Prefix: '{temp_text}' | Final Cleaned: '{clean_text}'")

        if len(clean_text) < 2:
            logger.info(f"[{ts}] ğŸ›‘ [Alice Core] Detected PURE STICKER. Skipping LLM.")

            # 50% æ¦‚ç‡å›å¤è¡¨æƒ…
            if random.random() < 0.6:
                replies = ["ğŸ¶", "ğŸ±", "ğŸ’–", "ğŸ’•", "ğŸ’", "ğŸ¤—", "ğŸ‘»", "ğŸ‘½"]
                reply = random.choice(replies)
                logger.info(f"[{ts}]ğŸ² [Short-Circuit] Reply: {reply}")
                return {
                    "internal_monologue": "Sticker acknowledged.",
                    "messages": msgs + [AIMessage(content=reply)],
                    "last_interaction_ts": time.time(),
                    "next_step": "save"
                }
            else:
                logger.info(f"[{ts}] ğŸ¤ [Short-Circuit] Silent.")
                return {
                    "internal_monologue": "Sticker ignored.",
                    "messages": msgs,
                    "last_interaction_ts": time.time(),
                    "next_step": "save"
                }

    # =========================================================================
    # ğŸ§  LLM å¤„ç† (Photo æˆ– å¸¦æœ‰æ–‡å­—çš„ Sticker)
    # =========================================================================

    psych_ctx = state.get("psychological_context", {})
    real_user_id = state.get("sender_qq", "unknown")
    user_display_name = state.get("sender_name", "User")
    now_str = datetime.now().strftime("%Y-%m-%d %H:%M")

    # RAG æ£€ç´¢ (ä¿æŒåŸé€»è¾‘)
    memory_context = ""
    try:
        # åªæœ‰æ¸…æ´—åçš„æ–‡æœ¬è¶³å¤Ÿé•¿æ‰æ£€ç´¢ï¼Œé¿å…ç”¨ "[å›¾ç‰‡]" æ£€ç´¢
        query_text = re.sub(r"^\[.*?\]:\s*", "", last_human_content).replace("[å›¾ç‰‡]", "").strip()
        if len(query_text) > 4:
            docs = await vector_db.search(query_text, k=3)
            if docs:
                logger.info(f"[{ts}] ğŸ“– [RAG] Hit: {[d[:20] + '...' for d in docs]}")
                memory_context = f"ã€ç›¸å…³å›å¿†ã€‘\n" + "\n".join(docs)
    except Exception as e:
        logger.error(f"[{ts}] [RAG Error] {e}")
        pass

    # è§†è§‰æ‘˜è¦
    vision_summary_text = "æ— "
    if image_data and visual_type == "photo":
        vision_summary_text = "ã€è§†è§‰ä¿¡å·æ´»è·ƒï¼šç”¨æˆ·å‘äº†å…·ä½“å›¾ç‰‡ï¼Œè§ä¸‹æ–¹å¤šæ¨¡æ€è¾“å…¥ã€‘"
    elif visual_type == "sticker":
        vision_summary_text = "ã€è§†è§‰ä¿¡å·ï¼šç”¨æˆ·å‘é€äº†ä¸€ä¸ªè¡¨æƒ…åŒ…/Stickerã€‘"

    # æ„é€  Prompt
    format_instruction = """
    # å¼ºåˆ¶å“åº”æ ¼å¼è¦æ±‚
    YOU MUST OUTPUT A VALID JSON OBJECT ONLY. NO OTHER TEXT OR EXPLANATION ALLOWED.
    YOU WILL BE PUNISHED IF YOU FAIL TO FOLLOW THIS INSTRUCTION.
    
    Response Format:
    {
      "monologue": "ä½ çš„å†…éƒ¨æ€è€ƒè¿‡ç¨‹",
      "action": "reply",
      "args": "",
      "response": "è¦å‘é€ç»™ç”¨æˆ·çš„å›å¤å†…å®¹"
    }
    
    Example:
    {"monologue": "ç”¨æˆ·é—®æˆ‘å–œæ¬¢ä»€ä¹ˆé¢œè‰²ï¼Œæˆ‘åº”è¯¥å›ç­”è“è‰²", "action": "reply", "args": "", "response": "æˆ‘å–œæ¬¢è“è‰²"}
    """

    # è·å–æƒ…ç»ªå’Œå…³ç³»æ•°æ®
    emotion_snapshot = state.get("global_emotion_snapshot", {})
    primary_emotion = psych_ctx.get("primary_emotion", emotion_snapshot.get("primary_emotion", "å¹³æ·¡"))
    secondary_emotion = psych_ctx.get("secondary_emotion", emotion_snapshot.get("secondary_emotion", ""))
    valence = emotion_snapshot.get("valence", 0.0)
    arousal = emotion_snapshot.get("arousal", 0.0)
    stress = emotion_snapshot.get("stress", 0.0)
    fatigue = emotion_snapshot.get("fatigue", 0.0)
    intimacy = psych_ctx.get("current_intimacy", 30)
    familiarity = psych_ctx.get("current_familiarity", 50)
    trust = psych_ctx.get("current_trust", 50)
    interest_match = psych_ctx.get("current_interest_match", 50)
    
    # ç”Ÿæˆå…³ç³»æè¿°
    if intimacy < 20:
        relation_desc = "é™Œç”Ÿäºº"
    elif intimacy < 40:
        relation_desc = "è®¤è¯†çš„äºº"
    elif intimacy < 60:
        if familiarity > 70:
            relation_desc = "ç†Ÿæ‚‰çš„æœ‹å‹"
        elif trust > 70:
            relation_desc = "å€¼å¾—ä¿¡ä»»çš„æœ‹å‹"
        else:
            relation_desc = "æ™®é€šçš„æœ‹å‹"
    elif intimacy < 80:
        if familiarity > 80 and trust > 80:
            relation_desc = "äº²å¯†çš„æœ‹å‹"
        elif interest_match > 80:
            relation_desc = "å¿—åŒé“åˆçš„æœ‹å‹"
        else:
            relation_desc = "å€¼å¾—ä¿¡èµ–çš„æœ‹å‹"
    else:
        if familiarity > 90 and trust > 90:
            relation_desc = "æœ€äº²å¯†çš„æœ‹å‹"
        else:
            relation_desc = "éå¸¸è¦å¥½çš„æœ‹å‹"

    # è®¡ç®—æ¬¡è¦å¿ƒæƒ…æ˜¾ç¤ºå†…å®¹
    secondary_emotion_message = f" + æ¬¡è¦å¿ƒæƒ…: {secondary_emotion}" if secondary_emotion else ""
    
    # æ„é€  Prompt
    final_system_prompt = AGENT_SYSTEM_PROMPT.format(
        core_persona=ALICE_CORE_PERSONA,
        time=now_str,
        current_user=f"{user_display_name} ({real_user_id})",
        vision_summary=vision_summary_text,
        primary_emotion=primary_emotion,
        secondary_emotion_message=secondary_emotion_message,
        valence=valence,
        arousal=arousal,
        stress=stress,
        fatigue=fatigue,
        internal_thought=psych_ctx.get("internal_thought", "æ€è€ƒä¸­..."),
        style_instruction=psych_ctx.get("style_instruction", "ä¿æŒæ—¥å¸¸è¯­æ°”"),
        intimacy=intimacy,
        familiarity=familiarity,
        trust=trust,
        interest_match=interest_match,
        relation_desc=relation_desc,
        memories=memory_context
    ) + "\n\n" + format_instruction

    input_messages = [SystemMessage(content=final_system_prompt)]
    if len(msgs) > 0:
        input_messages.extend(msgs[-10:])

    # æ³¨å…¥å›¾ç‰‡æ•°æ® (ä»…é™ photo)
    if visual_type == "photo" and image_data:
        input_messages.append(HumanMessage(content=[
            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}},
            {"type": "text", "text": "ï¼ˆç³»ç»Ÿé™„è¨€ï¼šè¿™æ˜¯ç”¨æˆ·å‘çš„å›¾ç‰‡ï¼Œè¯·ç»“åˆå›ç­”ã€‚ï¼‰"}
        ]))

    # ğŸš€ [æ ¸å¿ƒä¿®å¤ 2] Sticker å…œåº•æŒ‡ä»¤
    # å³ä½¿çŸ­è·¯é€»è¾‘è¢«ç»•è¿‡ï¼ˆæ¯”å¦‚ç”¨æˆ·è¯´äº†"å“ˆå“ˆ" + è¡¨æƒ…åŒ…ï¼‰ï¼Œä¹Ÿè¦é˜²æ­¢ LLM å¹»è§†åˆ†æå›¾ç‰‡
    if visual_type == "sticker":
        logger.info(f"[{ts}] ğŸ­ [Alice Core] Injecting STICKER SAFEGUARD.")
        safeguard = (
            "ã€ç³»ç»Ÿå¼ºåˆ¶æŒ‡ä»¤ã€‘\n"
            "ç”¨æˆ·æœ€åå‘é€çš„æ˜¯ä¸€ä¸ªã€è¡¨æƒ…åŒ…/Stickerã€‘ï¼ˆä»£ç ä¸­å¯èƒ½æ˜¾ç¤ºä¸º'[å›¾ç‰‡]'ï¼‰ã€‚\n"
            "1. è¿™æ˜¯ä¸€ä¸ªéä¿¡æ¯æ€§çš„è¡¨æƒ…ç¬¦å·ï¼Œ**ç»å¯¹ä¸è¦**è¯¢é—®'è¿™æ˜¯ä»€ä¹ˆå›¾ç‰‡'æˆ–'å›¾ç‰‡é‡Œæœ‰ä»€ä¹ˆ'ã€‚\n"
            "2. è¯·å°†å…¶è§†ä¸ºä¸€ç§æƒ…ç»ªè¡¨è¾¾ï¼Œä»…å¯¹ç”¨æˆ·çš„æ–‡å­—å†…å®¹ï¼ˆè‹¥æœ‰ï¼‰è¿›è¡Œå›å¤ï¼Œæˆ–å›ä»¥ç®€å•äº’åŠ¨ã€‚\n"
        )
        input_messages.append(SystemMessage(content=safeguard))

    # è°ƒç”¨ LLM
    parsed = {"action": "reply", "response": "..."}
    try:
        # è‡ªåŠ¨åˆ¤æ–­å¯¹è¯ç±»å‹
        conversation_type = "group" if "group" in str(state.get("session_id", "")) else "private"
        
        response = await cached_llm_invoke(
            llm, 
            input_messages, 
            temperature=llm.temperature,
            conversation_type=conversation_type
        )
        # å¤„ç†responseå¯èƒ½æ˜¯å­—ç¬¦ä¸²çš„æƒ…å†µ
        if isinstance(response, str):
            content = response.strip()
        else:
            content = response.content.strip()

        parsed_result = robust_json_parse(content)

        if parsed_result:
            parsed = parsed_result
        else:
            logger.warning(f"[{ts}] âš ï¸ [Agent JSON Fail] Raw: {content[:50]}...")
            if "{" not in content:
                parsed = {"monologue": "Raw Text", "action": "reply", "response": content}
    except Exception as e:
        logger.error(f"[{ts}]âŒ [Agent LLM Error] {e}")

    # æ„é€ è¿”å›
    ai_msg = AIMessage(content=parsed.get("response", "..."))
    # æ ¹æ®æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·è®¾ç½®next_step
    action = parsed.get("action", "reply")
    next_step = "tool" if action in ["web_search", "generate_image", "run_python_analysis"] else "save"
    
    return {
        "messages": msgs + [ai_msg],
        "next_step": next_step,
        "tool_call": {} if action == "reply" else {"name": action,
                                                   "args": parsed.get("args")}
    }
